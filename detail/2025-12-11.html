<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Adobe将Photoshop等功能集成至ChatGPT【AI 早报 2025-12-11】 - AI早报</title>
    <link rel="icon" type="image/jpeg" href="../static/favicon.jpeg">
    <link rel="stylesheet" href="../static/css/style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
    <meta name="description" content="1. 🚀 Adobe集成Photoshop至ChatGPT
2. 🔧 智谱AI开源GLM-TTS语音模型
3. 🔧 Google更新Gemini 2.5 TTS模型
4. 🚀 Qwen发布Qwen3-Omni-Flash全模态模型
5. 🔧 Claude Code升级Agent SDK
6. 🔧 VS Code Agent体验重大升级
7. 🔧 Cursor 2.2引入Debug Mode
8. ...">
    <meta name="keywords" content="AI,人工智能,科技资讯,技术前沿,早报,2025-12-11">
</head>
<body>
    <div class="container">
        <!-- 头部 -->
        <header class="header">
            <div class="header-content">
                <h1 class="logo">
                    <i class="fas fa-newspaper"></i>
                    AI早报
                </h1>
                <p class="subtitle">每日AI资讯精选，把握技术前沿动态</p>
            </div>
        </header>

        <!-- 主要内容区域 -->
        <main class="main">
            <!-- 详情视图 -->
            <div class="detail-view">
                <div class="detail-header">
                    <button class="btn-back" onclick="window.location.href='../index.html'">
                        返回首页
                    </button>
                    <div class="detail-actions">
                        <button class="btn-share" onclick="copyUrl()">
                            <i class="fas fa-share-alt"></i>
                            分享链接
                        </button>
                    </div>
                </div>

                <div class="detail-content">
                    <div class="newspaper-detail">
                        <div class="detail-title">
                            <h1>Adobe将Photoshop等功能集成至ChatGPT【AI 早报 2025-12-11】</h1>
                            <div class="detail-meta">
                                <div class="meta-item">
                                    <i class="fas fa-calendar"></i>
                                    <span>2025-12-11</span>
                                </div>
                                <div class="meta-item">
                                    <i class="fas fa-video"></i>
                                    <span>
                                        <a href="https://www.bilibili.com/video/BV1vmmKBhEDp" target="_blank" class="bv-link">BV1vmmKBhEDp</a>
                                    </span>
                                </div>
                                <div class="meta-item">
                                    <i class="fas fa-clock"></i>
                                    <span>2025年12月11日 09:05</span>
                                </div>
                                <div class="meta-item">
                                    <i class="fas fa-list"></i>
                                    <span>23 条资讯</span>
                                </div>
                            </div>
                        </div>
                        <div class="detail-body">
                            <h2 id="_1">📋 本期概览</h2>
<ol>
<li>🚀 Adobe集成Photoshop至ChatGPT</li>
<li>🔧 智谱AI开源GLM-TTS语音模型</li>
<li>🔧 Google更新Gemini 2.5 TTS模型</li>
<li>🚀 Qwen发布Qwen3-Omni-Flash全模态模型</li>
<li>🔧 Claude Code升级Agent SDK</li>
<li>🔧 VS Code Agent体验重大升级</li>
<li>🔧 Cursor 2.2引入Debug Mode</li>
<li>🔧 Google Jules新增主动编程功能</li>
<li>🚀 智谱AI发布AI输入法</li>
<li>🔧 Google Pomelli引入动画功能</li>
<li>🔧 阿里开源Wan-Move视频模型</li>
<li>🚀 Motif发布12.7B推理模型</li>
<li>🔧 南贝格开源Nanbeige4-3B模型</li>
<li>🔧 thu-pacman发布PCMind-2.1模型</li>
<li>🚀 Arcee AI发布Trinity Mini模型</li>
<li>🔧 StarCloud卫星训练AI模型成功</li>
<li>🔧 Onsros AI发布新T内核</li>
<li>🔧 Google推出Acts事实准确性基准</li>
<li>📈 Google推广Preferred Sources功能</li>
<li>📈 OpenAI加强网络安全准备</li>
<li>📈 DeepMind训练下一代AI模型</li>
<li>🔧 NVIDIA开发AI芯片定位技术</li>
<li>📈 亚马逊投资印度350亿美元</li>
</ol>
<hr />
<h3 id="1-Adobe集成Photoshop至ChatGPT">1. 🚀 Adobe集成Photoshop至ChatGPT</h3>
<p><strong>标签</strong>： <code>Adobe</code> <code>Photoshop Express</code> <code>ChatGPT</code></p>
<p>Adobe宣布将其Photoshop Express和Acrobat功能集成至ChatGPT，用户可通过自然语言指令进行图像编辑、PDF修改和动画制作。该功能免费开放，并支持在Adobe原生应用间无缝切换。目前，桌面版、网页版和iOS应用已全面支持，Android版仅支持Express，其他功能即将上线。此次集成旨在提升用户创作效率，降低专业工具使用门槛，实现AI助手与专业创意工具的无缝协作，标志着生成式AI与专业内容创作生态的深度融合。</p>
<p><strong>🔗 相关链接：</strong><br />
- <a href="https://news.adobe.com/news/2025/12/adobe-photoshop-express-acrobat-chatgpt">https://news.adobe.com/news/2025/12/adobe-photoshop-express-acrobat-chatgpt</a></p>
<hr />
<h3 id="2-智谱AI开源GLM-TTS语音模型">2. 🔧 智谱AI开源GLM-TTS语音模型</h3>
<p><strong>标签</strong>： <code>智谱AI</code> <code>GLM-TTS</code></p>
<p>智谱AI开源GLM-TTS模型，基于大语言模型构建高质量文本转语音系统。支持零样本语音克隆、流式推理和多奖励强化学习，显著增强情感表达能力。模型优化中英文混合文本处理，解决多音字发音问题，支持多语言语音生成。模型权重已在GitHub和Hugging Face开源，提供完整训练与推理代码，适用于语音助手、有声书、虚拟主播等场景，推动中文语音合成技术发展。</p>
<p><strong>🔗 相关链接：</strong><br />
- <a href="https://github.com/zai-org/GLM-TTS">https://github.com/zai-org/GLM-TTS</a><br />
- <a href="https://huggingface.co/zai-org/GLM-TTS">https://huggingface.co/zai-org/GLM-TTS</a><br />
- <a href="https://audio.z.ai/">https://audio.z.ai/</a></p>
<hr />
<h3 id="3-Google更新Gemini-25-TTS模型">3. 🔧 Google更新Gemini 2.5 TTS模型</h3>
<p><strong>标签</strong>： <code>Google</code> <code>Gemini 2.5</code> <code>TTS</code></p>
<p>Google发布Gemini 2.5 Flash和Pro TTS预览模型，取代此前版本。核心改进包括增强风格与语调多样性、精准语速控制和多说话人对话能力，支持24种语言。模型可通过Google AI Studio和GNI API访问，适用于语音助手、内容创作、多语言客服等场景。新模型在自然度和表现力上显著提升，支持更复杂的语音交互需求，推动生成式语音技术全球化应用。</p>
<p><strong>🔗 相关链接：</strong><br />
- <a href="https://github.com/zai-org/GLM-TTS">https://github.com/zai-org/GLM-TTS</a><br />
- <a href="https://huggingface.co/zai-org/GLM-TTS">https://huggingface.co/zai-org/GLM-TTS</a><br />
- <a href="https://audio.z.ai/">https://audio.z.ai/</a></p>
<hr />
<h3 id="4-Qwen发布Qwen3-Omni-Flash全模态模型">4. 🚀 Qwen发布Qwen3-Omni-Flash全模态模型</h3>
<p><strong>标签</strong>： <code>Qwen</code> <code>Qwen3-Omni-Flash</code></p>
<p>Qwen发布Qwen3-Omni-Flash-2025-12-01全模态大模型，支持文本、图像、音频和视频输入，实现实时流式生成与多模态输出。功能包括音视频交互、系统提示控制、多语言支持和语音生成，显著提升跨模态理解与生成能力。模型适用于智能助手、多模态内容创作、实时翻译等场景，推动端到端多模态AI系统发展。</p>
<p><strong>🔗 相关链接：</strong><br />
- <a href="https://qwen.ai/blog?id=qwen3-omni-flash-20251201">https://qwen.ai/blog?id=qwen3-omni-flash-20251201</a></p>
<hr />
<h3 id="5-Claude-Code升级Agent-SDK">5. 🔧 Claude Code升级Agent SDK</h3>
<p><strong>标签</strong>： <code>Claude Code</code> <code>Agent SDK</code></p>
<p>Claude Code发布新功能并升级Agent SDK，支持通过claude_rules目录加载自定义规则。新增异步子代理、即时上下文压缩、自定义会话名称和使用统计功能。Agent SDK升级后支持100万token上下文窗口、沙盒机制和第二版text_group接口，提升代码生成与调试效率，适用于复杂开发任务自动化。</p>
<p><strong>🔗 相关链接：</strong><br />
- <a href="https://x.com/claudeai/status/1998830338735485239">https://x.com/claudeai/status/1998830338735485239</a></p>
<hr />
<h3 id="6-VS-Code-Agent体验重大升级">6. 🔧 VS Code Agent体验重大升级</h3>
<p><strong>标签</strong>： <code>Visual Studio Code</code> <code>Agent</code></p>
<p>Visual Studio Code升级Agent体验，集成会话管理、隔离、后台运行和无缝任务委托功能。Agent sessions集成至聊天界面，支持基于git works的独立后台agents并行运行，实现跨agents任务委托与聊天上下文自动转移，提升开发协作效率，适用于多任务并行开发场景。</p>
<p><strong>🔗 相关链接：</strong><br />
- <a href="https://x.com/claudeai/status/1998830338735485239">https://x.com/claudeai/status/1998830338735485239</a><br />
- <a href="https://aka.ms/VSCodeRelease">https://aka.ms/VSCodeRelease</a></p>
<hr />
<h3 id="7-Cursor-22引入Debug-Mode">7. 🔧 Cursor 2.2引入Debug Mode</h3>
<p><strong>标签</strong>： <code>Cursor</code> <code>Debug Mode</code></p>
<p>Cursor发布2.2版本，引入Debug Mode，支持通过运行时日志复现和修复错误。新增内联mema图表、multi-agent judging自动评估并行agent结果、Pan chats允许置顶聊天记录。功能提升代码调试效率，支持复杂项目多代理协作，适用于全栈开发与AI辅助编程场景。</p>
<p><strong>🔗 相关链接：</strong><br />
- <a href="https://cursor.com/changelog/2-2">https://cursor.com/changelog/2-2</a><br />
- <a href="https://cursor.com/blog/debug-mode">https://cursor.com/blog/debug-mode</a></p>
<hr />
<h3 id="8-Google-Jules新增主动编程功能">8. 🔧 Google Jules新增主动编程功能</h3>
<p><strong>标签</strong>： <code>Google</code> <code>Jules</code></p>
<p>Google为编程Agent Jules新增suggested tasks、schedule tasks和render集成功能。suggested tasks扫描代码提出改进建议，schedule tasks支持定义任务频率并自动执行，render集成可分析部署失败日志并创建修复PR。suggested tasks向Pro和Ultra用户推出，其他功能对所有用户开放，提升开发自动化水平。</p>
<p><strong>🔗 相关链接：</strong><br />
- <a href="https://blog.google/technology/developers/gemini-2-5-text-to-speech/">https://blog.google/technology/developers/gemini-2-5-text-to-speech/</a><br />
- <a href="https://blog.google/technology/developers/jules-proactive-updates/">https://blog.google/technology/developers/jules-proactive-updates/</a><br />
- <a href="https://x.com/GoogleLabs/status/1998830445103054961">https://x.com/GoogleLabs/status/1998830445103054961</a></p>
<hr />
<h3 id="9-智谱AI发布AI输入法">9. 🚀 智谱AI发布AI输入法</h3>
<p><strong>标签</strong>： <code>智谱AI</code> <code>AI输入法</code></p>
<p>智谱AI发布基于GLM-ASR的桌面端输入法，支持语音转文字、翻译改写、所选即所改、一体化改写、人设切换。新增p-coding语音输入代码、屏幕捕捉和专属词汇导入功能，免费提供2000积分（约28天使用时长），适用于高效办公与编程场景。</p>
<p><strong>🔗 相关链接：</strong><br />
- <a href="https://github.com/zai-org/GLM-TTS">https://github.com/zai-org/GLM-TTS</a><br />
- <a href="https://huggingface.co/zai-org/GLM-TTS">https://huggingface.co/zai-org/GLM-TTS</a><br />
- <a href="https://audio.z.ai/">https://audio.z.ai/</a></p>
<hr />
<h3 id="10-Google-Pomelli引入动画功能">10. 🔧 Google Pomelli引入动画功能</h3>
<p><strong>标签</strong>： <code>Google Labs</code> <code>Pomelli</code></p>
<p>Google Labs为Pomelli引入animate功能，由VIVO 3.1模型支持，可将内容转换为符合品牌调性的动画。目前在美国、加拿大、澳大利亚和新西兰免费提供，适用于品牌内容创作、社交媒体营销等场景，提升内容表现力。</p>
<p><strong>🔗 相关链接：</strong><br />
- <a href="https://x.com/GoogleLabs/status/1998830445103054961">https://x.com/GoogleLabs/status/1998830445103054961</a><br />
- <a href="https://labs.google/pomelli">https://labs.google/pomelli</a></p>
<hr />
<h3 id="11-阿里开源Wan-Move视频模型">11. 🔧 阿里开源Wan-Move视频模型</h3>
<p><strong>标签</strong>： <code>阿里通义实验室</code> <code>Wan-Move</code></p>
<p>阿里通义实验室开源Wan-Move视频生成框架，通过潜在轨迹引导实现细粒度运动控制，支持生成长达5秒、480P高质量视频。模型基于扩散架构，适用于广告、短视频、影视预演等场景，推动可控视频生成技术发展。</p>
<p><strong>🔗 相关链接：</strong><br />
- <a href="https://github.com/ali-vilab/Wan-Move">https://github.com/ali-vilab/Wan-Move</a><br />
- <a href="https://huggingface.co/Ruihang/Wan-Move-14B-480P">https://huggingface.co/Ruihang/Wan-Move-14B-480P</a><br />
- <a href="https://arxiv.org/abs/2512.08765">https://arxiv.org/abs/2512.08765</a></p>
<hr />
<h3 id="12-Motif发布127B推理模型">12. 🚀 Motif发布12.7B推理模型</h3>
<p><strong>标签</strong>： <code>Motif Technologies</code> <code>Motif-2-12.7B</code></p>
<p>Motif Technologies发布Motif-2-12.7B-Reasoning模型，127亿参数开源推理模型，在Artificial Analysis智能指数中获45分，成为韩国领先AI模型。适用于复杂推理、数学计算、逻辑分析等任务，推动开源推理模型发展。</p>
<p><strong>🔗 相关链接：</strong><br />
- <a href="https://huggingface.co/Motif-Technologies/Motif-2-12.7B-Reasoning">https://huggingface.co/Motif-Technologies/Motif-2-12.7B-Reasoning</a><br />
- <a href="https://huggingface.co/Motif-Technologies/Motif-2-12.7B-Base">https://huggingface.co/Motif-Technologies/Motif-2-12.7B-Base</a></p>
<hr />
<h3 id="13-南贝格开源Nanbeige4-3B模型">13. 🔧 南贝格开源Nanbeige4-3B模型</h3>
<p><strong>标签</strong>： <code>南贝格</code> <code>Nanbeige4-3B</code></p>
<p>南贝格发布Nanbeige4-3B系列模型，包含Base和Thinking两种30亿参数变体。Base模型在多项基准测试中超越同规模及更大模型，Thinking版本在数学、工具使用及创意写作任务上达到新水平，适用于轻量化AI应用。</p>
<p><strong>🔗 相关链接：</strong><br />
- <a href="https://huggingface.co/Nanbeige/Nanbeige4-3B-Base">https://huggingface.co/Nanbeige/Nanbeige4-3B-Base</a><br />
- <a href="https://huggingface.co/Nanbeige/Nanbeige4-3B-Thinking-2511">https://huggingface.co/Nanbeige/Nanbeige4-3B-Thinking-2511</a></p>
<hr />
<h3 id="14-thu-pacman发布PCMind-21模型">14. 🔧 thu-pacman发布PCMind-2.1模型</h3>
<p><strong>标签</strong>： <code>thu-pacman</code> <code>PCMind-2.1</code></p>
<p>thu-pacman发布完全开源的PCMind-2.1-Kaiyuan-2B语言模型，20亿参数，在A3910A集群上使用2.2万亿token训练。模型权重、数据和代码均在Apache 2.0许可证下发布，适用于教育、研究等场景，推动开源生态发展。</p>
<p><strong>🔗 相关链接：</strong><br />
- <a href="https://arxiv.org/abs/2512.07612">https://arxiv.org/abs/2512.07612</a><br />
- <a href="https://huggingface.co/thu-pacman/PCMind-2.1-Kaiyuan-2B">https://huggingface.co/thu-pacman/PCMind-2.1-Kaiyuan-2B</a><br />
- <a href="https://huggingface.co/datasets/thu-pacman/PCMind-2.1-Kaiyuan-2B">https://huggingface.co/datasets/thu-pacman/PCMind-2.1-Kaiyuan-2B</a></p>
<hr />
<h3 id="15-Arcee-AI发布Trinity-Mini模型">15. 🚀 Arcee AI发布Trinity Mini模型</h3>
<p><strong>标签</strong>： <code>Arcee AI</code> <code>Trinity Mini</code></p>
<p>Arcee AI发布Trinity Mini模型，26B参数稀疏MoE模型，激活参数仅3B，拥有128个专家，基于10T Tokens训练，支持128K上下文。适用于长文本处理、复杂推理等场景，提升大模型部署效率。</p>
<p><strong>🔗 相关链接：</strong><br />
- <a href="https://clarifai.com/arcee_ai/AFM/models/trinity-mini">https://clarifai.com/arcee_ai/AFM/models/trinity-mini</a><br />
- <a href="https://openrouter.ai/arcee-ai/trinity-mini">https://openrouter.ai/arcee-ai/trinity-mini</a></p>
<hr />
<h3 id="16-StarCloud卫星训练AI模型成功">16. 🔧 StarCloud卫星训练AI模型成功</h3>
<p><strong>标签</strong>： <code>StarCloud</code> <code>NVIDIA H100</code> <code>Agent IDE</code></p>
<p>安迪亚支持的StarCloud宣布在StarCloud-1卫星上使用NVIDIA H100 GPU成功训练AI模型，运行Nano GPT和Google JAMA模型。集成Agent IDE，内置浏览器、Subway和Strip支持本地运行，具备聆听和录制功能，Agent可查看用户整个屏幕并支持鼠标手势指示，推动太空AI应用。</p>
<hr />
<h3 id="17-Onsros-AI发布新T内核">17. 🔧 Onsros AI发布新T内核</h3>
<p><strong>标签</strong>： <code>Onsros AI</code> <code>T内核</code></p>
<p>Onsros AI发布新T内核和智能自动打包技术，支持将LLM训练速度提升3~5倍，减少30%~90%微RAM使用且不损失准确性，支持低至3.9GB VRAM设备训练千万34B等模型，降低大模型训练门槛。</p>
<hr />
<h3 id="18-Google推出Acts事实准确性基准">18. 🔧 Google推出Acts事实准确性基准</h3>
<p><strong>标签</strong>： <code>Google DeepMind</code> <code>Acts</code> <code>Kaggle</code></p>
<p>Google DeepMind与Kaggle推出Acts基准测试套件，系统性评估LLM事实准确性，包含四个独立基准测试，覆盖内部知识、搜索工具使用、多模态理解及上下文依存回答，推动AI模型可靠性评估标准化。</p>
<hr />
<h3 id="19-Google推广Preferred-Sources功能">19. 📈 Google推广Preferred Sources功能</h3>
<p><strong>标签</strong>： <code>Google</code> <code>Preferred Sources</code></p>
<p>Google推出Preferred Sources功能，全球推广高质量付费内容，改进AI搜索链接展示，并与新闻出版商启动AI试点项目，支持网络生态系统发展，满足用户快速获取可信信息需求。</p>
<p><strong>🔗 相关链接：</strong><br />
- <a href="https://blog.google/technology/developers/gemini-2-5-text-to-speech/">https://blog.google/technology/developers/gemini-2-5-text-to-speech/</a><br />
- <a href="https://blog.google/technology/developers/jules-proactive-updates/">https://blog.google/technology/developers/jules-proactive-updates/</a><br />
- <a href="https://x.com/GoogleLabs/status/1998830445103054961">https://x.com/GoogleLabs/status/1998830445103054961</a></p>
<hr />
<h3 id="20-OpenAI加强网络安全准备">20. 📈 OpenAI加强网络安全准备</h3>
<p><strong>标签</strong>： <code>OpenAI</code> <code>网络安全</code></p>
<p>OpenAI加强网络安全准备，应对AI模型能力提升带来的双重用途风险。预计即将推出模型可能达到高水平网络安全能力，正在实施多层次保障措施，确保能力主要用于防御目的，防范AI滥用。</p>
<hr />
<h3 id="21-DeepMind训练下一代AI模型">21. 📈 DeepMind训练下一代AI模型</h3>
<p><strong>标签</strong>： <code>DeepMind</code> <code>Blackwell</code> <code>V4</code></p>
<p>据The Information报道，DeepMind正使用数千颗英伟达Blackwell芯片训练下一代主要模型。社交媒体消息称，DeepMind V4目标发布时间为2025年2月，推动AI算力与模型能力边界拓展。</p>
<hr />
<h3 id="22-NVIDIA开发AI芯片定位技术">22. 🔧 NVIDIA开发AI芯片定位技术</h3>
<p><strong>标签</strong>： <code>NVIDIA</code> <code>AI芯片定位</code></p>
<p>NVIDIA开发验证AI芯片物理位置的技术，通过测量与NVIDIA服务器通信时间延迟推断位置，不依赖GPS。该功能为可安装软件选项，帮助数据中心运营商监控GPU机群，响应美国政策要求，切断向中国非法出口高性能芯片。</p>
<hr />
<h3 id="23-亚马逊投资印度350亿美元">23. 📈 亚马逊投资印度350亿美元</h3>
<p><strong>标签</strong>： <code>亚马逊</code> <code>印度</code> <code>AI</code></p>
<p>亚马逊承诺未来5年在印度投资350亿美元，涵盖即时零售、云计算等领域，资金投向AI和物流基础设施，预计创造100万个就业岗位，推动印度数字经济发展。</p>
<p><strong>🔗 相关链接：</strong><br />
- <a href="https://github.com/zai-org/GLM-TTS">https://github.com/zai-org/GLM-TTS</a><br />
- <a href="https://huggingface.co/zai-org/GLM-TTS">https://huggingface.co/zai-org/GLM-TTS</a><br />
- <a href="https://audio.z.ai/">https://audio.z.ai/</a></p>
<hr />
<hr />
<h2 id="_2">🎬 视频链接</h2>
<p><strong>Bilibili</strong>： <a href="https://www.bilibili.com/video/BV1vmmKBhEDp">https://www.bilibili.com/video/BV1vmmKBhEDp</a></p>
<hr />
<p><em>整理自橘鸦AI早报 | BV号：BV1vmmKBhEDp | 2025-12-11 09:05:36</em></p>
                        </div>
                    </div>
                </div>
            </div>
        </main>

        <!-- 底部 -->
        <footer class="footer">
            <p>&copy; 2025 AI早报 - <a href="https://github.com/musnows/juya_agent" target="_blank">musnows/juya_agent</a> - 整理自橘鸦AI早报</p>
        </footer>
    </div>

    <!-- 成功提示 -->
    <div id="success-toast" class="toast success hidden">
        <i class="fas fa-check-circle"></i>
        <span id="success-message"></span>
    </div>

    <script>
        function showToast(message, type = 'success') {
            const toast = document.getElementById('success-toast');
            const messageElement = document.getElementById('success-message');

            messageElement.textContent = message;
            toast.classList.remove('hidden');

            setTimeout(() => {
                toast.classList.add('hidden');
            }, 3000);
        }

        function copyUrl() {
            navigator.clipboard.writeText(window.location.href).then(() => {
                showToast('链接已复制到剪贴板', 'success');
            }).catch(() => {
                showToast('复制失败，请手动复制链接', 'error');
            });
        }

        // 键盘快捷键支持
        document.addEventListener('keydown', function(e) {
            // ESC键返回首页
            if (e.key === 'Escape') {
                window.location.href = '../index.html';
            }
        });
    </script>
</body>
</html>