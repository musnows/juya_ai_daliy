{
  "title": "Adobe将Photoshop等功能集成至ChatGPT【AI 早报 2025-12-11】",
  "publish_date": "2025-12-11",
  "bv_id": "BV1vmmKBhEDp",
  "organize_time": "2025-12-11 09:05:36",
  "news_count": 23,
  "overview": "1. 🚀 Adobe集成Photoshop至ChatGPT\n2. 🔧 智谱AI开源GLM-TTS语音模型\n3. 🔧 Google更新Gemini 2.5 TTS模型\n4. 🚀 Qwen发布Qwen3-Omni-Flash全模态模型\n5. 🔧 Claude Code升级Agent SDK\n6. 🔧 VS Code Agent体验重大升级\n7. 🔧 Cursor 2.2引入Debug Mode\n8. 🔧 Google Jules新增主动编程功能\n9. 🚀 智谱AI发布AI输入法\n10. 🔧 Google Pomelli引入动画功能\n11. 🔧 阿里开源Wan-Move视频模型\n12. 🚀 Motif发布12.7B推理模型\n13. 🔧 南贝格开源Nanbeige4-3B模型\n14. 🔧 thu-pacman发布PCMind-2.1模型\n15. 🚀 Arcee AI发布Trinity Mini模型\n16. 🔧 StarCloud卫星训练AI模型成功\n17. 🔧 Onsros AI发布新T内核\n18. 🔧 Google推出Acts事实准确性基准\n19. 📈 Google推广Preferred Sources功能\n20. 📈 OpenAI加强网络安全准备\n21. 📈 DeepMind训练下一代AI模型\n22. 🔧 NVIDIA开发AI芯片定位技术\n23. 📈 亚马逊投资印度350亿美元",
  "html_content": "<h2 id=\"_1\">📋 本期概览</h2>\n<ol>\n<li>🚀 Adobe集成Photoshop至ChatGPT</li>\n<li>🔧 智谱AI开源GLM-TTS语音模型</li>\n<li>🔧 Google更新Gemini 2.5 TTS模型</li>\n<li>🚀 Qwen发布Qwen3-Omni-Flash全模态模型</li>\n<li>🔧 Claude Code升级Agent SDK</li>\n<li>🔧 VS Code Agent体验重大升级</li>\n<li>🔧 Cursor 2.2引入Debug Mode</li>\n<li>🔧 Google Jules新增主动编程功能</li>\n<li>🚀 智谱AI发布AI输入法</li>\n<li>🔧 Google Pomelli引入动画功能</li>\n<li>🔧 阿里开源Wan-Move视频模型</li>\n<li>🚀 Motif发布12.7B推理模型</li>\n<li>🔧 南贝格开源Nanbeige4-3B模型</li>\n<li>🔧 thu-pacman发布PCMind-2.1模型</li>\n<li>🚀 Arcee AI发布Trinity Mini模型</li>\n<li>🔧 StarCloud卫星训练AI模型成功</li>\n<li>🔧 Onsros AI发布新T内核</li>\n<li>🔧 Google推出Acts事实准确性基准</li>\n<li>📈 Google推广Preferred Sources功能</li>\n<li>📈 OpenAI加强网络安全准备</li>\n<li>📈 DeepMind训练下一代AI模型</li>\n<li>🔧 NVIDIA开发AI芯片定位技术</li>\n<li>📈 亚马逊投资印度350亿美元</li>\n</ol>\n<hr />\n<h3 id=\"1-Adobe集成Photoshop至ChatGPT\">1. 🚀 Adobe集成Photoshop至ChatGPT</h3>\n<p><strong>标签</strong>： <code>Adobe</code> <code>Photoshop Express</code> <code>ChatGPT</code></p>\n<p>Adobe宣布将其Photoshop Express和Acrobat功能集成至ChatGPT，用户可通过自然语言指令进行图像编辑、PDF修改和动画制作。该功能免费开放，并支持在Adobe原生应用间无缝切换。目前，桌面版、网页版和iOS应用已全面支持，Android版仅支持Express，其他功能即将上线。此次集成旨在提升用户创作效率，降低专业工具使用门槛，实现AI助手与专业创意工具的无缝协作，标志着生成式AI与专业内容创作生态的深度融合。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://news.adobe.com/news/2025/12/adobe-photoshop-express-acrobat-chatgpt\">https://news.adobe.com/news/2025/12/adobe-photoshop-express-acrobat-chatgpt</a></p>\n<hr />\n<h3 id=\"2-智谱AI开源GLM-TTS语音模型\">2. 🔧 智谱AI开源GLM-TTS语音模型</h3>\n<p><strong>标签</strong>： <code>智谱AI</code> <code>GLM-TTS</code></p>\n<p>智谱AI开源GLM-TTS模型，基于大语言模型构建高质量文本转语音系统。支持零样本语音克隆、流式推理和多奖励强化学习，显著增强情感表达能力。模型优化中英文混合文本处理，解决多音字发音问题，支持多语言语音生成。模型权重已在GitHub和Hugging Face开源，提供完整训练与推理代码，适用于语音助手、有声书、虚拟主播等场景，推动中文语音合成技术发展。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://github.com/zai-org/GLM-TTS\">https://github.com/zai-org/GLM-TTS</a><br />\n- <a href=\"https://huggingface.co/zai-org/GLM-TTS\">https://huggingface.co/zai-org/GLM-TTS</a><br />\n- <a href=\"https://audio.z.ai/\">https://audio.z.ai/</a></p>\n<hr />\n<h3 id=\"3-Google更新Gemini-25-TTS模型\">3. 🔧 Google更新Gemini 2.5 TTS模型</h3>\n<p><strong>标签</strong>： <code>Google</code> <code>Gemini 2.5</code> <code>TTS</code></p>\n<p>Google发布Gemini 2.5 Flash和Pro TTS预览模型，取代此前版本。核心改进包括增强风格与语调多样性、精准语速控制和多说话人对话能力，支持24种语言。模型可通过Google AI Studio和GNI API访问，适用于语音助手、内容创作、多语言客服等场景。新模型在自然度和表现力上显著提升，支持更复杂的语音交互需求，推动生成式语音技术全球化应用。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://github.com/zai-org/GLM-TTS\">https://github.com/zai-org/GLM-TTS</a><br />\n- <a href=\"https://huggingface.co/zai-org/GLM-TTS\">https://huggingface.co/zai-org/GLM-TTS</a><br />\n- <a href=\"https://audio.z.ai/\">https://audio.z.ai/</a></p>\n<hr />\n<h3 id=\"4-Qwen发布Qwen3-Omni-Flash全模态模型\">4. 🚀 Qwen发布Qwen3-Omni-Flash全模态模型</h3>\n<p><strong>标签</strong>： <code>Qwen</code> <code>Qwen3-Omni-Flash</code></p>\n<p>Qwen发布Qwen3-Omni-Flash-2025-12-01全模态大模型，支持文本、图像、音频和视频输入，实现实时流式生成与多模态输出。功能包括音视频交互、系统提示控制、多语言支持和语音生成，显著提升跨模态理解与生成能力。模型适用于智能助手、多模态内容创作、实时翻译等场景，推动端到端多模态AI系统发展。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://qwen.ai/blog?id=qwen3-omni-flash-20251201\">https://qwen.ai/blog?id=qwen3-omni-flash-20251201</a></p>\n<hr />\n<h3 id=\"5-Claude-Code升级Agent-SDK\">5. 🔧 Claude Code升级Agent SDK</h3>\n<p><strong>标签</strong>： <code>Claude Code</code> <code>Agent SDK</code></p>\n<p>Claude Code发布新功能并升级Agent SDK，支持通过claude_rules目录加载自定义规则。新增异步子代理、即时上下文压缩、自定义会话名称和使用统计功能。Agent SDK升级后支持100万token上下文窗口、沙盒机制和第二版text_group接口，提升代码生成与调试效率，适用于复杂开发任务自动化。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/claudeai/status/1998830338735485239\">https://x.com/claudeai/status/1998830338735485239</a></p>\n<hr />\n<h3 id=\"6-VS-Code-Agent体验重大升级\">6. 🔧 VS Code Agent体验重大升级</h3>\n<p><strong>标签</strong>： <code>Visual Studio Code</code> <code>Agent</code></p>\n<p>Visual Studio Code升级Agent体验，集成会话管理、隔离、后台运行和无缝任务委托功能。Agent sessions集成至聊天界面，支持基于git works的独立后台agents并行运行，实现跨agents任务委托与聊天上下文自动转移，提升开发协作效率，适用于多任务并行开发场景。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/claudeai/status/1998830338735485239\">https://x.com/claudeai/status/1998830338735485239</a><br />\n- <a href=\"https://aka.ms/VSCodeRelease\">https://aka.ms/VSCodeRelease</a></p>\n<hr />\n<h3 id=\"7-Cursor-22引入Debug-Mode\">7. 🔧 Cursor 2.2引入Debug Mode</h3>\n<p><strong>标签</strong>： <code>Cursor</code> <code>Debug Mode</code></p>\n<p>Cursor发布2.2版本，引入Debug Mode，支持通过运行时日志复现和修复错误。新增内联mema图表、multi-agent judging自动评估并行agent结果、Pan chats允许置顶聊天记录。功能提升代码调试效率，支持复杂项目多代理协作，适用于全栈开发与AI辅助编程场景。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://cursor.com/changelog/2-2\">https://cursor.com/changelog/2-2</a><br />\n- <a href=\"https://cursor.com/blog/debug-mode\">https://cursor.com/blog/debug-mode</a></p>\n<hr />\n<h3 id=\"8-Google-Jules新增主动编程功能\">8. 🔧 Google Jules新增主动编程功能</h3>\n<p><strong>标签</strong>： <code>Google</code> <code>Jules</code></p>\n<p>Google为编程Agent Jules新增suggested tasks、schedule tasks和render集成功能。suggested tasks扫描代码提出改进建议，schedule tasks支持定义任务频率并自动执行，render集成可分析部署失败日志并创建修复PR。suggested tasks向Pro和Ultra用户推出，其他功能对所有用户开放，提升开发自动化水平。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://blog.google/technology/developers/gemini-2-5-text-to-speech/\">https://blog.google/technology/developers/gemini-2-5-text-to-speech/</a><br />\n- <a href=\"https://blog.google/technology/developers/jules-proactive-updates/\">https://blog.google/technology/developers/jules-proactive-updates/</a><br />\n- <a href=\"https://x.com/GoogleLabs/status/1998830445103054961\">https://x.com/GoogleLabs/status/1998830445103054961</a></p>\n<hr />\n<h3 id=\"9-智谱AI发布AI输入法\">9. 🚀 智谱AI发布AI输入法</h3>\n<p><strong>标签</strong>： <code>智谱AI</code> <code>AI输入法</code></p>\n<p>智谱AI发布基于GLM-ASR的桌面端输入法，支持语音转文字、翻译改写、所选即所改、一体化改写、人设切换。新增p-coding语音输入代码、屏幕捕捉和专属词汇导入功能，免费提供2000积分（约28天使用时长），适用于高效办公与编程场景。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://github.com/zai-org/GLM-TTS\">https://github.com/zai-org/GLM-TTS</a><br />\n- <a href=\"https://huggingface.co/zai-org/GLM-TTS\">https://huggingface.co/zai-org/GLM-TTS</a><br />\n- <a href=\"https://audio.z.ai/\">https://audio.z.ai/</a></p>\n<hr />\n<h3 id=\"10-Google-Pomelli引入动画功能\">10. 🔧 Google Pomelli引入动画功能</h3>\n<p><strong>标签</strong>： <code>Google Labs</code> <code>Pomelli</code></p>\n<p>Google Labs为Pomelli引入animate功能，由VIVO 3.1模型支持，可将内容转换为符合品牌调性的动画。目前在美国、加拿大、澳大利亚和新西兰免费提供，适用于品牌内容创作、社交媒体营销等场景，提升内容表现力。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/GoogleLabs/status/1998830445103054961\">https://x.com/GoogleLabs/status/1998830445103054961</a><br />\n- <a href=\"https://labs.google/pomelli\">https://labs.google/pomelli</a></p>\n<hr />\n<h3 id=\"11-阿里开源Wan-Move视频模型\">11. 🔧 阿里开源Wan-Move视频模型</h3>\n<p><strong>标签</strong>： <code>阿里通义实验室</code> <code>Wan-Move</code></p>\n<p>阿里通义实验室开源Wan-Move视频生成框架，通过潜在轨迹引导实现细粒度运动控制，支持生成长达5秒、480P高质量视频。模型基于扩散架构，适用于广告、短视频、影视预演等场景，推动可控视频生成技术发展。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://github.com/ali-vilab/Wan-Move\">https://github.com/ali-vilab/Wan-Move</a><br />\n- <a href=\"https://huggingface.co/Ruihang/Wan-Move-14B-480P\">https://huggingface.co/Ruihang/Wan-Move-14B-480P</a><br />\n- <a href=\"https://arxiv.org/abs/2512.08765\">https://arxiv.org/abs/2512.08765</a></p>\n<hr />\n<h3 id=\"12-Motif发布127B推理模型\">12. 🚀 Motif发布12.7B推理模型</h3>\n<p><strong>标签</strong>： <code>Motif Technologies</code> <code>Motif-2-12.7B</code></p>\n<p>Motif Technologies发布Motif-2-12.7B-Reasoning模型，127亿参数开源推理模型，在Artificial Analysis智能指数中获45分，成为韩国领先AI模型。适用于复杂推理、数学计算、逻辑分析等任务，推动开源推理模型发展。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://huggingface.co/Motif-Technologies/Motif-2-12.7B-Reasoning\">https://huggingface.co/Motif-Technologies/Motif-2-12.7B-Reasoning</a><br />\n- <a href=\"https://huggingface.co/Motif-Technologies/Motif-2-12.7B-Base\">https://huggingface.co/Motif-Technologies/Motif-2-12.7B-Base</a></p>\n<hr />\n<h3 id=\"13-南贝格开源Nanbeige4-3B模型\">13. 🔧 南贝格开源Nanbeige4-3B模型</h3>\n<p><strong>标签</strong>： <code>南贝格</code> <code>Nanbeige4-3B</code></p>\n<p>南贝格发布Nanbeige4-3B系列模型，包含Base和Thinking两种30亿参数变体。Base模型在多项基准测试中超越同规模及更大模型，Thinking版本在数学、工具使用及创意写作任务上达到新水平，适用于轻量化AI应用。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://huggingface.co/Nanbeige/Nanbeige4-3B-Base\">https://huggingface.co/Nanbeige/Nanbeige4-3B-Base</a><br />\n- <a href=\"https://huggingface.co/Nanbeige/Nanbeige4-3B-Thinking-2511\">https://huggingface.co/Nanbeige/Nanbeige4-3B-Thinking-2511</a></p>\n<hr />\n<h3 id=\"14-thu-pacman发布PCMind-21模型\">14. 🔧 thu-pacman发布PCMind-2.1模型</h3>\n<p><strong>标签</strong>： <code>thu-pacman</code> <code>PCMind-2.1</code></p>\n<p>thu-pacman发布完全开源的PCMind-2.1-Kaiyuan-2B语言模型，20亿参数，在A3910A集群上使用2.2万亿token训练。模型权重、数据和代码均在Apache 2.0许可证下发布，适用于教育、研究等场景，推动开源生态发展。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://arxiv.org/abs/2512.07612\">https://arxiv.org/abs/2512.07612</a><br />\n- <a href=\"https://huggingface.co/thu-pacman/PCMind-2.1-Kaiyuan-2B\">https://huggingface.co/thu-pacman/PCMind-2.1-Kaiyuan-2B</a><br />\n- <a href=\"https://huggingface.co/datasets/thu-pacman/PCMind-2.1-Kaiyuan-2B\">https://huggingface.co/datasets/thu-pacman/PCMind-2.1-Kaiyuan-2B</a></p>\n<hr />\n<h3 id=\"15-Arcee-AI发布Trinity-Mini模型\">15. 🚀 Arcee AI发布Trinity Mini模型</h3>\n<p><strong>标签</strong>： <code>Arcee AI</code> <code>Trinity Mini</code></p>\n<p>Arcee AI发布Trinity Mini模型，26B参数稀疏MoE模型，激活参数仅3B，拥有128个专家，基于10T Tokens训练，支持128K上下文。适用于长文本处理、复杂推理等场景，提升大模型部署效率。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://clarifai.com/arcee_ai/AFM/models/trinity-mini\">https://clarifai.com/arcee_ai/AFM/models/trinity-mini</a><br />\n- <a href=\"https://openrouter.ai/arcee-ai/trinity-mini\">https://openrouter.ai/arcee-ai/trinity-mini</a></p>\n<hr />\n<h3 id=\"16-StarCloud卫星训练AI模型成功\">16. 🔧 StarCloud卫星训练AI模型成功</h3>\n<p><strong>标签</strong>： <code>StarCloud</code> <code>NVIDIA H100</code> <code>Agent IDE</code></p>\n<p>安迪亚支持的StarCloud宣布在StarCloud-1卫星上使用NVIDIA H100 GPU成功训练AI模型，运行Nano GPT和Google JAMA模型。集成Agent IDE，内置浏览器、Subway和Strip支持本地运行，具备聆听和录制功能，Agent可查看用户整个屏幕并支持鼠标手势指示，推动太空AI应用。</p>\n<hr />\n<h3 id=\"17-Onsros-AI发布新T内核\">17. 🔧 Onsros AI发布新T内核</h3>\n<p><strong>标签</strong>： <code>Onsros AI</code> <code>T内核</code></p>\n<p>Onsros AI发布新T内核和智能自动打包技术，支持将LLM训练速度提升3~5倍，减少30%~90%微RAM使用且不损失准确性，支持低至3.9GB VRAM设备训练千万34B等模型，降低大模型训练门槛。</p>\n<hr />\n<h3 id=\"18-Google推出Acts事实准确性基准\">18. 🔧 Google推出Acts事实准确性基准</h3>\n<p><strong>标签</strong>： <code>Google DeepMind</code> <code>Acts</code> <code>Kaggle</code></p>\n<p>Google DeepMind与Kaggle推出Acts基准测试套件，系统性评估LLM事实准确性，包含四个独立基准测试，覆盖内部知识、搜索工具使用、多模态理解及上下文依存回答，推动AI模型可靠性评估标准化。</p>\n<hr />\n<h3 id=\"19-Google推广Preferred-Sources功能\">19. 📈 Google推广Preferred Sources功能</h3>\n<p><strong>标签</strong>： <code>Google</code> <code>Preferred Sources</code></p>\n<p>Google推出Preferred Sources功能，全球推广高质量付费内容，改进AI搜索链接展示，并与新闻出版商启动AI试点项目，支持网络生态系统发展，满足用户快速获取可信信息需求。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://blog.google/technology/developers/gemini-2-5-text-to-speech/\">https://blog.google/technology/developers/gemini-2-5-text-to-speech/</a><br />\n- <a href=\"https://blog.google/technology/developers/jules-proactive-updates/\">https://blog.google/technology/developers/jules-proactive-updates/</a><br />\n- <a href=\"https://x.com/GoogleLabs/status/1998830445103054961\">https://x.com/GoogleLabs/status/1998830445103054961</a></p>\n<hr />\n<h3 id=\"20-OpenAI加强网络安全准备\">20. 📈 OpenAI加强网络安全准备</h3>\n<p><strong>标签</strong>： <code>OpenAI</code> <code>网络安全</code></p>\n<p>OpenAI加强网络安全准备，应对AI模型能力提升带来的双重用途风险。预计即将推出模型可能达到高水平网络安全能力，正在实施多层次保障措施，确保能力主要用于防御目的，防范AI滥用。</p>\n<hr />\n<h3 id=\"21-DeepMind训练下一代AI模型\">21. 📈 DeepMind训练下一代AI模型</h3>\n<p><strong>标签</strong>： <code>DeepMind</code> <code>Blackwell</code> <code>V4</code></p>\n<p>据The Information报道，DeepMind正使用数千颗英伟达Blackwell芯片训练下一代主要模型。社交媒体消息称，DeepMind V4目标发布时间为2025年2月，推动AI算力与模型能力边界拓展。</p>\n<hr />\n<h3 id=\"22-NVIDIA开发AI芯片定位技术\">22. 🔧 NVIDIA开发AI芯片定位技术</h3>\n<p><strong>标签</strong>： <code>NVIDIA</code> <code>AI芯片定位</code></p>\n<p>NVIDIA开发验证AI芯片物理位置的技术，通过测量与NVIDIA服务器通信时间延迟推断位置，不依赖GPS。该功能为可安装软件选项，帮助数据中心运营商监控GPU机群，响应美国政策要求，切断向中国非法出口高性能芯片。</p>\n<hr />\n<h3 id=\"23-亚马逊投资印度350亿美元\">23. 📈 亚马逊投资印度350亿美元</h3>\n<p><strong>标签</strong>： <code>亚马逊</code> <code>印度</code> <code>AI</code></p>\n<p>亚马逊承诺未来5年在印度投资350亿美元，涵盖即时零售、云计算等领域，资金投向AI和物流基础设施，预计创造100万个就业岗位，推动印度数字经济发展。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://github.com/zai-org/GLM-TTS\">https://github.com/zai-org/GLM-TTS</a><br />\n- <a href=\"https://huggingface.co/zai-org/GLM-TTS\">https://huggingface.co/zai-org/GLM-TTS</a><br />\n- <a href=\"https://audio.z.ai/\">https://audio.z.ai/</a></p>\n<hr />\n<hr />\n<h2 id=\"_2\">🎬 视频链接</h2>\n<p><strong>Bilibili</strong>： <a href=\"https://www.bilibili.com/video/BV1vmmKBhEDp\">https://www.bilibili.com/video/BV1vmmKBhEDp</a></p>\n<hr />\n<p><em>整理自橘鸦AI早报 | BV号：BV1vmmKBhEDp | 2025-12-11 09:05:36</em></p>",
  "content": "# Adobe将Photoshop等功能集成至ChatGPT【AI 早报 2025-12-11】\n\n**📅 发布日期：** 2025-12-11\n**🎬 BV号：** [BV1vmmKBhEDp](https://www.bilibili.com/video/BV1vmmKBhEDp)\n**📝 整理时间：** 2025-12-11 09:05:36\n**📊 资讯数量：** 23 条\n\n---\n\n## 📋 本期概览\n\n1. 🚀 Adobe集成Photoshop至ChatGPT\n2. 🔧 智谱AI开源GLM-TTS语音模型\n3. 🔧 Google更新Gemini 2.5 TTS模型\n4. 🚀 Qwen发布Qwen3-Omni-Flash全模态模型\n5. 🔧 Claude Code升级Agent SDK\n6. 🔧 VS Code Agent体验重大升级\n7. 🔧 Cursor 2.2引入Debug Mode\n8. 🔧 Google Jules新增主动编程功能\n9. 🚀 智谱AI发布AI输入法\n10. 🔧 Google Pomelli引入动画功能\n11. 🔧 阿里开源Wan-Move视频模型\n12. 🚀 Motif发布12.7B推理模型\n13. 🔧 南贝格开源Nanbeige4-3B模型\n14. 🔧 thu-pacman发布PCMind-2.1模型\n15. 🚀 Arcee AI发布Trinity Mini模型\n16. 🔧 StarCloud卫星训练AI模型成功\n17. 🔧 Onsros AI发布新T内核\n18. 🔧 Google推出Acts事实准确性基准\n19. 📈 Google推广Preferred Sources功能\n20. 📈 OpenAI加强网络安全准备\n21. 📈 DeepMind训练下一代AI模型\n22. 🔧 NVIDIA开发AI芯片定位技术\n23. 📈 亚马逊投资印度350亿美元\n\n---\n\n### 1. 🚀 Adobe集成Photoshop至ChatGPT {#1-Adobe集成Photoshop至ChatGPT}\n\n**标签**： `Adobe` `Photoshop Express` `ChatGPT`\n\nAdobe宣布将其Photoshop Express和Acrobat功能集成至ChatGPT，用户可通过自然语言指令进行图像编辑、PDF修改和动画制作。该功能免费开放，并支持在Adobe原生应用间无缝切换。目前，桌面版、网页版和iOS应用已全面支持，Android版仅支持Express，其他功能即将上线。此次集成旨在提升用户创作效率，降低专业工具使用门槛，实现AI助手与专业创意工具的无缝协作，标志着生成式AI与专业内容创作生态的深度融合。\n\n**🔗 相关链接：**\n- <https://news.adobe.com/news/2025/12/adobe-photoshop-express-acrobat-chatgpt>\n\n---\n\n### 2. 🔧 智谱AI开源GLM-TTS语音模型 {#2-智谱AI开源GLM-TTS语音模型}\n\n**标签**： `智谱AI` `GLM-TTS`\n\n智谱AI开源GLM-TTS模型，基于大语言模型构建高质量文本转语音系统。支持零样本语音克隆、流式推理和多奖励强化学习，显著增强情感表达能力。模型优化中英文混合文本处理，解决多音字发音问题，支持多语言语音生成。模型权重已在GitHub和Hugging Face开源，提供完整训练与推理代码，适用于语音助手、有声书、虚拟主播等场景，推动中文语音合成技术发展。\n\n**🔗 相关链接：**\n- <https://github.com/zai-org/GLM-TTS>\n- <https://huggingface.co/zai-org/GLM-TTS>\n- <https://audio.z.ai/>\n\n---\n\n### 3. 🔧 Google更新Gemini 2.5 TTS模型 {#3-Google更新Gemini-25-TTS模型}\n\n**标签**： `Google` `Gemini 2.5` `TTS`\n\nGoogle发布Gemini 2.5 Flash和Pro TTS预览模型，取代此前版本。核心改进包括增强风格与语调多样性、精准语速控制和多说话人对话能力，支持24种语言。模型可通过Google AI Studio和GNI API访问，适用于语音助手、内容创作、多语言客服等场景。新模型在自然度和表现力上显著提升，支持更复杂的语音交互需求，推动生成式语音技术全球化应用。\n\n**🔗 相关链接：**\n- <https://github.com/zai-org/GLM-TTS>\n- <https://huggingface.co/zai-org/GLM-TTS>\n- <https://audio.z.ai/>\n\n---\n\n### 4. 🚀 Qwen发布Qwen3-Omni-Flash全模态模型 {#4-Qwen发布Qwen3-Omni-Flash全模态模型}\n\n**标签**： `Qwen` `Qwen3-Omni-Flash`\n\nQwen发布Qwen3-Omni-Flash-2025-12-01全模态大模型，支持文本、图像、音频和视频输入，实现实时流式生成与多模态输出。功能包括音视频交互、系统提示控制、多语言支持和语音生成，显著提升跨模态理解与生成能力。模型适用于智能助手、多模态内容创作、实时翻译等场景，推动端到端多模态AI系统发展。\n\n**🔗 相关链接：**\n- <https://qwen.ai/blog?id=qwen3-omni-flash-20251201>\n\n---\n\n### 5. 🔧 Claude Code升级Agent SDK {#5-Claude-Code升级Agent-SDK}\n\n**标签**： `Claude Code` `Agent SDK`\n\nClaude Code发布新功能并升级Agent SDK，支持通过claude_rules目录加载自定义规则。新增异步子代理、即时上下文压缩、自定义会话名称和使用统计功能。Agent SDK升级后支持100万token上下文窗口、沙盒机制和第二版text_group接口，提升代码生成与调试效率，适用于复杂开发任务自动化。\n\n**🔗 相关链接：**\n- <https://x.com/claudeai/status/1998830338735485239>\n\n---\n\n### 6. 🔧 VS Code Agent体验重大升级 {#6-VS-Code-Agent体验重大升级}\n\n**标签**： `Visual Studio Code` `Agent`\n\nVisual Studio Code升级Agent体验，集成会话管理、隔离、后台运行和无缝任务委托功能。Agent sessions集成至聊天界面，支持基于git works的独立后台agents并行运行，实现跨agents任务委托与聊天上下文自动转移，提升开发协作效率，适用于多任务并行开发场景。\n\n**🔗 相关链接：**\n- <https://x.com/claudeai/status/1998830338735485239>\n- <https://aka.ms/VSCodeRelease>\n\n---\n\n### 7. 🔧 Cursor 2.2引入Debug Mode {#7-Cursor-22引入Debug-Mode}\n\n**标签**： `Cursor` `Debug Mode`\n\nCursor发布2.2版本，引入Debug Mode，支持通过运行时日志复现和修复错误。新增内联mema图表、multi-agent judging自动评估并行agent结果、Pan chats允许置顶聊天记录。功能提升代码调试效率，支持复杂项目多代理协作，适用于全栈开发与AI辅助编程场景。\n\n**🔗 相关链接：**\n- <https://cursor.com/changelog/2-2>\n- <https://cursor.com/blog/debug-mode>\n\n---\n\n### 8. 🔧 Google Jules新增主动编程功能 {#8-Google-Jules新增主动编程功能}\n\n**标签**： `Google` `Jules`\n\nGoogle为编程Agent Jules新增suggested tasks、schedule tasks和render集成功能。suggested tasks扫描代码提出改进建议，schedule tasks支持定义任务频率并自动执行，render集成可分析部署失败日志并创建修复PR。suggested tasks向Pro和Ultra用户推出，其他功能对所有用户开放，提升开发自动化水平。\n\n**🔗 相关链接：**\n- <https://blog.google/technology/developers/gemini-2-5-text-to-speech/>\n- <https://blog.google/technology/developers/jules-proactive-updates/>\n- <https://x.com/GoogleLabs/status/1998830445103054961>\n\n---\n\n### 9. 🚀 智谱AI发布AI输入法 {#9-智谱AI发布AI输入法}\n\n**标签**： `智谱AI` `AI输入法`\n\n智谱AI发布基于GLM-ASR的桌面端输入法，支持语音转文字、翻译改写、所选即所改、一体化改写、人设切换。新增p-coding语音输入代码、屏幕捕捉和专属词汇导入功能，免费提供2000积分（约28天使用时长），适用于高效办公与编程场景。\n\n**🔗 相关链接：**\n- <https://github.com/zai-org/GLM-TTS>\n- <https://huggingface.co/zai-org/GLM-TTS>\n- <https://audio.z.ai/>\n\n---\n\n### 10. 🔧 Google Pomelli引入动画功能 {#10-Google-Pomelli引入动画功能}\n\n**标签**： `Google Labs` `Pomelli`\n\nGoogle Labs为Pomelli引入animate功能，由VIVO 3.1模型支持，可将内容转换为符合品牌调性的动画。目前在美国、加拿大、澳大利亚和新西兰免费提供，适用于品牌内容创作、社交媒体营销等场景，提升内容表现力。\n\n**🔗 相关链接：**\n- <https://x.com/GoogleLabs/status/1998830445103054961>\n- <https://labs.google/pomelli>\n\n---\n\n### 11. 🔧 阿里开源Wan-Move视频模型 {#11-阿里开源Wan-Move视频模型}\n\n**标签**： `阿里通义实验室` `Wan-Move`\n\n阿里通义实验室开源Wan-Move视频生成框架，通过潜在轨迹引导实现细粒度运动控制，支持生成长达5秒、480P高质量视频。模型基于扩散架构，适用于广告、短视频、影视预演等场景，推动可控视频生成技术发展。\n\n**🔗 相关链接：**\n- <https://github.com/ali-vilab/Wan-Move>\n- <https://huggingface.co/Ruihang/Wan-Move-14B-480P>\n- <https://arxiv.org/abs/2512.08765>\n\n---\n\n### 12. 🚀 Motif发布12.7B推理模型 {#12-Motif发布127B推理模型}\n\n**标签**： `Motif Technologies` `Motif-2-12.7B`\n\nMotif Technologies发布Motif-2-12.7B-Reasoning模型，127亿参数开源推理模型，在Artificial Analysis智能指数中获45分，成为韩国领先AI模型。适用于复杂推理、数学计算、逻辑分析等任务，推动开源推理模型发展。\n\n**🔗 相关链接：**\n- <https://huggingface.co/Motif-Technologies/Motif-2-12.7B-Reasoning>\n- <https://huggingface.co/Motif-Technologies/Motif-2-12.7B-Base>\n\n---\n\n### 13. 🔧 南贝格开源Nanbeige4-3B模型 {#13-南贝格开源Nanbeige4-3B模型}\n\n**标签**： `南贝格` `Nanbeige4-3B`\n\n南贝格发布Nanbeige4-3B系列模型，包含Base和Thinking两种30亿参数变体。Base模型在多项基准测试中超越同规模及更大模型，Thinking版本在数学、工具使用及创意写作任务上达到新水平，适用于轻量化AI应用。\n\n**🔗 相关链接：**\n- <https://huggingface.co/Nanbeige/Nanbeige4-3B-Base>\n- <https://huggingface.co/Nanbeige/Nanbeige4-3B-Thinking-2511>\n\n---\n\n### 14. 🔧 thu-pacman发布PCMind-2.1模型 {#14-thu-pacman发布PCMind-21模型}\n\n**标签**： `thu-pacman` `PCMind-2.1`\n\nthu-pacman发布完全开源的PCMind-2.1-Kaiyuan-2B语言模型，20亿参数，在A3910A集群上使用2.2万亿token训练。模型权重、数据和代码均在Apache 2.0许可证下发布，适用于教育、研究等场景，推动开源生态发展。\n\n**🔗 相关链接：**\n- <https://arxiv.org/abs/2512.07612>\n- <https://huggingface.co/thu-pacman/PCMind-2.1-Kaiyuan-2B>\n- <https://huggingface.co/datasets/thu-pacman/PCMind-2.1-Kaiyuan-2B>\n\n---\n\n### 15. 🚀 Arcee AI发布Trinity Mini模型 {#15-Arcee-AI发布Trinity-Mini模型}\n\n**标签**： `Arcee AI` `Trinity Mini`\n\nArcee AI发布Trinity Mini模型，26B参数稀疏MoE模型，激活参数仅3B，拥有128个专家，基于10T Tokens训练，支持128K上下文。适用于长文本处理、复杂推理等场景，提升大模型部署效率。\n\n**🔗 相关链接：**\n- <https://clarifai.com/arcee_ai/AFM/models/trinity-mini>\n- <https://openrouter.ai/arcee-ai/trinity-mini>\n\n---\n\n### 16. 🔧 StarCloud卫星训练AI模型成功 {#16-StarCloud卫星训练AI模型成功}\n\n**标签**： `StarCloud` `NVIDIA H100` `Agent IDE`\n\n安迪亚支持的StarCloud宣布在StarCloud-1卫星上使用NVIDIA H100 GPU成功训练AI模型，运行Nano GPT和Google JAMA模型。集成Agent IDE，内置浏览器、Subway和Strip支持本地运行，具备聆听和录制功能，Agent可查看用户整个屏幕并支持鼠标手势指示，推动太空AI应用。\n\n---\n\n### 17. 🔧 Onsros AI发布新T内核 {#17-Onsros-AI发布新T内核}\n\n**标签**： `Onsros AI` `T内核`\n\nOnsros AI发布新T内核和智能自动打包技术，支持将LLM训练速度提升3~5倍，减少30%~90%微RAM使用且不损失准确性，支持低至3.9GB VRAM设备训练千万34B等模型，降低大模型训练门槛。\n\n---\n\n### 18. 🔧 Google推出Acts事实准确性基准 {#18-Google推出Acts事实准确性基准}\n\n**标签**： `Google DeepMind` `Acts` `Kaggle`\n\nGoogle DeepMind与Kaggle推出Acts基准测试套件，系统性评估LLM事实准确性，包含四个独立基准测试，覆盖内部知识、搜索工具使用、多模态理解及上下文依存回答，推动AI模型可靠性评估标准化。\n\n---\n\n### 19. 📈 Google推广Preferred Sources功能 {#19-Google推广Preferred-Sources功能}\n\n**标签**： `Google` `Preferred Sources`\n\nGoogle推出Preferred Sources功能，全球推广高质量付费内容，改进AI搜索链接展示，并与新闻出版商启动AI试点项目，支持网络生态系统发展，满足用户快速获取可信信息需求。\n\n**🔗 相关链接：**\n- <https://blog.google/technology/developers/gemini-2-5-text-to-speech/>\n- <https://blog.google/technology/developers/jules-proactive-updates/>\n- <https://x.com/GoogleLabs/status/1998830445103054961>\n\n---\n\n### 20. 📈 OpenAI加强网络安全准备 {#20-OpenAI加强网络安全准备}\n\n**标签**： `OpenAI` `网络安全`\n\nOpenAI加强网络安全准备，应对AI模型能力提升带来的双重用途风险。预计即将推出模型可能达到高水平网络安全能力，正在实施多层次保障措施，确保能力主要用于防御目的，防范AI滥用。\n\n---\n\n### 21. 📈 DeepMind训练下一代AI模型 {#21-DeepMind训练下一代AI模型}\n\n**标签**： `DeepMind` `Blackwell` `V4`\n\n据The Information报道，DeepMind正使用数千颗英伟达Blackwell芯片训练下一代主要模型。社交媒体消息称，DeepMind V4目标发布时间为2025年2月，推动AI算力与模型能力边界拓展。\n\n---\n\n### 22. 🔧 NVIDIA开发AI芯片定位技术 {#22-NVIDIA开发AI芯片定位技术}\n\n**标签**： `NVIDIA` `AI芯片定位`\n\nNVIDIA开发验证AI芯片物理位置的技术，通过测量与NVIDIA服务器通信时间延迟推断位置，不依赖GPS。该功能为可安装软件选项，帮助数据中心运营商监控GPU机群，响应美国政策要求，切断向中国非法出口高性能芯片。\n\n---\n\n### 23. 📈 亚马逊投资印度350亿美元 {#23-亚马逊投资印度350亿美元}\n\n**标签**： `亚马逊` `印度` `AI`\n\n亚马逊承诺未来5年在印度投资350亿美元，涵盖即时零售、云计算等领域，资金投向AI和物流基础设施，预计创造100万个就业岗位，推动印度数字经济发展。\n\n**🔗 相关链接：**\n- <https://github.com/zai-org/GLM-TTS>\n- <https://huggingface.co/zai-org/GLM-TTS>\n- <https://audio.z.ai/>\n\n---\n\n---\n\n## 🎬 视频链接\n\n**Bilibili**： <https://www.bilibili.com/video/BV1vmmKBhEDp>\n\n---\n\n*整理自橘鸦AI早报 | BV号：BV1vmmKBhEDp | 2025-12-11 09:05:36*"
}