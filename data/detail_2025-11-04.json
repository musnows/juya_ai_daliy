{
  "title": "Gemini CLI引入实验性Todo功能【AI 早报 2025-11-04】",
  "publish_date": "2025-11-04",
  "bv_id": "BV1zN1rBFEyV",
  "organize_time": "2025-11-22 20:38:39",
  "news_count": 8,
  "overview": "1. 🔧 Gemini CLI新增实验性Todo功能\n2. 🚀 百度网盘发布MCP服务器\n3. 🚀 通义千问发布Qwen3-Max-Thinking预览版\n4. 🔧 GitHub上线AI工具预算追踪功能\n5. 🔧 Gemini Docs MCP Server发布\n6. 📈 AWS与OpenAI达成多年战略合作\n7. 📈 Lambda与微软签署数十亿美元AI协议\n8. 📈 AI需求推动内存价格大幅上涨",
  "html_content": "<h2 id=\"_1\">📋 本期概览</h2>\n<ol>\n<li>🔧 Gemini CLI新增实验性Todo功能</li>\n<li>🚀 百度网盘发布MCP服务器</li>\n<li>🚀 通义千问发布Qwen3-Max-Thinking预览版</li>\n<li>🔧 GitHub上线AI工具预算追踪功能</li>\n<li>🔧 Gemini Docs MCP Server发布</li>\n<li>📈 AWS与OpenAI达成多年战略合作</li>\n<li>📈 Lambda与微软签署数十亿美元AI协议</li>\n<li>📈 AI需求推动内存价格大幅上涨</li>\n</ol>\n<hr />\n<h3 id=\"1-Gemini-CLI新增实验性Todo功能\">1. 🔧 Gemini CLI新增实验性Todo功能</h3>\n<p><strong>标签：</strong> <code>Gemini CLI</code> <code>Google</code></p>\n<p>Google的Gemini命令行界面（CLI）引入了实验性的Todo功能，允许用户通过自然语言指令管理待办事项。该功能目前处于早期测试阶段，支持创建、查看和标记任务完成状态，旨在提升开发者和高级用户在终端环境下的任务管理效率。尽管尚未集成至主版本，但此举表明Google正探索将AI助手能力进一步嵌入开发工作流。用户可通过特定命令调用Todo功能，未来有望与Google Calendar、Tasks等服务联动。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/JackWoth98/status/1985430754319364275\">https://x.com/JackWoth98/status/1985430754319364275</a><br />\n- <a href=\"https://x.com/_philschmid/status/1985363147071386048\">https://x.com/_philschmid/status/1985363147071386048</a></p>\n<hr />\n<h3 id=\"2-百度网盘发布MCP服务器\">2. 🚀 百度网盘发布MCP服务器</h3>\n<p><strong>标签：</strong> <code>百度网盘</code> <code>MCP服务器</code> <code>百度</code></p>\n<p>百度网盘正式开源其MCP（Model Context Protocol）服务器，项目托管于GitHub（baidu-netdisk/mcp），允许AI模型通过标准化接口访问和操作百度网盘中的文件。该MCP服务器支持文件上传、下载、列表查询、元数据获取等基础操作，为AI代理提供了与个人云存储交互的能力。此举是百度推动AI与本地数据融合的重要举措，有助于构建以用户数据为中心的智能应用生态，尤其适用于文档管理、自动化备份等场景。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://github.com/baidu-netdisk/mcp\">https://github.com/baidu-netdisk/mcp</a></p>\n<hr />\n<h3 id=\"3-通义千问发布Qwen3-Max-Thinking预览版\">3. 🚀 通义千问发布Qwen3-Max-Thinking预览版</h3>\n<p><strong>标签：</strong> <code>通义千问</code> <code>Qwen3-Max-Thinking</code> <code>阿里云</code></p>\n<p>阿里云通义千问团队发布Qwen3-Max-Thinking的早期预览版本，该模型专注于增强推理与思维链（Chain-of-Thought）能力，适用于复杂逻辑分析、数学推导和多步问题求解。Qwen3-Max-Thinking在内部测试中展现出优于前代模型的推理准确率和上下文理解深度，支持长文本输入与结构化输出。该版本目前面向开发者开放试用，标志着通义千问在推理型大模型领域的技术演进，未来将集成至阿里云AI平台及通义App等产品中。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://mp.weixin.qq.com/s/404k8cjngyou3ZcNVxgY9Q\">https://mp.weixin.qq.com/s/404k8cjngyou3ZcNVxgY9Q</a></p>\n<hr />\n<h3 id=\"4-GitHub上线AI工具预算追踪功能\">4. 🔧 GitHub上线AI工具预算追踪功能</h3>\n<p><strong>标签：</strong> <code>GitHub</code> <code>GitHub Copilot</code> <code>AI预算追踪</code></p>\n<p>GitHub推出AI工具预算追踪与控制功能，企业用户可为其GitHub Copilot、Codespaces等AI服务设置月度支出预算，并实时监控使用情况。该功能支持按组织、团队或项目维度分配预算，超出限额时将自动限制AI功能访问。此外，GitHub还推出AI控制权限委派机制，允许企业管理员将AI策略管理权下放至指定成员，并增强Copilot策略对IDE中Agent模式的支持。这些更新旨在提升企业在规模化使用AI工具时的成本可控性与治理灵活性，响应日益增长的AI支出管理需求。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://github.blog/changelog/2025-11-03-control-ai-spending-with-budget-tracking-for-github-ai-tools/\">https://github.blog/changelog/2025-11-03-control-ai-spending-with-budget-tracking-for-github-ai-tools/</a><br />\n- <a href=\"https://github.blog/changelog/2025-11-03-delegate-ai-controls-management-to-members-of-your-enterprise/\">https://github.blog/changelog/2025-11-03-delegate-ai-controls-management-to-members-of-your-enterprise/</a><br />\n- <a href=\"https://github.blog/changelog/2025-11-03-github-copilot-policy-now-supports-agent-mode-in-the-ide/\">https://github.blog/changelog/2025-11-03-github-copilot-policy-now-supports-agent-mode-in-the-ide/</a></p>\n<hr />\n<h3 id=\"5-Gemini-Docs-MCP-Server发布\">5. 🔧 Gemini Docs MCP Server发布</h3>\n<p><strong>标签：</strong> <code>Gemini Docs MCP Server</code> <code>Google Gemini</code> <code>MCP</code></p>\n<p>开发者社区发布Gemini Docs MCP Server，允许AI模型通过Model Context Protocol访问Google Gemini官方文档。该服务器由社区成员维护，支持检索API参考、使用指南、最佳实践等文档内容，为开发者提供实时、结构化的文档查询能力。集成后，AI代理可在编码过程中自动获取Gemini API的最新信息，减少上下文切换，提升开发效率。该工具适用于构建基于Gemini的自动化开发助手或知识问答系统。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/JackWoth98/status/1985430754319364275\">https://x.com/JackWoth98/status/1985430754319364275</a><br />\n- <a href=\"https://github.com/baidu-netdisk/mcp\">https://github.com/baidu-netdisk/mcp</a><br />\n- <a href=\"https://x.com/_philschmid/status/1985363147071386048\">https://x.com/_philschmid/status/1985363147071386048</a></p>\n<hr />\n<h3 id=\"6-AWS与OpenAI达成多年战略合作\">6. 📈 AWS与OpenAI达成多年战略合作</h3>\n<p><strong>标签：</strong> <code>AWS</code> <code>OpenAI</code> <code>Trainium</code></p>\n<p>AWS与OpenAI宣布达成多年战略合作协议，OpenAI将利用AWS的云计算基础设施（包括Trainium和Inferentia芯片）训练和部署其大模型。AWS将成为OpenAI的关键云基础设施合作伙伴，支持其AI研发与全球服务扩展。双方还将合作优化AI工作负载在AWS上的性能与能效，并探索联合解决方案面向企业客户。此次合作标志着OpenAI在多云战略中深化与AWS的绑定，同时强化AWS在AI基础设施领域的领先地位。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://openai.com/index/aws-and-openai-partnership/\">https://openai.com/index/aws-and-openai-partnership/</a><br />\n- <a href=\"https://www.aboutamazon.com/news/aws/aws-open-ai-workloads-compute-infrastructure\">https://www.aboutamazon.com/news/aws/aws-open-ai-workloads-compute-infrastructure</a></p>\n<hr />\n<h3 id=\"7-Lambda与微软签署数十亿美元AI协议\">7. 📈 Lambda与微软签署数十亿美元AI协议</h3>\n<p><strong>标签：</strong> <code>Lambda</code> <code>Microsoft</code> <code>AI基础设施</code></p>\n<p>AI基础设施公司Lambda与微软达成一项价值数十亿美元的多年期协议，为微软提供高性能计算资源以支持其AI训练与推理需求。Lambda将部署其专有GPU集群，用于加速微软Azure上的AI工作负载，涵盖大模型训练、推理服务与AI应用开发。该协议凸显了AI公司对专用计算资源的巨大需求，也反映了Lambda在AI基础设施市场的快速崛起。此前微软还宣布与澳大利亚IREN公司签署97亿美元协议，进一步扩展其全球AI云容量布局。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://techcrunch.com/2025/11/03/lambda-inks-multi-billion-dollar-ai-infrastructure-deal-with-microsoft/\">https://techcrunch.com/2025/11/03/lambda-inks-multi-billion-dollar-ai-infrastructure-deal-with-microsoft/</a><br />\n- <a href=\"https://techcrunch.com/2025/11/03/microsoft-inks-9-7bil-deal-with-australias-iren-for-ai-cloud-capacity/\">https://techcrunch.com/2025/11/03/microsoft-inks-9-7bil-deal-with-australias-iren-for-ai-cloud-capacity/</a></p>\n<hr />\n<h3 id=\"8-AI需求推动内存价格大幅上涨\">8. 📈 AI需求推动内存价格大幅上涨</h3>\n<p><strong>标签：</strong> <code>HBM</code> <code>AI服务器</code> <code>内存价格</code></p>\n<p>受AI服务器和大模型训练需求激增影响，全球内存市场价格出现显著上涨。据IT之家报道，HBM（高带宽内存）和DDR5内存价格在过去数月内持续攀升，部分型号涨幅超过30%。AI芯片（如NVIDIA H100、B100）对HBM的高依赖导致供需紧张，三星、SK海力士等厂商产能满载。内存价格上涨将直接影响AI硬件成本，可能传导至云服务定价，对AI初创企业和中小厂商构成成本压力，同时加速行业对内存技术（如HBM4、CXL）的投资。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://www.ithome.com/0/894/577.htm\">https://www.ithome.com/0/894/577.htm</a></p>\n<hr />\n<hr />\n<h2 id=\"_2\">🎬 视频链接</h2>\n<p><strong>Bilibili</strong>： <a href=\"https://www.bilibili.com/video/BV1zN1rBFEyV\">https://www.bilibili.com/video/BV1zN1rBFEyV</a></p>\n<hr />\n<p><em>整理自橘鸦AI早报 | BV号：BV1zN1rBFEyV | 2025-11-22 20:38:39</em></p>",
  "content": "# Gemini CLI引入实验性Todo功能【AI 早报 2025-11-04】\n\n**📅 发布日期：** 2025-11-04\n**🎬 BV号：** BV1zN1rBFEyV\n**📝 整理时间：** 2025-11-22 20:38:39\n**📊 资讯数量：** 8 条\n\n---\n\n## 📋 本期概览\n\n1. 🔧 Gemini CLI新增实验性Todo功能\n2. 🚀 百度网盘发布MCP服务器\n3. 🚀 通义千问发布Qwen3-Max-Thinking预览版\n4. 🔧 GitHub上线AI工具预算追踪功能\n5. 🔧 Gemini Docs MCP Server发布\n6. 📈 AWS与OpenAI达成多年战略合作\n7. 📈 Lambda与微软签署数十亿美元AI协议\n8. 📈 AI需求推动内存价格大幅上涨\n\n---\n\n### 1. 🔧 Gemini CLI新增实验性Todo功能 {#1-Gemini-CLI新增实验性Todo功能}\n\n**标签：** `Gemini CLI` `Google`\n\nGoogle的Gemini命令行界面（CLI）引入了实验性的Todo功能，允许用户通过自然语言指令管理待办事项。该功能目前处于早期测试阶段，支持创建、查看和标记任务完成状态，旨在提升开发者和高级用户在终端环境下的任务管理效率。尽管尚未集成至主版本，但此举表明Google正探索将AI助手能力进一步嵌入开发工作流。用户可通过特定命令调用Todo功能，未来有望与Google Calendar、Tasks等服务联动。\n\n**🔗 相关链接：**\n- <https://x.com/JackWoth98/status/1985430754319364275>\n- <https://x.com/_philschmid/status/1985363147071386048>\n\n---\n\n### 2. 🚀 百度网盘发布MCP服务器 {#2-百度网盘发布MCP服务器}\n\n**标签：** `百度网盘` `MCP服务器` `百度`\n\n百度网盘正式开源其MCP（Model Context Protocol）服务器，项目托管于GitHub（baidu-netdisk/mcp），允许AI模型通过标准化接口访问和操作百度网盘中的文件。该MCP服务器支持文件上传、下载、列表查询、元数据获取等基础操作，为AI代理提供了与个人云存储交互的能力。此举是百度推动AI与本地数据融合的重要举措，有助于构建以用户数据为中心的智能应用生态，尤其适用于文档管理、自动化备份等场景。\n\n**🔗 相关链接：**\n- <https://github.com/baidu-netdisk/mcp>\n\n---\n\n### 3. 🚀 通义千问发布Qwen3-Max-Thinking预览版 {#3-通义千问发布Qwen3-Max-Thinking预览版}\n\n**标签：** `通义千问` `Qwen3-Max-Thinking` `阿里云`\n\n阿里云通义千问团队发布Qwen3-Max-Thinking的早期预览版本，该模型专注于增强推理与思维链（Chain-of-Thought）能力，适用于复杂逻辑分析、数学推导和多步问题求解。Qwen3-Max-Thinking在内部测试中展现出优于前代模型的推理准确率和上下文理解深度，支持长文本输入与结构化输出。该版本目前面向开发者开放试用，标志着通义千问在推理型大模型领域的技术演进，未来将集成至阿里云AI平台及通义App等产品中。\n\n**🔗 相关链接：**\n- <https://mp.weixin.qq.com/s/404k8cjngyou3ZcNVxgY9Q>\n\n---\n\n### 4. 🔧 GitHub上线AI工具预算追踪功能 {#4-GitHub上线AI工具预算追踪功能}\n\n**标签：** `GitHub` `GitHub Copilot` `AI预算追踪`\n\nGitHub推出AI工具预算追踪与控制功能，企业用户可为其GitHub Copilot、Codespaces等AI服务设置月度支出预算，并实时监控使用情况。该功能支持按组织、团队或项目维度分配预算，超出限额时将自动限制AI功能访问。此外，GitHub还推出AI控制权限委派机制，允许企业管理员将AI策略管理权下放至指定成员，并增强Copilot策略对IDE中Agent模式的支持。这些更新旨在提升企业在规模化使用AI工具时的成本可控性与治理灵活性，响应日益增长的AI支出管理需求。\n\n**🔗 相关链接：**\n- <https://github.blog/changelog/2025-11-03-control-ai-spending-with-budget-tracking-for-github-ai-tools/>\n- <https://github.blog/changelog/2025-11-03-delegate-ai-controls-management-to-members-of-your-enterprise/>\n- <https://github.blog/changelog/2025-11-03-github-copilot-policy-now-supports-agent-mode-in-the-ide/>\n\n---\n\n### 5. 🔧 Gemini Docs MCP Server发布 {#5-Gemini-Docs-MCP-Server发布}\n\n**标签：** `Gemini Docs MCP Server` `Google Gemini` `MCP`\n\n开发者社区发布Gemini Docs MCP Server，允许AI模型通过Model Context Protocol访问Google Gemini官方文档。该服务器由社区成员维护，支持检索API参考、使用指南、最佳实践等文档内容，为开发者提供实时、结构化的文档查询能力。集成后，AI代理可在编码过程中自动获取Gemini API的最新信息，减少上下文切换，提升开发效率。该工具适用于构建基于Gemini的自动化开发助手或知识问答系统。\n\n**🔗 相关链接：**\n- <https://x.com/JackWoth98/status/1985430754319364275>\n- <https://github.com/baidu-netdisk/mcp>\n- <https://x.com/_philschmid/status/1985363147071386048>\n\n---\n\n### 6. 📈 AWS与OpenAI达成多年战略合作 {#6-AWS与OpenAI达成多年战略合作}\n\n**标签：** `AWS` `OpenAI` `Trainium`\n\nAWS与OpenAI宣布达成多年战略合作协议，OpenAI将利用AWS的云计算基础设施（包括Trainium和Inferentia芯片）训练和部署其大模型。AWS将成为OpenAI的关键云基础设施合作伙伴，支持其AI研发与全球服务扩展。双方还将合作优化AI工作负载在AWS上的性能与能效，并探索联合解决方案面向企业客户。此次合作标志着OpenAI在多云战略中深化与AWS的绑定，同时强化AWS在AI基础设施领域的领先地位。\n\n**🔗 相关链接：**\n- <https://openai.com/index/aws-and-openai-partnership/>\n- <https://www.aboutamazon.com/news/aws/aws-open-ai-workloads-compute-infrastructure>\n\n---\n\n### 7. 📈 Lambda与微软签署数十亿美元AI协议 {#7-Lambda与微软签署数十亿美元AI协议}\n\n**标签：** `Lambda` `Microsoft` `AI基础设施`\n\nAI基础设施公司Lambda与微软达成一项价值数十亿美元的多年期协议，为微软提供高性能计算资源以支持其AI训练与推理需求。Lambda将部署其专有GPU集群，用于加速微软Azure上的AI工作负载，涵盖大模型训练、推理服务与AI应用开发。该协议凸显了AI公司对专用计算资源的巨大需求，也反映了Lambda在AI基础设施市场的快速崛起。此前微软还宣布与澳大利亚IREN公司签署97亿美元协议，进一步扩展其全球AI云容量布局。\n\n**🔗 相关链接：**\n- <https://techcrunch.com/2025/11/03/lambda-inks-multi-billion-dollar-ai-infrastructure-deal-with-microsoft/>\n- <https://techcrunch.com/2025/11/03/microsoft-inks-9-7bil-deal-with-australias-iren-for-ai-cloud-capacity/>\n\n---\n\n### 8. 📈 AI需求推动内存价格大幅上涨 {#8-AI需求推动内存价格大幅上涨}\n\n**标签：** `HBM` `AI服务器` `内存价格`\n\n受AI服务器和大模型训练需求激增影响，全球内存市场价格出现显著上涨。据IT之家报道，HBM（高带宽内存）和DDR5内存价格在过去数月内持续攀升，部分型号涨幅超过30%。AI芯片（如NVIDIA H100、B100）对HBM的高依赖导致供需紧张，三星、SK海力士等厂商产能满载。内存价格上涨将直接影响AI硬件成本，可能传导至云服务定价，对AI初创企业和中小厂商构成成本压力，同时加速行业对内存技术（如HBM4、CXL）的投资。\n\n**🔗 相关链接：**\n- <https://www.ithome.com/0/894/577.htm>\n\n---\n\n---\n\n## 🎬 视频链接\n\n**Bilibili**： <https://www.bilibili.com/video/BV1zN1rBFEyV>\n\n---\n\n*整理自橘鸦AI早报 | BV号：BV1zN1rBFEyV | 2025-11-22 20:38:39*"
}