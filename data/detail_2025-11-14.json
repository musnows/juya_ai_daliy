{
  "title": "Gemini 3 现身 Gemini APP 的 Canvas 功能 【AI 早报 2025-11-14】",
  "publish_date": "2025-11-14",
  "bv_id": "BV1G5CPBrEmd",
  "organize_time": "2025-11-22 20:35:31",
  "news_count": 17,
  "overview": "1. 🚀 Google DeepMind发布SIMA 2智能体\n2. 🚀 Lumine发布3D开放世界通用智能体\n3. 🚀 百度发布文心大模型5.0\n4. 🚀 OpenAI上线GPT-5.1模型API\n5. 🔧 Codex发布0.58.0支持GPT-5.1模型\n6. 🚀 OpenAI发布Apps SDK预览版\n7. 🔧 Gemini 3或上线Canvas功能\n8. 🔧 Google发布Gemini Live重大更新\n9. 🔧 Google升级Gemini CLI用户体验\n10. 🔧 NotebookLM推出Deep Research功能\n11. 📈 Google更新AI搜索购物体验\n12. 🚀 Anthropic扩展Claude Code网页版\n13. 🔧 VS Code发布1.106集成Agent管理\n14. 🔧 Qwen发布DeepResearch 2511升级\n15. 📈 阿里云调整通义千问3-Max价格\n16. 🚀 H Company发布Holo2模型系列\n17. 🚀 JanHQ发布Jan-v2-VL多模态Agent模型",
  "html_content": "<h2 id=\"_1\">📋 本期概览</h2>\n<ol>\n<li>🚀 Google DeepMind发布SIMA 2智能体</li>\n<li>🚀 Lumine发布3D开放世界通用智能体</li>\n<li>🚀 百度发布文心大模型5.0</li>\n<li>🚀 OpenAI上线GPT-5.1模型API</li>\n<li>🔧 Codex发布0.58.0支持GPT-5.1模型</li>\n<li>🚀 OpenAI发布Apps SDK预览版</li>\n<li>🔧 Gemini 3或上线Canvas功能</li>\n<li>🔧 Google发布Gemini Live重大更新</li>\n<li>🔧 Google升级Gemini CLI用户体验</li>\n<li>🔧 NotebookLM推出Deep Research功能</li>\n<li>📈 Google更新AI搜索购物体验</li>\n<li>🚀 Anthropic扩展Claude Code网页版</li>\n<li>🔧 VS Code发布1.106集成Agent管理</li>\n<li>🔧 Qwen发布DeepResearch 2511升级</li>\n<li>📈 阿里云调整通义千问3-Max价格</li>\n<li>🚀 H Company发布Holo2模型系列</li>\n<li>🚀 JanHQ发布Jan-v2-VL多模态Agent模型</li>\n</ol>\n<hr />\n<h3 id=\"1-Google-DeepMind发布SIMA-2智能体\">1. 🚀 Google DeepMind发布SIMA 2智能体</h3>\n<p><strong>标签：</strong> <code>Google DeepMind</code> <code>SIMA 2</code> <code>虚拟3D世界</code></p>\n<p>Google DeepMind于近日发布SIMA 2（Scalable Instructable Multiworld Agent 2），一款可在虚拟3D世界中与人类协同操作、推理并持续学习的通用智能体。该智能体支持多环境交互，具备任务理解、自然语言指令执行和实时反馈学习能力，能够在复杂3D场景中进行导航、操作物体和协作决策。SIMA 2通过强化学习与模仿学习结合的方式，在多个虚拟世界中实现跨域泛化，标志着AI在具身智能（Embodied AI）方向的重要进展。其潜在应用包括虚拟助手、游戏AI、机器人仿真训练和交互式教育平台。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/\">https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/</a><br />\n- <a href=\"https://blog.google/technology/google-labs/notebooklm-deep-research-file-types/\">https://blog.google/technology/google-labs/notebooklm-deep-research-file-types/</a><br />\n- <a href=\"https://x.com/NotebookLM/status/1989099764764283224\">https://x.com/NotebookLM/status/1989099764764283224</a></p>\n<hr />\n<h3 id=\"2-Lumine发布3D开放世界通用智能体\">2. 🚀 Lumine发布3D开放世界通用智能体</h3>\n<p><strong>标签：</strong> <code>Lumine</code> <code>3D开放世界</code> <code>通用智能体</code></p>\n<p>Lumine团队推出面向3D开放世界环境的通用智能体，旨在实现跨游戏、仿真平台的高自由度自主行为。该智能体支持多模态输入（视觉、语音、文本），具备环境理解、任务规划和长期记忆能力，可在无监督或弱监督条件下学习复杂交互行为。其架构支持插件式扩展，适用于元宇宙、数字孪生、虚拟训练等场景。Lumine强调其智能体具备‘与人类共玩’（play with you）的能力，推动人机协作智能的发展。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://www.lumine-ai.org/\">https://www.lumine-ai.org/</a></p>\n<hr />\n<h3 id=\"3-百度发布文心大模型50\">3. 🚀 百度发布文心大模型5.0</h3>\n<p><strong>标签：</strong> <code>百度</code> <code>文心大模型5.0</code> <code>ERNIE</code></p>\n<p>百度正式发布文心大模型5.0（ERNIE 5.0），在语言理解、逻辑推理、多轮对话和代码生成能力上实现显著提升。新版本采用更高效的稀疏架构与混合专家（MoE）技术，支持更长上下文窗口（最高达128K tokens），并优化了中文语义理解与生成质量。文心5.0已在百度搜索、智能云、小度助手等产品中部署，助力企业智能化升级。其推理效率较前代提升约30%，在多项中文NLP基准测试中保持领先。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://zhidx.com/p/514799.html\">https://zhidx.com/p/514799.html</a></p>\n<hr />\n<h3 id=\"4-OpenAI上线GPT-51模型API\">4. 🚀 OpenAI上线GPT-5.1模型API</h3>\n<p><strong>标签：</strong> <code>OpenAI</code> <code>GPT-5.1</code> <code>API</code></p>\n<p>OpenAI正式向开发者开放GPT-5.1系列模型的API访问权限，标志着其大模型迭代进入新阶段。GPT-5.1在推理能力、指令遵循精度和长文本处理方面较GPT-5.0有明显提升，支持最大128K上下文窗口，并优化了多轮对话的连贯性与安全性。官方同步发布《GPT-5.1 Prompting Guide》，提供结构化提示工程最佳实践。该模型适用于复杂问答、内容创作、代码生成和自动化决策等场景，进一步巩固OpenAI在生成式AI领域的领先地位。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://openai.com/index/gpt-5-1-for-developers/\">https://openai.com/index/gpt-5-1-for-developers/</a><br />\n- <a href=\"https://cookbook.openai.com/examples/gpt-5/gpt-5.1_prompting_guide\">https://cookbook.openai.com/examples/gpt-5/gpt-5.1_prompting_guide</a><br />\n- <a href=\"https://github.com/openai/codex/releases/tag/rust-v0.58.0\">https://github.com/openai/codex/releases/tag/rust-v0.58.0</a></p>\n<hr />\n<h3 id=\"5-Codex发布0580支持GPT-51模型\">5. 🔧 Codex发布0.58.0支持GPT-5.1模型</h3>\n<p><strong>标签：</strong> <code>Codex</code> <code>GPT-5.1</code> <code>OpenAI</code></p>\n<p>OpenAI开源项目Codex发布Rust版本v0.58.0，正式集成对GPT-5.1系列模型的支持。该版本优化了模型调用接口、错误处理机制和异步执行性能，支持在本地或边缘环境中部署GPT-5.1推理服务。更新还包含新的代码补全策略、上下文缓存机制和安全性过滤模块，适用于IDE插件、自动化编程助手和CI/CD集成场景。Codex作为OpenAI生态的重要工具链，进一步降低了开发者使用前沿大模型的门槛。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://openai.com/index/gpt-5-1-for-developers/\">https://openai.com/index/gpt-5-1-for-developers/</a><br />\n- <a href=\"https://cookbook.openai.com/examples/gpt-5/gpt-5.1_prompting_guide\">https://cookbook.openai.com/examples/gpt-5/gpt-5.1_prompting_guide</a><br />\n- <a href=\"https://github.com/openai/codex/releases/tag/rust-v0.58.0\">https://github.com/openai/codex/releases/tag/rust-v0.58.0</a></p>\n<hr />\n<h3 id=\"6-OpenAI发布Apps-SDK预览版\">6. 🚀 OpenAI发布Apps SDK预览版</h3>\n<p><strong>标签：</strong> <code>OpenAI</code> <code>Apps SDK</code> <code>GPT模型</code></p>\n<p>OpenAI推出Apps SDK预览版，允许开发者使用Python和TypeScript构建可调用GPT模型的原生应用。SDK提供身份认证、权限管理、模型调用、日志记录和用户反馈收集等核心模块，支持快速集成到Web、移动端和桌面应用中。该工具旨在简化AI应用开发流程，推动GPT模型在垂直领域的落地，如教育、医疗、客服等。预览版已开放注册，未来将支持更多部署模式和商业化选项。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://openai.com/index/gpt-5-1-for-developers/\">https://openai.com/index/gpt-5-1-for-developers/</a><br />\n- <a href=\"https://cookbook.openai.com/examples/gpt-5/gpt-5.1_prompting_guide\">https://cookbook.openai.com/examples/gpt-5/gpt-5.1_prompting_guide</a><br />\n- <a href=\"https://developers.openai.com/apps-sdk/\">https://developers.openai.com/apps-sdk/</a></p>\n<hr />\n<h3 id=\"7-Gemini-3或上线Canvas功能\">7. 🔧 Gemini 3或上线Canvas功能</h3>\n<p><strong>标签：</strong> <code>Google</code> <code>Gemini 3</code> <code>Canvas</code></p>\n<p>据TestingCatalog报道，Google正在为Gemini App测试名为Canvas的新功能，可能基于Gemini 3模型构建。该功能允许用户通过自然语言指令生成可视化内容，如图表、流程图、代码结构图等，并支持实时编辑与导出。Canvas强调‘创意表达’，旨在提升用户在内容创作、项目规划和知识整理中的效率。若正式推出，将增强Gemini在多模态交互领域的竞争力。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/\">https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/</a><br />\n- <a href=\"https://www.testingcatalog.com/google-prepares-creative-canvas-mode-for-release/\">https://www.testingcatalog.com/google-prepares-creative-canvas-mode-for-release/</a><br />\n- <a href=\"https://x.com/GeminiApp/status/1988755100412834151\">https://x.com/GeminiApp/status/1988755100412834151</a></p>\n<hr />\n<h3 id=\"8-Google发布Gemini-Live重大更新\">8. 🔧 Google发布Gemini Live重大更新</h3>\n<p><strong>标签：</strong> <code>Google</code> <code>Gemini Live</code> <code>语音交互</code></p>\n<p>Google通过官方渠道宣布Gemini Live迎来重大更新，重点优化实时语音交互体验。新版本支持更自然的对话节奏、上下文记忆增强和背景噪音抑制，可在移动设备上实现低延迟的连续对话。更新还引入多语言混合输入识别和个性化响应风格设置，提升跨语言用户的使用体验。Gemini Live作为Google AI助手战略的核心组件，正逐步向多模态、个性化方向演进。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/\">https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/</a><br />\n- <a href=\"https://x.com/GeminiApp/status/1988755100412834151\">https://x.com/GeminiApp/status/1988755100412834151</a><br />\n- <a href=\"https://developers.googleblog.com/en/making-the-terminal-beautiful-one-pixel-at-a-time/\">https://developers.googleblog.com/en/making-the-terminal-beautiful-one-pixel-at-a-time/</a></p>\n<hr />\n<h3 id=\"9-Google升级Gemini-CLI用户体验\">9. 🔧 Google升级Gemini CLI用户体验</h3>\n<p><strong>标签：</strong> <code>Google</code> <code>Gemini CLI</code> <code>开发者工具</code></p>\n<p>Google发布Gemini命令行界面（CLI）的重大用户体验升级，引入彩色输出、语法高亮、进度条和交互式提示等可视化元素。新设计采用现代终端美学，支持自定义主题和快捷键，显著提升开发者在终端中使用Gemini进行代码生成、调试和文档查询的效率。该更新体现了Google对开发者工具链的持续投入，推动AI在命令行环境中的深度集成。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/\">https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/</a><br />\n- <a href=\"https://x.com/GeminiApp/status/1988755100412834151\">https://x.com/GeminiApp/status/1988755100412834151</a><br />\n- <a href=\"https://developers.googleblog.com/en/making-the-terminal-beautiful-one-pixel-at-a-time/\">https://developers.googleblog.com/en/making-the-terminal-beautiful-one-pixel-at-a-time/</a></p>\n<hr />\n<h3 id=\"10-NotebookLM推出Deep-Research功能\">10. 🔧 NotebookLM推出Deep Research功能</h3>\n<p><strong>标签：</strong> <code>Google</code> <code>NotebookLM</code> <code>Deep Research</code></p>\n<p>Google NotebookLM发布重大更新，新增Deep Research功能，支持用户上传PDF、DOCX、TXT等文件类型，并自动生成深度分析报告。该功能可跨文档提取关键信息、构建知识图谱、生成引用摘要，并提供多轮追问能力。同时，NotebookLM引入自定义视频风格选项，允许用户选择不同视觉模板生成讲解视频。此次升级强化了其在学术研究、企业情报和知识管理中的应用价值。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/\">https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/</a><br />\n- <a href=\"https://x.com/GeminiApp/status/1988755100412834151\">https://x.com/GeminiApp/status/1988755100412834151</a><br />\n- <a href=\"https://developers.googleblog.com/en/making-the-terminal-beautiful-one-pixel-at-a-time/\">https://developers.googleblog.com/en/making-the-terminal-beautiful-one-pixel-at-a-time/</a></p>\n<hr />\n<h3 id=\"11-Google更新AI搜索购物体验\">11. 📈 Google更新AI搜索购物体验</h3>\n<p><strong>标签：</strong> <code>Google</code> <code>AI搜索</code> <code>Gemini</code></p>\n<p>Google宣布升级其AI驱动的搜索购物体验，利用Gemini模型优化商品推荐、价格比较和用户评论分析。新系统支持自然语言查询（如‘适合油性皮肤的平价面霜’），并生成结构化结果，包含产品对比、用户评分、成分分析和购买链接。该更新旨在提升电商搜索的精准度与转化率，推动AI在零售场景中的商业化落地。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/\">https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/</a><br />\n- <a href=\"https://www.testingcatalog.com/google-prepares-creative-canvas-mode-for-release/\">https://www.testingcatalog.com/google-prepares-creative-canvas-mode-for-release/</a><br />\n- <a href=\"https://x.com/GeminiApp/status/1988755100412834151\">https://x.com/GeminiApp/status/1988755100412834151</a></p>\n<hr />\n<h3 id=\"12-Anthropic扩展Claude-Code网页版\">12. 🚀 Anthropic扩展Claude Code网页版</h3>\n<p><strong>标签：</strong> <code>Anthropic</code> <code>Claude Code</code> <code>企业计划</code></p>\n<p>Anthropic宣布Claude Code网页版已扩展至团队和企业计划用户，支持多人协作、权限管理和企业级安全策略。该工具允许开发者通过自然语言指令执行代码生成、调试、测试和部署任务，集成Git工作流和CI/CD管道。网页版提供实时协作编辑、任务分配和审计日志功能，助力企业实现AI驱动的软件开发流程自动化。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/claudeai/status/1988737589130747906\">https://x.com/claudeai/status/1988737589130747906</a></p>\n<hr />\n<h3 id=\"13-VS-Code发布1106集成Agent管理\">13. 🔧 VS Code发布1.106集成Agent管理</h3>\n<p><strong>标签：</strong> <code>VS Code</code> <code>Copilot</code> <code>Agent管理</code></p>\n<p>Visual Studio Code发布v1.106版本，新增Copilot Agent任务管理视图，支持开发者创建、监控和终止AI代理任务。新界面提供任务状态、执行日志、资源占用和响应延迟等可视化指标，优化AI辅助编程的透明度和可控性。该功能与GitHub Copilot深度集成，适用于复杂项目中的多代理协作场景，提升开发效率与代码质量。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://github.blog/changelog/2025-11-13-manage-copilot-coding-agent-tasks-in-visual-studio-code\">https://github.blog/changelog/2025-11-13-manage-copilot-coding-agent-tasks-in-visual-studio-code</a><br />\n- <a href=\"https://x.com/code/status/1988973703141740913\">https://x.com/code/status/1988973703141740913</a></p>\n<hr />\n<h3 id=\"14-Qwen发布DeepResearch-2511升级\">14. 🔧 Qwen发布DeepResearch 2511升级</h3>\n<p><strong>标签：</strong> <code>Qwen</code> <code>DeepResearch</code> <code>阿里云</code></p>\n<p>阿里云Qwen团队发布DeepResearch功能2511版本升级，增强其长文本分析、多源信息整合和逻辑推理能力。新版本支持最大256K上下文窗口，可处理PDF、网页、数据库等多种数据源，并生成带引用标注的研究报告。升级还优化了中文语义理解与领域知识检索，适用于金融、法律、科研等专业场景。用户可通过chat.qwen.ai直接体验该功能。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://qwen.ai/blog?id=qwen-deepresearch\">https://qwen.ai/blog?id=qwen-deepresearch</a><br />\n- <a href=\"https://chat.qwen.ai/?inputFeature=deep_research\">https://chat.qwen.ai/?inputFeature=deep_research</a><br />\n- <a href=\"https://linux.do/t/topic/1167502\">https://linux.do/t/topic/1167502</a></p>\n<hr />\n<h3 id=\"15-阿里云调整通义千问3-Max价格\">15. 📈 阿里云调整通义千问3-Max价格</h3>\n<p><strong>标签：</strong> <code>阿里云</code> <code>通义千问3-Max</code> <code>百炼平台</code></p>\n<p>阿里云百炼平台调整通义千问3-Max（Qwen3-Max）模型的API调用价格，具体调整幅度未公开，但社区讨论显示推理成本有所优化。此次调价可能旨在提升模型在中小企业和开发者中的可及性，增强其在中文大模型市场的竞争力。Qwen3-Max作为阿里云旗舰模型，支持多模态输入与复杂任务处理，广泛应用于智能客服、内容生成和数据分析等领域。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://linux.do/t/topic/1167502\">https://linux.do/t/topic/1167502</a></p>\n<hr />\n<h3 id=\"16-H-Company发布Holo2模型系列\">16. 🚀 H Company发布Holo2模型系列</h3>\n<p><strong>标签：</strong> <code>H Company</code> <code>Holo2</code> <code>多模态模型</code></p>\n<p>H Company发布Holo2系列大模型，包含多个参数规模的变体，支持文本、图像、音频多模态输入与生成。该系列采用新型混合架构，强调在3D内容生成、虚拟角色交互和空间理解方面的能力。Holo2在Hugging Face上开源部分模型，支持本地部署与微调，适用于元宇宙、数字人、AR/VR等前沿应用场景。其发布标志着新兴AI公司在多模态智能体领域的布局加速。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://www.hcompany.ai/blog/holo2\">https://www.hcompany.ai/blog/holo2</a><br />\n- <a href=\"https://huggingface.co/collections/Hcompany/holo2\">https://huggingface.co/collections/Hcompany/holo2</a></p>\n<hr />\n<h3 id=\"17-JanHQ发布Jan-v2-VL多模态Agent模型\">17. 🚀 JanHQ发布Jan-v2-VL多模态Agent模型</h3>\n<p><strong>标签：</strong> <code>JanHQ</code> <code>Jan-v2-VL</code> <code>多模态Agent</code></p>\n<p>JanHQ发布Jan-v2-VL系列多模态Agent模型，支持图像理解、文本生成和跨模态推理。该模型可在本地设备上运行，强调隐私保护与低延迟响应，适用于个人助手、教育辅导和智能设备控制等场景。Jan-v2-VL在Hugging Face上提供多个版本，支持ONNX和TensorRT加速，推动轻量化AI在边缘计算中的落地。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://huggingface.co/collections/janhq/jan-v2-vl\">https://huggingface.co/collections/janhq/jan-v2-vl</a></p>\n<hr />\n<hr />\n<h2 id=\"_2\">🎬 视频链接</h2>\n<p><strong>Bilibili</strong>： <a href=\"https://www.bilibili.com/video/BV1G5CPBrEmd\">https://www.bilibili.com/video/BV1G5CPBrEmd</a></p>\n<hr />\n<p><em>整理自橘鸦AI早报 | BV号：BV1G5CPBrEmd | 2025-11-22 20:35:31</em></p>",
  "content": "# Gemini 3 现身 Gemini APP 的 Canvas 功能 【AI 早报 2025-11-14】\n\n**📅 发布日期：** 2025-11-14\n**🎬 BV号：** BV1G5CPBrEmd\n**📝 整理时间：** 2025-11-22 20:35:31\n**📊 资讯数量：** 17 条\n\n---\n\n## 📋 本期概览\n\n1. 🚀 Google DeepMind发布SIMA 2智能体\n2. 🚀 Lumine发布3D开放世界通用智能体\n3. 🚀 百度发布文心大模型5.0\n4. 🚀 OpenAI上线GPT-5.1模型API\n5. 🔧 Codex发布0.58.0支持GPT-5.1模型\n6. 🚀 OpenAI发布Apps SDK预览版\n7. 🔧 Gemini 3或上线Canvas功能\n8. 🔧 Google发布Gemini Live重大更新\n9. 🔧 Google升级Gemini CLI用户体验\n10. 🔧 NotebookLM推出Deep Research功能\n11. 📈 Google更新AI搜索购物体验\n12. 🚀 Anthropic扩展Claude Code网页版\n13. 🔧 VS Code发布1.106集成Agent管理\n14. 🔧 Qwen发布DeepResearch 2511升级\n15. 📈 阿里云调整通义千问3-Max价格\n16. 🚀 H Company发布Holo2模型系列\n17. 🚀 JanHQ发布Jan-v2-VL多模态Agent模型\n\n---\n\n### 1. 🚀 Google DeepMind发布SIMA 2智能体 {#1-Google-DeepMind发布SIMA-2智能体}\n\n**标签：** `Google DeepMind` `SIMA 2` `虚拟3D世界`\n\nGoogle DeepMind于近日发布SIMA 2（Scalable Instructable Multiworld Agent 2），一款可在虚拟3D世界中与人类协同操作、推理并持续学习的通用智能体。该智能体支持多环境交互，具备任务理解、自然语言指令执行和实时反馈学习能力，能够在复杂3D场景中进行导航、操作物体和协作决策。SIMA 2通过强化学习与模仿学习结合的方式，在多个虚拟世界中实现跨域泛化，标志着AI在具身智能（Embodied AI）方向的重要进展。其潜在应用包括虚拟助手、游戏AI、机器人仿真训练和交互式教育平台。\n\n**🔗 相关链接：**\n- <https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/>\n- <https://blog.google/technology/google-labs/notebooklm-deep-research-file-types/>\n- <https://x.com/NotebookLM/status/1989099764764283224>\n\n---\n\n### 2. 🚀 Lumine发布3D开放世界通用智能体 {#2-Lumine发布3D开放世界通用智能体}\n\n**标签：** `Lumine` `3D开放世界` `通用智能体`\n\nLumine团队推出面向3D开放世界环境的通用智能体，旨在实现跨游戏、仿真平台的高自由度自主行为。该智能体支持多模态输入（视觉、语音、文本），具备环境理解、任务规划和长期记忆能力，可在无监督或弱监督条件下学习复杂交互行为。其架构支持插件式扩展，适用于元宇宙、数字孪生、虚拟训练等场景。Lumine强调其智能体具备‘与人类共玩’（play with you）的能力，推动人机协作智能的发展。\n\n**🔗 相关链接：**\n- <https://www.lumine-ai.org/>\n\n---\n\n### 3. 🚀 百度发布文心大模型5.0 {#3-百度发布文心大模型50}\n\n**标签：** `百度` `文心大模型5.0` `ERNIE`\n\n百度正式发布文心大模型5.0（ERNIE 5.0），在语言理解、逻辑推理、多轮对话和代码生成能力上实现显著提升。新版本采用更高效的稀疏架构与混合专家（MoE）技术，支持更长上下文窗口（最高达128K tokens），并优化了中文语义理解与生成质量。文心5.0已在百度搜索、智能云、小度助手等产品中部署，助力企业智能化升级。其推理效率较前代提升约30%，在多项中文NLP基准测试中保持领先。\n\n**🔗 相关链接：**\n- <https://zhidx.com/p/514799.html>\n\n---\n\n### 4. 🚀 OpenAI上线GPT-5.1模型API {#4-OpenAI上线GPT-51模型API}\n\n**标签：** `OpenAI` `GPT-5.1` `API`\n\nOpenAI正式向开发者开放GPT-5.1系列模型的API访问权限，标志着其大模型迭代进入新阶段。GPT-5.1在推理能力、指令遵循精度和长文本处理方面较GPT-5.0有明显提升，支持最大128K上下文窗口，并优化了多轮对话的连贯性与安全性。官方同步发布《GPT-5.1 Prompting Guide》，提供结构化提示工程最佳实践。该模型适用于复杂问答、内容创作、代码生成和自动化决策等场景，进一步巩固OpenAI在生成式AI领域的领先地位。\n\n**🔗 相关链接：**\n- <https://openai.com/index/gpt-5-1-for-developers/>\n- <https://cookbook.openai.com/examples/gpt-5/gpt-5.1_prompting_guide>\n- <https://github.com/openai/codex/releases/tag/rust-v0.58.0>\n\n---\n\n### 5. 🔧 Codex发布0.58.0支持GPT-5.1模型 {#5-Codex发布0580支持GPT-51模型}\n\n**标签：** `Codex` `GPT-5.1` `OpenAI`\n\nOpenAI开源项目Codex发布Rust版本v0.58.0，正式集成对GPT-5.1系列模型的支持。该版本优化了模型调用接口、错误处理机制和异步执行性能，支持在本地或边缘环境中部署GPT-5.1推理服务。更新还包含新的代码补全策略、上下文缓存机制和安全性过滤模块，适用于IDE插件、自动化编程助手和CI/CD集成场景。Codex作为OpenAI生态的重要工具链，进一步降低了开发者使用前沿大模型的门槛。\n\n**🔗 相关链接：**\n- <https://openai.com/index/gpt-5-1-for-developers/>\n- <https://cookbook.openai.com/examples/gpt-5/gpt-5.1_prompting_guide>\n- <https://github.com/openai/codex/releases/tag/rust-v0.58.0>\n\n---\n\n### 6. 🚀 OpenAI发布Apps SDK预览版 {#6-OpenAI发布Apps-SDK预览版}\n\n**标签：** `OpenAI` `Apps SDK` `GPT模型`\n\nOpenAI推出Apps SDK预览版，允许开发者使用Python和TypeScript构建可调用GPT模型的原生应用。SDK提供身份认证、权限管理、模型调用、日志记录和用户反馈收集等核心模块，支持快速集成到Web、移动端和桌面应用中。该工具旨在简化AI应用开发流程，推动GPT模型在垂直领域的落地，如教育、医疗、客服等。预览版已开放注册，未来将支持更多部署模式和商业化选项。\n\n**🔗 相关链接：**\n- <https://openai.com/index/gpt-5-1-for-developers/>\n- <https://cookbook.openai.com/examples/gpt-5/gpt-5.1_prompting_guide>\n- <https://developers.openai.com/apps-sdk/>\n\n---\n\n### 7. 🔧 Gemini 3或上线Canvas功能 {#7-Gemini-3或上线Canvas功能}\n\n**标签：** `Google` `Gemini 3` `Canvas`\n\n据TestingCatalog报道，Google正在为Gemini App测试名为Canvas的新功能，可能基于Gemini 3模型构建。该功能允许用户通过自然语言指令生成可视化内容，如图表、流程图、代码结构图等，并支持实时编辑与导出。Canvas强调‘创意表达’，旨在提升用户在内容创作、项目规划和知识整理中的效率。若正式推出，将增强Gemini在多模态交互领域的竞争力。\n\n**🔗 相关链接：**\n- <https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/>\n- <https://www.testingcatalog.com/google-prepares-creative-canvas-mode-for-release/>\n- <https://x.com/GeminiApp/status/1988755100412834151>\n\n---\n\n### 8. 🔧 Google发布Gemini Live重大更新 {#8-Google发布Gemini-Live重大更新}\n\n**标签：** `Google` `Gemini Live` `语音交互`\n\nGoogle通过官方渠道宣布Gemini Live迎来重大更新，重点优化实时语音交互体验。新版本支持更自然的对话节奏、上下文记忆增强和背景噪音抑制，可在移动设备上实现低延迟的连续对话。更新还引入多语言混合输入识别和个性化响应风格设置，提升跨语言用户的使用体验。Gemini Live作为Google AI助手战略的核心组件，正逐步向多模态、个性化方向演进。\n\n**🔗 相关链接：**\n- <https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/>\n- <https://x.com/GeminiApp/status/1988755100412834151>\n- <https://developers.googleblog.com/en/making-the-terminal-beautiful-one-pixel-at-a-time/>\n\n---\n\n### 9. 🔧 Google升级Gemini CLI用户体验 {#9-Google升级Gemini-CLI用户体验}\n\n**标签：** `Google` `Gemini CLI` `开发者工具`\n\nGoogle发布Gemini命令行界面（CLI）的重大用户体验升级，引入彩色输出、语法高亮、进度条和交互式提示等可视化元素。新设计采用现代终端美学，支持自定义主题和快捷键，显著提升开发者在终端中使用Gemini进行代码生成、调试和文档查询的效率。该更新体现了Google对开发者工具链的持续投入，推动AI在命令行环境中的深度集成。\n\n**🔗 相关链接：**\n- <https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/>\n- <https://x.com/GeminiApp/status/1988755100412834151>\n- <https://developers.googleblog.com/en/making-the-terminal-beautiful-one-pixel-at-a-time/>\n\n---\n\n### 10. 🔧 NotebookLM推出Deep Research功能 {#10-NotebookLM推出Deep-Research功能}\n\n**标签：** `Google` `NotebookLM` `Deep Research`\n\nGoogle NotebookLM发布重大更新，新增Deep Research功能，支持用户上传PDF、DOCX、TXT等文件类型，并自动生成深度分析报告。该功能可跨文档提取关键信息、构建知识图谱、生成引用摘要，并提供多轮追问能力。同时，NotebookLM引入自定义视频风格选项，允许用户选择不同视觉模板生成讲解视频。此次升级强化了其在学术研究、企业情报和知识管理中的应用价值。\n\n**🔗 相关链接：**\n- <https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/>\n- <https://x.com/GeminiApp/status/1988755100412834151>\n- <https://developers.googleblog.com/en/making-the-terminal-beautiful-one-pixel-at-a-time/>\n\n---\n\n### 11. 📈 Google更新AI搜索购物体验 {#11-Google更新AI搜索购物体验}\n\n**标签：** `Google` `AI搜索` `Gemini`\n\nGoogle宣布升级其AI驱动的搜索购物体验，利用Gemini模型优化商品推荐、价格比较和用户评论分析。新系统支持自然语言查询（如‘适合油性皮肤的平价面霜’），并生成结构化结果，包含产品对比、用户评分、成分分析和购买链接。该更新旨在提升电商搜索的精准度与转化率，推动AI在零售场景中的商业化落地。\n\n**🔗 相关链接：**\n- <https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/>\n- <https://www.testingcatalog.com/google-prepares-creative-canvas-mode-for-release/>\n- <https://x.com/GeminiApp/status/1988755100412834151>\n\n---\n\n### 12. 🚀 Anthropic扩展Claude Code网页版 {#12-Anthropic扩展Claude-Code网页版}\n\n**标签：** `Anthropic` `Claude Code` `企业计划`\n\nAnthropic宣布Claude Code网页版已扩展至团队和企业计划用户，支持多人协作、权限管理和企业级安全策略。该工具允许开发者通过自然语言指令执行代码生成、调试、测试和部署任务，集成Git工作流和CI/CD管道。网页版提供实时协作编辑、任务分配和审计日志功能，助力企业实现AI驱动的软件开发流程自动化。\n\n**🔗 相关链接：**\n- <https://x.com/claudeai/status/1988737589130747906>\n\n---\n\n### 13. 🔧 VS Code发布1.106集成Agent管理 {#13-VS-Code发布1106集成Agent管理}\n\n**标签：** `VS Code` `Copilot` `Agent管理`\n\nVisual Studio Code发布v1.106版本，新增Copilot Agent任务管理视图，支持开发者创建、监控和终止AI代理任务。新界面提供任务状态、执行日志、资源占用和响应延迟等可视化指标，优化AI辅助编程的透明度和可控性。该功能与GitHub Copilot深度集成，适用于复杂项目中的多代理协作场景，提升开发效率与代码质量。\n\n**🔗 相关链接：**\n- <https://github.blog/changelog/2025-11-13-manage-copilot-coding-agent-tasks-in-visual-studio-code>\n- <https://x.com/code/status/1988973703141740913>\n\n---\n\n### 14. 🔧 Qwen发布DeepResearch 2511升级 {#14-Qwen发布DeepResearch-2511升级}\n\n**标签：** `Qwen` `DeepResearch` `阿里云`\n\n阿里云Qwen团队发布DeepResearch功能2511版本升级，增强其长文本分析、多源信息整合和逻辑推理能力。新版本支持最大256K上下文窗口，可处理PDF、网页、数据库等多种数据源，并生成带引用标注的研究报告。升级还优化了中文语义理解与领域知识检索，适用于金融、法律、科研等专业场景。用户可通过chat.qwen.ai直接体验该功能。\n\n**🔗 相关链接：**\n- <https://qwen.ai/blog?id=qwen-deepresearch>\n- <https://chat.qwen.ai/?inputFeature=deep_research>\n- <https://linux.do/t/topic/1167502>\n\n---\n\n### 15. 📈 阿里云调整通义千问3-Max价格 {#15-阿里云调整通义千问3-Max价格}\n\n**标签：** `阿里云` `通义千问3-Max` `百炼平台`\n\n阿里云百炼平台调整通义千问3-Max（Qwen3-Max）模型的API调用价格，具体调整幅度未公开，但社区讨论显示推理成本有所优化。此次调价可能旨在提升模型在中小企业和开发者中的可及性，增强其在中文大模型市场的竞争力。Qwen3-Max作为阿里云旗舰模型，支持多模态输入与复杂任务处理，广泛应用于智能客服、内容生成和数据分析等领域。\n\n**🔗 相关链接：**\n- <https://linux.do/t/topic/1167502>\n\n---\n\n### 16. 🚀 H Company发布Holo2模型系列 {#16-H-Company发布Holo2模型系列}\n\n**标签：** `H Company` `Holo2` `多模态模型`\n\nH Company发布Holo2系列大模型，包含多个参数规模的变体，支持文本、图像、音频多模态输入与生成。该系列采用新型混合架构，强调在3D内容生成、虚拟角色交互和空间理解方面的能力。Holo2在Hugging Face上开源部分模型，支持本地部署与微调，适用于元宇宙、数字人、AR/VR等前沿应用场景。其发布标志着新兴AI公司在多模态智能体领域的布局加速。\n\n**🔗 相关链接：**\n- <https://www.hcompany.ai/blog/holo2>\n- <https://huggingface.co/collections/Hcompany/holo2>\n\n---\n\n### 17. 🚀 JanHQ发布Jan-v2-VL多模态Agent模型 {#17-JanHQ发布Jan-v2-VL多模态Agent模型}\n\n**标签：** `JanHQ` `Jan-v2-VL` `多模态Agent`\n\nJanHQ发布Jan-v2-VL系列多模态Agent模型，支持图像理解、文本生成和跨模态推理。该模型可在本地设备上运行，强调隐私保护与低延迟响应，适用于个人助手、教育辅导和智能设备控制等场景。Jan-v2-VL在Hugging Face上提供多个版本，支持ONNX和TensorRT加速，推动轻量化AI在边缘计算中的落地。\n\n**🔗 相关链接：**\n- <https://huggingface.co/collections/janhq/jan-v2-vl>\n\n---\n\n---\n\n## 🎬 视频链接\n\n**Bilibili**： <https://www.bilibili.com/video/BV1G5CPBrEmd>\n\n---\n\n*整理自橘鸦AI早报 | BV号：BV1G5CPBrEmd | 2025-11-22 20:35:31*"
}