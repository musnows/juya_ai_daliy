{
  "title": "阿里Qwen团队开源 Qwen-Image-Layered【AI 早报 2025-12-20】",
  "publish_date": "2025-12-20",
  "bv_id": "BV1pSBwB3E6B",
  "organize_time": "2025-12-20 09:00:17",
  "news_count": 20,
  "overview": "1. 🚀 Qwen开源图像分层编辑模型\n2. 🔧 Codex CLI支持Skills功能\n3. 🚀 Gemini CLI向免费用户开放Gemini 3\n4. 🔧 Gemini App集成NotebookLM功能\n5. 🚀 Google发布Gemma Scope 2可解释性工具\n6. 🚀 Google推出A2UI智能体驱动UI协议\n7. 🚀 NVIDIA发布NitroGen游戏智能体模型\n8. 🚀 Meta开源Text Seal水印检测工具\n9. 🚀 Will McGugan发布终端AI工具Toad\n10. 🔧 AI推理新基准FrontierCS发布\n11. 🚀 Transluce AI发布模型行为解码器\n12. 🚀 MiniMax开放M2.1模型体验申请\n13. 🔧 智谱GLM-4.7模型即将发布\n14. 📈 智谱AI通过港交所聆讯\n15. 🚀 全光学芯片莱震发布\n16. 🔧 字节发布C Prover 1.5技术报告\n17. 📈 Meta开发Mango与Avocado新模型\n18. 📈 Koder收购代码审查平台Graph\n19. 📈 Andrej Karpathy年度回顾发布\n20. 📈 Google成立算力分配委员会",
  "html_content": "<h2 id=\"_1\">📋 本期概览</h2>\n<ol>\n<li>🚀 Qwen开源图像分层编辑模型</li>\n<li>🔧 Codex CLI支持Skills功能</li>\n<li>🚀 Gemini CLI向免费用户开放Gemini 3</li>\n<li>🔧 Gemini App集成NotebookLM功能</li>\n<li>🚀 Google发布Gemma Scope 2可解释性工具</li>\n<li>🚀 Google推出A2UI智能体驱动UI协议</li>\n<li>🚀 NVIDIA发布NitroGen游戏智能体模型</li>\n<li>🚀 Meta开源Text Seal水印检测工具</li>\n<li>🚀 Will McGugan发布终端AI工具Toad</li>\n<li>🔧 AI推理新基准FrontierCS发布</li>\n<li>🚀 Transluce AI发布模型行为解码器</li>\n<li>🚀 MiniMax开放M2.1模型体验申请</li>\n<li>🔧 智谱GLM-4.7模型即将发布</li>\n<li>📈 智谱AI通过港交所聆讯</li>\n<li>🚀 全光学芯片莱震发布</li>\n<li>🔧 字节发布C Prover 1.5技术报告</li>\n<li>📈 Meta开发Mango与Avocado新模型</li>\n<li>📈 Koder收购代码审查平台Graph</li>\n<li>📈 Andrej Karpathy年度回顾发布</li>\n<li>📈 Google成立算力分配委员会</li>\n</ol>\n<hr />\n<h3 id=\"1-Qwen开源图像分层编辑模型\">1. 🚀 Qwen开源图像分层编辑模型</h3>\n<p><strong>标签</strong>： <code>Qwen</code> <code>Qwen-Image-Layered</code> <code>阿里</code></p>\n<p>阿里Qwen团队发布Qwen-Image-Layered，可将图像分解为多个独立可编辑的图层，支持重着色、移动、删除等操作，实现类似Photoshop的高保真编辑体验。该模型基于分层表示学习技术，能够精准分离图像中的前景、背景及对象边界，支持非破坏性编辑，适用于图像修复、内容创作、广告设计等场景。模型已在Hugging Face开源，并发布技术论文与博客，提供完整训练细节和推理接口。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://huggingface.co/Qwen/Qwen-Image-Layered\">https://huggingface.co/Qwen/Qwen-Image-Layered</a><br />\n- <a href=\"https://arxiv.org/abs/2512.15603\">https://arxiv.org/abs/2512.15603</a><br />\n- <a href=\"https://qwenlm.github.io/blog/qwen-image-layered/\">https://qwenlm.github.io/blog/qwen-image-layered/</a></p>\n<hr />\n<h3 id=\"2-Codex-CLI支持Skills功能\">2. 🔧 Codex CLI支持Skills功能</h3>\n<p><strong>标签</strong>： <code>OpenAI</code> <code>Codex CLI</code> <code>Skills</code></p>\n<p>OpenAI宣布Codex CLI正式支持Skills功能，允许开发者通过可重用的指令包（Skills）完成特定编程任务。用户更新CLI至最新版本后，可调用系统预置或自定义安装的Skills，实现代码生成、调试、文档生成等自动化操作。Skills以模块化方式封装常见开发流程，提升AI编程助手的一致性与可维护性，支持团队协作与知识沉淀，是AI原生开发工具链的重要演进。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/OpenAIDevs/status/2002099762536010235\">https://x.com/OpenAIDevs/status/2002099762536010235</a><br />\n- <a href=\"https://developers.openai.com/codex/skills\">https://developers.openai.com/codex/skills</a></p>\n<hr />\n<h3 id=\"3-Gemini-CLI向免费用户开放Gemini-3\">3. 🚀 Gemini CLI向免费用户开放Gemini 3</h3>\n<p><strong>标签</strong>： <code>Google</code> <code>Gemini CLI</code> <code>Gemini 3</code></p>\n<p>Google宣布Gemini CLI现已向所有免费用户开放Gemini 3模型。用户只需在设置界面手动开启‘预览功能’选项，即可立即免费体验最新模型。Gemini 3在多模态理解、代码生成和复杂推理方面性能显著提升，支持自然语言指令执行终端任务、文件操作和系统管理，极大降低了AI命令行工具的使用门槛，推动AI终端助手普及。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/ntaylormullen/status/2002131383477801045\">https://x.com/ntaylormullen/status/2002131383477801045</a><br />\n- <a href=\"https://x.com/NotebookLM/status/2002075730738327669\">https://x.com/NotebookLM/status/2002075730738327669</a><br />\n- <a href=\"https://deepmind.google/blog/gemma-scope-2-helping-the-ai-safety-community-deepen-understanding-of-complex-language-model-behavior/\">https://deepmind.google/blog/gemma-scope-2-helping-the-ai-safety-community-deepen-understanding-of-complex-language-model-behavior/</a></p>\n<hr />\n<h3 id=\"4-Gemini-App集成NotebookLM功能\">4. 🔧 Gemini App集成NotebookLM功能</h3>\n<p><strong>标签</strong>： <code>Google</code> <code>Gemini App</code> <code>NotebookLM</code></p>\n<p>Google Gemini App正式集成NotebookLM功能，支持用户直接上传并组合多个笔记本内容。该更新允许用户基于现有笔记进行在线研究、生成图像或构建应用程序。Gemini可自动提取笔记中的关键信息，生成摘要、问答、思维导图，并调用多模态能力输出可视化内容，实现知识管理与AI创作的无缝衔接，提升个人与团队生产力。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/ntaylormullen/status/2002131383477801045\">https://x.com/ntaylormullen/status/2002131383477801045</a><br />\n- <a href=\"https://x.com/NotebookLM/status/2002075730738327669\">https://x.com/NotebookLM/status/2002075730738327669</a><br />\n- <a href=\"https://deepmind.google/blog/gemma-scope-2-helping-the-ai-safety-community-deepen-understanding-of-complex-language-model-behavior/\">https://deepmind.google/blog/gemma-scope-2-helping-the-ai-safety-community-deepen-understanding-of-complex-language-model-behavior/</a></p>\n<hr />\n<h3 id=\"5-Google发布Gemma-Scope-2可解释性工具\">5. 🚀 Google发布Gemma Scope 2可解释性工具</h3>\n<p><strong>标签</strong>： <code>Google DeepMind</code> <code>Gemma Scope 2</code> <code>Gemma 3</code></p>\n<p>Google DeepMind发布Gemma Scope 2，专用于解析Gemma 3模型的内部逻辑。该套件包含大规模稀疏自动编码器（SAE），可追踪模型推理过程中的激活路径，帮助研究人员识别幻觉、偏见等风险。工具支持逐层分析注意力机制与神经元响应，已在Hugging Face开源，适用于AI安全、模型调试与可解释性研究，推动透明AI发展。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://deepmind.google/blog/gemma-scope-2-helping-the-ai-safety-community-deepen-understanding-of-complex-language-model-behavior/\">https://deepmind.google/blog/gemma-scope-2-helping-the-ai-safety-community-deepen-understanding-of-complex-language-model-behavior/</a><br />\n- <a href=\"https://huggingface.co/collections/google/gemma-scope-2\">https://huggingface.co/collections/google/gemma-scope-2</a><br />\n- <a href=\"https://deepmind.google/models/gemma/gemma-scope/\">https://deepmind.google/models/gemma/gemma-scope/</a></p>\n<hr />\n<h3 id=\"6-Google推出A2UI智能体驱动UI协议\">6. 🚀 Google推出A2UI智能体驱动UI协议</h3>\n<p><strong>标签</strong>： <code>Google</code> <code>A2UI</code> <code>智能体</code></p>\n<p>Google发布开源协议A2UI，允许AI智能体通过声明式组件生成跨平台交互界面。该协议支持Web与移动端原生渲染，确保数据传输安全，采用JSON格式定义UI结构，AI可直接生成按钮、表单、列表等组件。A2UI目前处于早期预览阶段，旨在构建AI原生应用界面标准，降低智能体应用开发门槛，提升用户体验一致性。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/NotebookLM/status/2002075730738327669\">https://x.com/NotebookLM/status/2002075730738327669</a><br />\n- <a href=\"https://deepmind.google/blog/gemma-scope-2-helping-the-ai-safety-community-deepen-understanding-of-complex-language-model-behavior/\">https://deepmind.google/blog/gemma-scope-2-helping-the-ai-safety-community-deepen-understanding-of-complex-language-model-behavior/</a><br />\n- <a href=\"https://huggingface.co/collections/google/gemma-scope-2\">https://huggingface.co/collections/google/gemma-scope-2</a></p>\n<hr />\n<h3 id=\"7-NVIDIA发布NitroGen游戏智能体模型\">7. 🚀 NVIDIA发布NitroGen游戏智能体模型</h3>\n<p><strong>标签</strong>： <code>NVIDIA</code> <code>NitroGen</code> <code>游戏智能体</code></p>\n<p>NVIDIA发布开源游戏智能体模型NitroGen，拥有5亿参数，基于4万小时游戏视频训练，能直接通过游戏画面预测手柄动作。模型支持多任务泛化，可在未见过的游戏中执行导航、战斗、采集等操作。提供Hugging Face模型库、训练数据集与文档，适用于游戏自动化测试、AI玩家模拟与虚拟助手开发，推动通用游戏智能体发展。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://github.com/MineDojo/NitroGen\">https://github.com/MineDojo/NitroGen</a><br />\n- <a href=\"https://nitrogen.minedojo.org/\">https://nitrogen.minedojo.org/</a><br />\n- <a href=\"https://huggingface.co/nvidia/NitroGen\">https://huggingface.co/nvidia/NitroGen</a></p>\n<hr />\n<h3 id=\"8-Meta开源Text-Seal水印检测工具\">8. 🚀 Meta开源Text Seal水印检测工具</h3>\n<p><strong>标签</strong>： <code>Meta</code> <code>Text Seal</code> <code>水印检测</code></p>\n<p>Meta AI开源Text Seal工具包，为大语言模型提供生成时与事后的文本水印方案。该工具支持在文本中嵌入不可见水印，并能检测训练数据是否被水印污染，防止模型记忆敏感信息。功能包括水印嵌入、提取、污染溯源，适用于版权保护、数据合规与模型安全审计，提升AI生成内容的可追溯性与可信度。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://github.com/facebookresearch/textseal\">https://github.com/facebookresearch/textseal</a></p>\n<hr />\n<h3 id=\"9-Will-McGugan发布终端AI工具Toad\">9. 🚀 Will McGugan发布终端AI工具Toad</h3>\n<p><strong>标签</strong>： <code>Will McGugan</code> <code>Toad</code> <code>AI编程代理</code></p>\n<p>开发者Will McGugan发布终端AI工具Toad，专为Claude等AI编程代理提供统一交互体验。Toad内置文件模糊搜索、Markdown实时渲染、代码高亮与上下文管理功能，支持与AI代理无缝集成。用户可在终端中直接调用AI进行代码审查、重构与文档生成，提升开发效率，是AI原生终端工具的重要实践。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://willmcgugan.github.io/toad-released/\">https://willmcgugan.github.io/toad-released/</a><br />\n- <a href=\"https://github.com/batrachianai/toad\">https://github.com/batrachianai/toad</a></p>\n<hr />\n<h3 id=\"10-AI推理新基准FrontierCS发布\">10. 🔧 AI推理新基准FrontierCS发布</h3>\n<p><strong>标签</strong>： <code>伯克利</code> <code>FrontierCS</code> <code>推理基准</code></p>\n<p>伯克利研究团队发布AI前沿推理能力新基准FrontierCS，包含156个前沿计算机科学难题，涵盖算法设计、系统优化、形式验证等开放性问题。测试显示，当前最强推理模型（如o1、Gemini 3）在解决这些问题时与人类专家仍存在巨大差距，尤其在创造性设计与跨领域整合方面。该基准推动AI向真正科学推理迈进。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://arxiv.org/abs/2512.15699\">https://arxiv.org/abs/2512.15699</a><br />\n- <a href=\"https://github.com/FrontierCS/Frontier-CS\">https://github.com/FrontierCS/Frontier-CS</a></p>\n<hr />\n<h3 id=\"11-Transluce-AI发布模型行为解码器\">11. 🚀 Transluce AI发布模型行为解码器</h3>\n<p><strong>标签</strong>： <code>Transluce AI</code> <code>PCD</code> <code>行为解码器</code></p>\n<p>研究机构Transluce AI发布预测概念解码器（PCD），能将AI模型的内部状态转化为可读概念列表。该工具可在模型不直接透露信息的情况下，识别越狱攻击、隐藏提示与潜在风险行为。PCD通过分析隐藏层激活，映射至语义概念空间，支持实时监控与干预，适用于AI安全、内容审核与模型调试。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://transluce.org/pcd\">https://transluce.org/pcd</a><br />\n- <a href=\"https://arxiv.org/abs/2512.15712\">https://arxiv.org/abs/2512.15712</a><br />\n- <a href=\"https://decoder.transluce.org/\">https://decoder.transluce.org/</a></p>\n<hr />\n<h3 id=\"12-MiniMax开放M21模型体验申请\">12. 🚀 MiniMax开放M2.1模型体验申请</h3>\n<p><strong>标签</strong>： <code>MiniMax</code> <code>M2.1</code> <code>大语言模型</code></p>\n<p>MiniMax官方宣布开放大语言模型M2.1的早期体验申请，并发布在线报名表。该模型在推理、代码与多轮对话方面性能显著提升，支持长上下文与复杂任务规划。开发者可通过官网提交申请，获得API访问权限，参与模型测试与反馈，推动下一代大模型生态建设。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/MiniMax__AI/status/2001909739891101948\">https://x.com/MiniMax__AI/status/2001909739891101948</a></p>\n<hr />\n<h3 id=\"13-智谱GLM-47模型即将发布\">13. 🔧 智谱GLM-4.7模型即将发布</h3>\n<p><strong>标签</strong>： <code>智谱AI</code> <code>GLM-4.7</code> <code>VLLM</code></p>\n<p>智谱AI在开源框架VLLM中提交支持GLM-4.7模型的代码，表明新模型即将发布。开发者发现官方API已上线该模型接口，但目前暂未对外部用户开放权限。GLM-4.7预计在多模态理解、推理与生成方面实现重大升级，延续智谱在开源大模型领域的领先地位。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://github.\">https://github.</a></p>\n<hr />\n<h3 id=\"14-智谱AI通过港交所聆讯\">14. 📈 智谱AI通过港交所聆讯</h3>\n<p><strong>标签</strong>： <code>智谱AI</code> <code>港交所</code> <code>大模型</code></p>\n<p>智谱AI已通过港交所聆讯，计划近期挂牌上市，或将成为全球大模型第一股。招股书显示，公司营收增长迅速，但因巨额算力投入导致亏损持续扩大，2025年上半年月均亏损近3亿元。上市将助力其扩大研发与基础设施投入，加速商业化落地。</p>\n<hr />\n<h3 id=\"15-全光学芯片莱震发布\">15. 🚀 全光学芯片莱震发布</h3>\n<p><strong>标签</strong>： <code>上海交大</code> <code>清华</code> <code>莱震</code></p>\n<p>上海交大与清华团队联合开发全光学芯片莱震，集成超200万个光子神经元。实验表明，莱震在执行复杂视觉生成任务时，速度和能效比现有电子芯片高出两个数量级。该芯片利用光信号进行并行计算，适用于实时AI推理、边缘计算与高性能计算场景，推动AI硬件革新。</p>\n<hr />\n<h3 id=\"16-字节发布C-Prover-15技术报告\">16. 🔧 字节发布C Prover 1.5技术报告</h3>\n<p><strong>标签</strong>： <code>字节跳动</code> <code>C Prover 1.5</code> <code>数学推理</code></p>\n<p>字节跳动发布C Prover 1.5模型技术报告，该模型在数学基准测试中表现优异，以更低算力达到上一代高资源模型水平。C Prover 1.5采用强化学习与可验证奖励机制，支持数学定理证明、代码验证与逻辑推理，适用于科研辅助与形式化验证，体现AI在科学计算中的潜力。</p>\n<hr />\n<h3 id=\"17-Meta开发Mango与Avocado新模型\">17. 📈 Meta开发Mango与Avocado新模型</h3>\n<p><strong>标签</strong>： <code>Meta</code> <code>Mango</code> <code>Avocado</code></p>\n<p>据外媒报道，Meta正在开发代号为Mango的图像视频模型与名为Avocado的文本模型，计划于2026年上半年发布。Mango支持高分辨率生成与视频理解，Avocado聚焦长文本生成与复杂推理。两者将整合至Meta下一代AI产品中，强化其在多模态与通用AI领域的竞争力。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://github.com/facebookresearch/textseal\">https://github.com/facebookresearch/textseal</a></p>\n<hr />\n<h3 id=\"18-Koder收购代码审查平台Graph\">18. 📈 Koder收购代码审查平台Graph</h3>\n<p><strong>标签</strong>： <code>Koder</code> <code>Graph</code> <code>代码审查</code></p>\n<p>AI代码编辑器Koder宣布收购代码审查平台Graph，双方将整合团队与技术。收购后Graph保持独立运营，并计划将其AI审查功能与Koder的B进行深度集成，实现自动化代码质量评估、漏洞检测与合规检查，提升AI编程工具链的完整性。</p>\n<hr />\n<h3 id=\"19-Andrej-Karpathy年度回顾发布\">19. 📈 Andrej Karpathy年度回顾发布</h3>\n<p><strong>标签</strong>： <code>Andrej Karpathy</code> <code>大语言模型</code> <code>强化学习</code></p>\n<p>知名学者Andrej Karpathy发布年度回顾，指出2025年是大语言模型范式转变的一年。他认为可验证奖励、强化学习已成为核心驱动力，Jaxco等应用揭示了全新的垂直应用层。AI正从通用助手向领域专家演进，推动AI原生应用生态形成。</p>\n<hr />\n<h3 id=\"20-Google成立算力分配委员会\">20. 📈 Google成立算力分配委员会</h3>\n<p><strong>标签</strong>： <code>Google</code> <code>算力分配</code> <code>Colab</code></p>\n<p>为应对算力短缺，Google成立由高管组成的分配委员会，协调内部资源。目前Google Colab获得约一半可用算力，公司计划每6个月将服务容量翻倍，以缓解业务发展瓶颈。该举措反映AI基础设施竞争加剧，算力已成为战略资源。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/NotebookLM/status/2002075730738327669\">https://x.com/NotebookLM/status/2002075730738327669</a><br />\n- <a href=\"https://deepmind.google/blog/gemma-scope-2-helping-the-ai-safety-community-deepen-understanding-of-complex-language-model-behavior/\">https://deepmind.google/blog/gemma-scope-2-helping-the-ai-safety-community-deepen-understanding-of-complex-language-model-behavior/</a><br />\n- <a href=\"https://huggingface.co/collections/google/gemma-scope-2\">https://huggingface.co/collections/google/gemma-scope-2</a></p>\n<hr />\n<hr />\n<h2 id=\"_2\">🎬 视频链接</h2>\n<p><strong>Bilibili</strong>： <a href=\"https://www.bilibili.com/video/BV1pSBwB3E6B\">https://www.bilibili.com/video/BV1pSBwB3E6B</a></p>\n<hr />\n<p><em>整理自橘鸦AI早报 | BV号：BV1pSBwB3E6B | 2025-12-20 09:00:17</em></p>",
  "content": "# 阿里Qwen团队开源 Qwen-Image-Layered【AI 早报 2025-12-20】\n\n**📅 发布日期：** 2025-12-20\n**🎬 BV号：** [BV1pSBwB3E6B](https://www.bilibili.com/video/BV1pSBwB3E6B)\n**📝 整理时间：** 2025-12-20 09:00:17\n**📊 资讯数量：** 20 条\n\n---\n\n## 📋 本期概览\n\n1. 🚀 Qwen开源图像分层编辑模型\n2. 🔧 Codex CLI支持Skills功能\n3. 🚀 Gemini CLI向免费用户开放Gemini 3\n4. 🔧 Gemini App集成NotebookLM功能\n5. 🚀 Google发布Gemma Scope 2可解释性工具\n6. 🚀 Google推出A2UI智能体驱动UI协议\n7. 🚀 NVIDIA发布NitroGen游戏智能体模型\n8. 🚀 Meta开源Text Seal水印检测工具\n9. 🚀 Will McGugan发布终端AI工具Toad\n10. 🔧 AI推理新基准FrontierCS发布\n11. 🚀 Transluce AI发布模型行为解码器\n12. 🚀 MiniMax开放M2.1模型体验申请\n13. 🔧 智谱GLM-4.7模型即将发布\n14. 📈 智谱AI通过港交所聆讯\n15. 🚀 全光学芯片莱震发布\n16. 🔧 字节发布C Prover 1.5技术报告\n17. 📈 Meta开发Mango与Avocado新模型\n18. 📈 Koder收购代码审查平台Graph\n19. 📈 Andrej Karpathy年度回顾发布\n20. 📈 Google成立算力分配委员会\n\n---\n\n### 1. 🚀 Qwen开源图像分层编辑模型 {#1-Qwen开源图像分层编辑模型}\n\n**标签**： `Qwen` `Qwen-Image-Layered` `阿里`\n\n阿里Qwen团队发布Qwen-Image-Layered，可将图像分解为多个独立可编辑的图层，支持重着色、移动、删除等操作，实现类似Photoshop的高保真编辑体验。该模型基于分层表示学习技术，能够精准分离图像中的前景、背景及对象边界，支持非破坏性编辑，适用于图像修复、内容创作、广告设计等场景。模型已在Hugging Face开源，并发布技术论文与博客，提供完整训练细节和推理接口。\n\n**🔗 相关链接：**\n- <https://huggingface.co/Qwen/Qwen-Image-Layered>\n- <https://arxiv.org/abs/2512.15603>\n- <https://qwenlm.github.io/blog/qwen-image-layered/>\n\n---\n\n### 2. 🔧 Codex CLI支持Skills功能 {#2-Codex-CLI支持Skills功能}\n\n**标签**： `OpenAI` `Codex CLI` `Skills`\n\nOpenAI宣布Codex CLI正式支持Skills功能，允许开发者通过可重用的指令包（Skills）完成特定编程任务。用户更新CLI至最新版本后，可调用系统预置或自定义安装的Skills，实现代码生成、调试、文档生成等自动化操作。Skills以模块化方式封装常见开发流程，提升AI编程助手的一致性与可维护性，支持团队协作与知识沉淀，是AI原生开发工具链的重要演进。\n\n**🔗 相关链接：**\n- <https://x.com/OpenAIDevs/status/2002099762536010235>\n- <https://developers.openai.com/codex/skills>\n\n---\n\n### 3. 🚀 Gemini CLI向免费用户开放Gemini 3 {#3-Gemini-CLI向免费用户开放Gemini-3}\n\n**标签**： `Google` `Gemini CLI` `Gemini 3`\n\nGoogle宣布Gemini CLI现已向所有免费用户开放Gemini 3模型。用户只需在设置界面手动开启‘预览功能’选项，即可立即免费体验最新模型。Gemini 3在多模态理解、代码生成和复杂推理方面性能显著提升，支持自然语言指令执行终端任务、文件操作和系统管理，极大降低了AI命令行工具的使用门槛，推动AI终端助手普及。\n\n**🔗 相关链接：**\n- <https://x.com/ntaylormullen/status/2002131383477801045>\n- <https://x.com/NotebookLM/status/2002075730738327669>\n- <https://deepmind.google/blog/gemma-scope-2-helping-the-ai-safety-community-deepen-understanding-of-complex-language-model-behavior/>\n\n---\n\n### 4. 🔧 Gemini App集成NotebookLM功能 {#4-Gemini-App集成NotebookLM功能}\n\n**标签**： `Google` `Gemini App` `NotebookLM`\n\nGoogle Gemini App正式集成NotebookLM功能，支持用户直接上传并组合多个笔记本内容。该更新允许用户基于现有笔记进行在线研究、生成图像或构建应用程序。Gemini可自动提取笔记中的关键信息，生成摘要、问答、思维导图，并调用多模态能力输出可视化内容，实现知识管理与AI创作的无缝衔接，提升个人与团队生产力。\n\n**🔗 相关链接：**\n- <https://x.com/ntaylormullen/status/2002131383477801045>\n- <https://x.com/NotebookLM/status/2002075730738327669>\n- <https://deepmind.google/blog/gemma-scope-2-helping-the-ai-safety-community-deepen-understanding-of-complex-language-model-behavior/>\n\n---\n\n### 5. 🚀 Google发布Gemma Scope 2可解释性工具 {#5-Google发布Gemma-Scope-2可解释性工具}\n\n**标签**： `Google DeepMind` `Gemma Scope 2` `Gemma 3`\n\nGoogle DeepMind发布Gemma Scope 2，专用于解析Gemma 3模型的内部逻辑。该套件包含大规模稀疏自动编码器（SAE），可追踪模型推理过程中的激活路径，帮助研究人员识别幻觉、偏见等风险。工具支持逐层分析注意力机制与神经元响应，已在Hugging Face开源，适用于AI安全、模型调试与可解释性研究，推动透明AI发展。\n\n**🔗 相关链接：**\n- <https://deepmind.google/blog/gemma-scope-2-helping-the-ai-safety-community-deepen-understanding-of-complex-language-model-behavior/>\n- <https://huggingface.co/collections/google/gemma-scope-2>\n- <https://deepmind.google/models/gemma/gemma-scope/>\n\n---\n\n### 6. 🚀 Google推出A2UI智能体驱动UI协议 {#6-Google推出A2UI智能体驱动UI协议}\n\n**标签**： `Google` `A2UI` `智能体`\n\nGoogle发布开源协议A2UI，允许AI智能体通过声明式组件生成跨平台交互界面。该协议支持Web与移动端原生渲染，确保数据传输安全，采用JSON格式定义UI结构，AI可直接生成按钮、表单、列表等组件。A2UI目前处于早期预览阶段，旨在构建AI原生应用界面标准，降低智能体应用开发门槛，提升用户体验一致性。\n\n**🔗 相关链接：**\n- <https://x.com/NotebookLM/status/2002075730738327669>\n- <https://deepmind.google/blog/gemma-scope-2-helping-the-ai-safety-community-deepen-understanding-of-complex-language-model-behavior/>\n- <https://huggingface.co/collections/google/gemma-scope-2>\n\n---\n\n### 7. 🚀 NVIDIA发布NitroGen游戏智能体模型 {#7-NVIDIA发布NitroGen游戏智能体模型}\n\n**标签**： `NVIDIA` `NitroGen` `游戏智能体`\n\nNVIDIA发布开源游戏智能体模型NitroGen，拥有5亿参数，基于4万小时游戏视频训练，能直接通过游戏画面预测手柄动作。模型支持多任务泛化，可在未见过的游戏中执行导航、战斗、采集等操作。提供Hugging Face模型库、训练数据集与文档，适用于游戏自动化测试、AI玩家模拟与虚拟助手开发，推动通用游戏智能体发展。\n\n**🔗 相关链接：**\n- <https://github.com/MineDojo/NitroGen>\n- <https://nitrogen.minedojo.org/>\n- <https://huggingface.co/nvidia/NitroGen>\n\n---\n\n### 8. 🚀 Meta开源Text Seal水印检测工具 {#8-Meta开源Text-Seal水印检测工具}\n\n**标签**： `Meta` `Text Seal` `水印检测`\n\nMeta AI开源Text Seal工具包，为大语言模型提供生成时与事后的文本水印方案。该工具支持在文本中嵌入不可见水印，并能检测训练数据是否被水印污染，防止模型记忆敏感信息。功能包括水印嵌入、提取、污染溯源，适用于版权保护、数据合规与模型安全审计，提升AI生成内容的可追溯性与可信度。\n\n**🔗 相关链接：**\n- <https://github.com/facebookresearch/textseal>\n\n---\n\n### 9. 🚀 Will McGugan发布终端AI工具Toad {#9-Will-McGugan发布终端AI工具Toad}\n\n**标签**： `Will McGugan` `Toad` `AI编程代理`\n\n开发者Will McGugan发布终端AI工具Toad，专为Claude等AI编程代理提供统一交互体验。Toad内置文件模糊搜索、Markdown实时渲染、代码高亮与上下文管理功能，支持与AI代理无缝集成。用户可在终端中直接调用AI进行代码审查、重构与文档生成，提升开发效率，是AI原生终端工具的重要实践。\n\n**🔗 相关链接：**\n- <https://willmcgugan.github.io/toad-released/>\n- <https://github.com/batrachianai/toad>\n\n---\n\n### 10. 🔧 AI推理新基准FrontierCS发布 {#10-AI推理新基准FrontierCS发布}\n\n**标签**： `伯克利` `FrontierCS` `推理基准`\n\n伯克利研究团队发布AI前沿推理能力新基准FrontierCS，包含156个前沿计算机科学难题，涵盖算法设计、系统优化、形式验证等开放性问题。测试显示，当前最强推理模型（如o1、Gemini 3）在解决这些问题时与人类专家仍存在巨大差距，尤其在创造性设计与跨领域整合方面。该基准推动AI向真正科学推理迈进。\n\n**🔗 相关链接：**\n- <https://arxiv.org/abs/2512.15699>\n- <https://github.com/FrontierCS/Frontier-CS>\n\n---\n\n### 11. 🚀 Transluce AI发布模型行为解码器 {#11-Transluce-AI发布模型行为解码器}\n\n**标签**： `Transluce AI` `PCD` `行为解码器`\n\n研究机构Transluce AI发布预测概念解码器（PCD），能将AI模型的内部状态转化为可读概念列表。该工具可在模型不直接透露信息的情况下，识别越狱攻击、隐藏提示与潜在风险行为。PCD通过分析隐藏层激活，映射至语义概念空间，支持实时监控与干预，适用于AI安全、内容审核与模型调试。\n\n**🔗 相关链接：**\n- <https://transluce.org/pcd>\n- <https://arxiv.org/abs/2512.15712>\n- <https://decoder.transluce.org/>\n\n---\n\n### 12. 🚀 MiniMax开放M2.1模型体验申请 {#12-MiniMax开放M21模型体验申请}\n\n**标签**： `MiniMax` `M2.1` `大语言模型`\n\nMiniMax官方宣布开放大语言模型M2.1的早期体验申请，并发布在线报名表。该模型在推理、代码与多轮对话方面性能显著提升，支持长上下文与复杂任务规划。开发者可通过官网提交申请，获得API访问权限，参与模型测试与反馈，推动下一代大模型生态建设。\n\n**🔗 相关链接：**\n- <https://x.com/MiniMax__AI/status/2001909739891101948>\n\n---\n\n### 13. 🔧 智谱GLM-4.7模型即将发布 {#13-智谱GLM-47模型即将发布}\n\n**标签**： `智谱AI` `GLM-4.7` `VLLM`\n\n智谱AI在开源框架VLLM中提交支持GLM-4.7模型的代码，表明新模型即将发布。开发者发现官方API已上线该模型接口，但目前暂未对外部用户开放权限。GLM-4.7预计在多模态理解、推理与生成方面实现重大升级，延续智谱在开源大模型领域的领先地位。\n\n**🔗 相关链接：**\n- <https://github.>\n\n---\n\n### 14. 📈 智谱AI通过港交所聆讯 {#14-智谱AI通过港交所聆讯}\n\n**标签**： `智谱AI` `港交所` `大模型`\n\n智谱AI已通过港交所聆讯，计划近期挂牌上市，或将成为全球大模型第一股。招股书显示，公司营收增长迅速，但因巨额算力投入导致亏损持续扩大，2025年上半年月均亏损近3亿元。上市将助力其扩大研发与基础设施投入，加速商业化落地。\n\n---\n\n### 15. 🚀 全光学芯片莱震发布 {#15-全光学芯片莱震发布}\n\n**标签**： `上海交大` `清华` `莱震`\n\n上海交大与清华团队联合开发全光学芯片莱震，集成超200万个光子神经元。实验表明，莱震在执行复杂视觉生成任务时，速度和能效比现有电子芯片高出两个数量级。该芯片利用光信号进行并行计算，适用于实时AI推理、边缘计算与高性能计算场景，推动AI硬件革新。\n\n---\n\n### 16. 🔧 字节发布C Prover 1.5技术报告 {#16-字节发布C-Prover-15技术报告}\n\n**标签**： `字节跳动` `C Prover 1.5` `数学推理`\n\n字节跳动发布C Prover 1.5模型技术报告，该模型在数学基准测试中表现优异，以更低算力达到上一代高资源模型水平。C Prover 1.5采用强化学习与可验证奖励机制，支持数学定理证明、代码验证与逻辑推理，适用于科研辅助与形式化验证，体现AI在科学计算中的潜力。\n\n---\n\n### 17. 📈 Meta开发Mango与Avocado新模型 {#17-Meta开发Mango与Avocado新模型}\n\n**标签**： `Meta` `Mango` `Avocado`\n\n据外媒报道，Meta正在开发代号为Mango的图像视频模型与名为Avocado的文本模型，计划于2026年上半年发布。Mango支持高分辨率生成与视频理解，Avocado聚焦长文本生成与复杂推理。两者将整合至Meta下一代AI产品中，强化其在多模态与通用AI领域的竞争力。\n\n**🔗 相关链接：**\n- <https://github.com/facebookresearch/textseal>\n\n---\n\n### 18. 📈 Koder收购代码审查平台Graph {#18-Koder收购代码审查平台Graph}\n\n**标签**： `Koder` `Graph` `代码审查`\n\nAI代码编辑器Koder宣布收购代码审查平台Graph，双方将整合团队与技术。收购后Graph保持独立运营，并计划将其AI审查功能与Koder的B进行深度集成，实现自动化代码质量评估、漏洞检测与合规检查，提升AI编程工具链的完整性。\n\n---\n\n### 19. 📈 Andrej Karpathy年度回顾发布 {#19-Andrej-Karpathy年度回顾发布}\n\n**标签**： `Andrej Karpathy` `大语言模型` `强化学习`\n\n知名学者Andrej Karpathy发布年度回顾，指出2025年是大语言模型范式转变的一年。他认为可验证奖励、强化学习已成为核心驱动力，Jaxco等应用揭示了全新的垂直应用层。AI正从通用助手向领域专家演进，推动AI原生应用生态形成。\n\n---\n\n### 20. 📈 Google成立算力分配委员会 {#20-Google成立算力分配委员会}\n\n**标签**： `Google` `算力分配` `Colab`\n\n为应对算力短缺，Google成立由高管组成的分配委员会，协调内部资源。目前Google Colab获得约一半可用算力，公司计划每6个月将服务容量翻倍，以缓解业务发展瓶颈。该举措反映AI基础设施竞争加剧，算力已成为战略资源。\n\n**🔗 相关链接：**\n- <https://x.com/NotebookLM/status/2002075730738327669>\n- <https://deepmind.google/blog/gemma-scope-2-helping-the-ai-safety-community-deepen-understanding-of-complex-language-model-behavior/>\n- <https://huggingface.co/collections/google/gemma-scope-2>\n\n---\n\n---\n\n## 🎬 视频链接\n\n**Bilibili**： <https://www.bilibili.com/video/BV1pSBwB3E6B>\n\n---\n\n*整理自橘鸦AI早报 | BV号：BV1pSBwB3E6B | 2025-12-20 09:00:17*"
}