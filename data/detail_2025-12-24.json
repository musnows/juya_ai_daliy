{
  "title": "MiniMax正式发布M2.1模型；Qwen开源Qwen-Image-Edit-2511模型【AI 早报 2025-12-24】",
  "publish_date": "2025-12-24",
  "bv_id": "BV1LHB3BHEJP",
  "organize_time": "2025-12-24 09:03:39",
  "news_count": 9,
  "overview": "1. 🚀 MiniMax发布M2.1模型，移动端性能显著提升\n2. 🚀 Qwen开源Qwen-Image-Edit-2511图像编辑模型\n3. 🚀 Qwen推出Qwen3-TTS系列语音合成模型\n4. 🚀 阿里云通义Fun团队开源Audio-Chat-8B音频模型\n5. 🔧 智谱团队透露GLM-5规划并即将发布新IDE工具\n6. 🔧 Diffusers新增Z-Image-Omni-Base模型\n7. 📈 Poetiq harness刷新ARC-AGI-2评测纪录至75%\n8. 🚀 xAI发布Grok Collections API，集成OCR与RAG技术\n9. 🔧 FunctionGemma本地微调指南发布，支持自定义工具调用",
  "html_content": "<h2 id=\"_1\">📋 本期概览</h2>\n<ol>\n<li>🚀 MiniMax发布M2.1模型，移动端性能显著提升</li>\n<li>🚀 Qwen开源Qwen-Image-Edit-2511图像编辑模型</li>\n<li>🚀 Qwen推出Qwen3-TTS系列语音合成模型</li>\n<li>🚀 阿里云通义Fun团队开源Audio-Chat-8B音频模型</li>\n<li>🔧 智谱团队透露GLM-5规划并即将发布新IDE工具</li>\n<li>🔧 Diffusers新增Z-Image-Omni-Base模型</li>\n<li>📈 Poetiq harness刷新ARC-AGI-2评测纪录至75%</li>\n<li>🚀 xAI发布Grok Collections API，集成OCR与RAG技术</li>\n<li>🔧 FunctionGemma本地微调指南发布，支持自定义工具调用</li>\n</ol>\n<hr />\n<h3 id=\"1-MiniMax发布M21模型移动端性能显著提升\">1. 🚀 MiniMax发布M2.1模型，移动端性能显著提升</h3>\n<p><strong>标签</strong>： <code>MiniMax</code> <code>MiniMax-M2.1</code> <code>VIBE</code></p>\n<p>MiniMax于2025年12月24日正式发布并开源其旗舰模型MiniMax-M2.1，该模型在SW Bench评测中得分达74.0%，较前代有显著提升。M2.1针对移动端场景进行了深度优化，重点增强场景式构建能力，旨在推动AI在移动生产环境中的落地应用。目前，该模型的API及相关Agents产品已全面开放，开发者可通过Hugging Face和MiniMax官网获取模型权重与接入文档。此外，配套发布的VIBE模型进一步提升了多模态交互体验，支持更自然的移动端AI应用开发。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://www.minimaxi.com/news/minimax-m21\">https://www.minimaxi.com/news/minimax-m21</a><br />\n- <a href=\"https://huggingface.co/MiniMaxAI/MiniMax-M2.1\">https://huggingface.co/MiniMaxAI/MiniMax-M2.1</a><br />\n- <a href=\"https://huggingface.co/MiniMaxAI/VIBE\">https://huggingface.co/MiniMaxAI/VIBE</a></p>\n<hr />\n<h3 id=\"2-Qwen开源Qwen-Image-Edit-2511图像编辑\">2. 🚀 Qwen开源Qwen-Image-Edit-2511图像编辑模型</h3>\n<p><strong>标签</strong>： <code>Qwen</code> <code>Qwen-Image-Edit-2511</code> <code>阿里云</code></p>\n<p>阿里云通义千问团队于12月24日开源Qwen-Image-Edit-2511模型，该模型在多人一致性与图像生成质量方面实现大幅提升。新版本集成了流行的LoRA功能，支持灯光增强、新视角生成和几何作图等高级编辑能力。用户可通过Qwen Chat的图像编辑功能直接体验该模型，适用于创意设计、内容生成等场景。模型已在ModelScope和GitHub开源，提供完整权重与推理代码，推动开源图像编辑技术发展。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://qwenlm.github.io/blog/qwen-image-edit-2511/\">https://qwenlm.github.io/blog/qwen-image-edit-2511/</a><br />\n- <a href=\"https://modelscope.cn/models/Qwen/Qwen-Image-Edit-2511\">https://modelscope.cn/models/Qwen/Qwen-Image-Edit-2511</a><br />\n- <a href=\"https://chat.qwen.ai/?inputFeature=image_edit\">https://chat.qwen.ai/?inputFeature=image_edit</a></p>\n<hr />\n<h3 id=\"3-Qwen推出Qwen3-TTS系列语音合成模型\">3. 🚀 Qwen推出Qwen3-TTS系列语音合成模型</h3>\n<p><strong>标签</strong>： <code>Qwen</code> <code>Qwen3-TTS</code> <code>VD-Flash</code> <code>VC-Flash</code></p>\n<p>Qwen团队同期发布Qwen3-TTS系列两款语音合成模型：VD-Flash支持通过自然语言指令自定义音色，实现高度个性化的语音生成；VC-Flash仅需3秒音频样本即可完成音色克隆，支持中、英、日等10种语言。两款模型均针对低延迟场景优化，适用于智能客服、有声内容制作等应用，显著提升语音交互的自然度与效率。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://qwenlm.github.io/blog/qwen-image-edit-2511/\">https://qwenlm.github.io/blog/qwen-image-edit-2511/</a><br />\n- <a href=\"https://modelscope.cn/models/Qwen/Qwen-Image-Edit-2511\">https://modelscope.cn/models/Qwen/Qwen-Image-Edit-2511</a><br />\n- <a href=\"https://chat.qwen.ai/?inputFeature=image_edit\">https://chat.qwen.ai/?inputFeature=image_edit</a></p>\n<hr />\n<h3 id=\"4-阿里云通义Fun团队开源Audio-Chat-8B音频模型\">4. 🚀 阿里云通义Fun团队开源Audio-Chat-8B音频模型</h3>\n<p><strong>标签</strong>： <code>阿里云</code> <code>Audio-Chat-8B</code> <code>通义Fun</code></p>\n<p>阿里云通义Fun团队开源80亿参数音频语言模型Audio-Chat-8B，专为低延迟自然语音交互设计。该模型在多项基准测试中表现优异，位居同尺寸模型前列，支持实时语音理解与生成。模型权重与训练代码已全面开放，适用于智能助手、语音交互系统等场景，推动轻量化语音AI技术的普及。</p>\n<hr />\n<h3 id=\"5-智谱团队透露GLM-5规划并即将发布新IDE工具\">5. 🔧 智谱团队透露GLM-5规划并即将发布新IDE工具</h3>\n<p><strong>标签</strong>： <code>智谱AI</code> <code>GLM-5</code> <code>再扣IDE</code></p>\n<p>智谱AI团队在Reddit AMA活动中透露，正在开发名为“再扣”的IDE工具，预计即将对外发布。该IDE将深度集成GLM系列模型，提供代码补全、智能调试等功能。团队同时确认已对GLM-5进行大量适配优化，未来将支持更复杂的开发场景，提升AI辅助编程体验。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1ptxm3x/ama_with_zai_the_lab_behind_glm47/\">https://www.reddit.com/r/LocalLLaMA/comments/1ptxm3x/ama_with_zai_the_lab_behind_glm47/</a></p>\n<hr />\n<h3 id=\"6-Diffusers新增Z-Image-Omni-Base模型\">6. 🔧 Diffusers新增Z-Image-Omni-Base模型</h3>\n<p><strong>标签</strong>： <code>Hugging Face</code> <code>Diffusers</code> <code>Z-Image-Omni-Base</code></p>\n<p>Hugging Face的Diffusers库新增Z-Image-Omni-Base模型，该模型支持多模态图像生成与理解任务，具备跨域适应能力。此次更新通过GitHub Pull Request #12857实现，社区讨论活跃，预示该模型即将正式发布。Z-Image-Omni-Base有望在图像编辑、内容生成等领域提供更强性能。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://github.com/huggingface/diffusers/pull/12857\">https://github.com/huggingface/diffusers/pull/12857</a><br />\n- <a href=\"https://linux.do/t/topic/1354686\">https://linux.do/t/topic/1354686</a></p>\n<hr />\n<h3 id=\"7-Poetiq-harness刷新ARC-AGI-2评测纪录至\">7. 📈 Poetiq harness刷新ARC-AGI-2评测纪录至75%</h3>\n<p><strong>标签</strong>： <code>Poetiq</code> <code>GPT-5.2X Hi</code> <code>ARC-AGI-2</code></p>\n<p>AI公司Poetiq官方宣布，其基于GPT-5.2X Hi模型与Poetiq Carness系统，在ARC-AGI-2通用人工智能评测中创下75%的历史新高，刷新此前纪录。该成绩表明其在复杂推理与任务泛化能力上的重大突破，为AGI发展提供重要参考。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/poetiq_ai/status/2003546910427361402\">https://x.com/poetiq_ai/status/2003546910427361402</a></p>\n<hr />\n<h3 id=\"8-xAI发布Grok-Collections-API集成OCR\">8. 🚀 xAI发布Grok Collections API，集成OCR与RAG技术</h3>\n<p><strong>标签</strong>： <code>xAI</code> <code>Grok Collections API</code> <code>RAG</code></p>\n<p>xAI于12月24日正式推出Grok Collections API，这是一款集成OCR与布局感知技术的先进RAG（检索增强生成）系统。开发者可直接上传PDF或代码库，自动构建知识库并实现智能问答。API首周免费，支持高效文档理解与知识提取，适用于企业知识管理、法律分析等场景。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.ai/news/grok-collections-api\">https://x.ai/news/grok-collections-api</a></p>\n<hr />\n<h3 id=\"9-FunctionGemma本地微调指南发布支持自定义工具调用\">9. 🔧 FunctionGemma本地微调指南发布，支持自定义工具调用</h3>\n<p><strong>标签</strong>： <code>Unsloth AI</code> <code>LM Studio</code> <code>FunctionGemma</code></p>\n<p>Unsloth AI与LM Studio联合发布FunctionGemma模型本地微调技术指南，指导用户基于Google Function Gemma模型实现自定义工具调用。教程提供免费的Colab笔记本，支持将微调后的模型转换为GGUF格式，便于在本地部署。该指南降低了大模型工具调用开发门槛，推动个性化AI应用落地。</p>\n<hr />\n<hr />\n<h2 id=\"_2\">🎬 视频链接</h2>\n<p><strong>Bilibili</strong>： <a href=\"https://www.bilibili.com/video/BV1LHB3BHEJP\">https://www.bilibili.com/video/BV1LHB3BHEJP</a></p>\n<hr />\n<p><em>整理自橘鸦AI早报 | BV号：BV1LHB3BHEJP | 2025-12-24 09:03:39</em></p>",
  "content": "# MiniMax正式发布M2.1模型；Qwen开源Qwen-Image-Edit-2511模型【AI 早报 2025-12-24】\n\n**📅 发布日期：** 2025-12-24\n**🎬 BV号：** [BV1LHB3BHEJP](https://www.bilibili.com/video/BV1LHB3BHEJP)\n**📝 整理时间：** 2025-12-24 09:03:39\n**📊 资讯数量：** 9 条\n\n---\n\n## 📋 本期概览\n\n1. 🚀 MiniMax发布M2.1模型，移动端性能显著提升\n2. 🚀 Qwen开源Qwen-Image-Edit-2511图像编辑模型\n3. 🚀 Qwen推出Qwen3-TTS系列语音合成模型\n4. 🚀 阿里云通义Fun团队开源Audio-Chat-8B音频模型\n5. 🔧 智谱团队透露GLM-5规划并即将发布新IDE工具\n6. 🔧 Diffusers新增Z-Image-Omni-Base模型\n7. 📈 Poetiq harness刷新ARC-AGI-2评测纪录至75%\n8. 🚀 xAI发布Grok Collections API，集成OCR与RAG技术\n9. 🔧 FunctionGemma本地微调指南发布，支持自定义工具调用\n\n---\n\n### 1. 🚀 MiniMax发布M2.1模型，移动端性能显著提升 {#1-MiniMax发布M21模型移动端性能显著提升}\n\n**标签**： `MiniMax` `MiniMax-M2.1` `VIBE`\n\nMiniMax于2025年12月24日正式发布并开源其旗舰模型MiniMax-M2.1，该模型在SW Bench评测中得分达74.0%，较前代有显著提升。M2.1针对移动端场景进行了深度优化，重点增强场景式构建能力，旨在推动AI在移动生产环境中的落地应用。目前，该模型的API及相关Agents产品已全面开放，开发者可通过Hugging Face和MiniMax官网获取模型权重与接入文档。此外，配套发布的VIBE模型进一步提升了多模态交互体验，支持更自然的移动端AI应用开发。\n\n**🔗 相关链接：**\n- <https://www.minimaxi.com/news/minimax-m21>\n- <https://huggingface.co/MiniMaxAI/MiniMax-M2.1>\n- <https://huggingface.co/MiniMaxAI/VIBE>\n\n---\n\n### 2. 🚀 Qwen开源Qwen-Image-Edit-2511图像编辑模型 {#2-Qwen开源Qwen-Image-Edit-2511图像编辑}\n\n**标签**： `Qwen` `Qwen-Image-Edit-2511` `阿里云`\n\n阿里云通义千问团队于12月24日开源Qwen-Image-Edit-2511模型，该模型在多人一致性与图像生成质量方面实现大幅提升。新版本集成了流行的LoRA功能，支持灯光增强、新视角生成和几何作图等高级编辑能力。用户可通过Qwen Chat的图像编辑功能直接体验该模型，适用于创意设计、内容生成等场景。模型已在ModelScope和GitHub开源，提供完整权重与推理代码，推动开源图像编辑技术发展。\n\n**🔗 相关链接：**\n- <https://qwenlm.github.io/blog/qwen-image-edit-2511/>\n- <https://modelscope.cn/models/Qwen/Qwen-Image-Edit-2511>\n- <https://chat.qwen.ai/?inputFeature=image_edit>\n\n---\n\n### 3. 🚀 Qwen推出Qwen3-TTS系列语音合成模型 {#3-Qwen推出Qwen3-TTS系列语音合成模型}\n\n**标签**： `Qwen` `Qwen3-TTS` `VD-Flash` `VC-Flash`\n\nQwen团队同期发布Qwen3-TTS系列两款语音合成模型：VD-Flash支持通过自然语言指令自定义音色，实现高度个性化的语音生成；VC-Flash仅需3秒音频样本即可完成音色克隆，支持中、英、日等10种语言。两款模型均针对低延迟场景优化，适用于智能客服、有声内容制作等应用，显著提升语音交互的自然度与效率。\n\n**🔗 相关链接：**\n- <https://qwenlm.github.io/blog/qwen-image-edit-2511/>\n- <https://modelscope.cn/models/Qwen/Qwen-Image-Edit-2511>\n- <https://chat.qwen.ai/?inputFeature=image_edit>\n\n---\n\n### 4. 🚀 阿里云通义Fun团队开源Audio-Chat-8B音频模型 {#4-阿里云通义Fun团队开源Audio-Chat-8B音频模型}\n\n**标签**： `阿里云` `Audio-Chat-8B` `通义Fun`\n\n阿里云通义Fun团队开源80亿参数音频语言模型Audio-Chat-8B，专为低延迟自然语音交互设计。该模型在多项基准测试中表现优异，位居同尺寸模型前列，支持实时语音理解与生成。模型权重与训练代码已全面开放，适用于智能助手、语音交互系统等场景，推动轻量化语音AI技术的普及。\n\n---\n\n### 5. 🔧 智谱团队透露GLM-5规划并即将发布新IDE工具 {#5-智谱团队透露GLM-5规划并即将发布新IDE工具}\n\n**标签**： `智谱AI` `GLM-5` `再扣IDE`\n\n智谱AI团队在Reddit AMA活动中透露，正在开发名为“再扣”的IDE工具，预计即将对外发布。该IDE将深度集成GLM系列模型，提供代码补全、智能调试等功能。团队同时确认已对GLM-5进行大量适配优化，未来将支持更复杂的开发场景，提升AI辅助编程体验。\n\n**🔗 相关链接：**\n- <https://www.reddit.com/r/LocalLLaMA/comments/1ptxm3x/ama_with_zai_the_lab_behind_glm47/>\n\n---\n\n### 6. 🔧 Diffusers新增Z-Image-Omni-Base模型 {#6-Diffusers新增Z-Image-Omni-Base模型}\n\n**标签**： `Hugging Face` `Diffusers` `Z-Image-Omni-Base`\n\nHugging Face的Diffusers库新增Z-Image-Omni-Base模型，该模型支持多模态图像生成与理解任务，具备跨域适应能力。此次更新通过GitHub Pull Request #12857实现，社区讨论活跃，预示该模型即将正式发布。Z-Image-Omni-Base有望在图像编辑、内容生成等领域提供更强性能。\n\n**🔗 相关链接：**\n- <https://github.com/huggingface/diffusers/pull/12857>\n- <https://linux.do/t/topic/1354686>\n\n---\n\n### 7. 📈 Poetiq harness刷新ARC-AGI-2评测纪录至75% {#7-Poetiq-harness刷新ARC-AGI-2评测纪录至}\n\n**标签**： `Poetiq` `GPT-5.2X Hi` `ARC-AGI-2`\n\nAI公司Poetiq官方宣布，其基于GPT-5.2X Hi模型与Poetiq Carness系统，在ARC-AGI-2通用人工智能评测中创下75%的历史新高，刷新此前纪录。该成绩表明其在复杂推理与任务泛化能力上的重大突破，为AGI发展提供重要参考。\n\n**🔗 相关链接：**\n- <https://x.com/poetiq_ai/status/2003546910427361402>\n\n---\n\n### 8. 🚀 xAI发布Grok Collections API，集成OCR与RAG技术 {#8-xAI发布Grok-Collections-API集成OCR}\n\n**标签**： `xAI` `Grok Collections API` `RAG`\n\nxAI于12月24日正式推出Grok Collections API，这是一款集成OCR与布局感知技术的先进RAG（检索增强生成）系统。开发者可直接上传PDF或代码库，自动构建知识库并实现智能问答。API首周免费，支持高效文档理解与知识提取，适用于企业知识管理、法律分析等场景。\n\n**🔗 相关链接：**\n- <https://x.ai/news/grok-collections-api>\n\n---\n\n### 9. 🔧 FunctionGemma本地微调指南发布，支持自定义工具调用 {#9-FunctionGemma本地微调指南发布支持自定义工具调用}\n\n**标签**： `Unsloth AI` `LM Studio` `FunctionGemma`\n\nUnsloth AI与LM Studio联合发布FunctionGemma模型本地微调技术指南，指导用户基于Google Function Gemma模型实现自定义工具调用。教程提供免费的Colab笔记本，支持将微调后的模型转换为GGUF格式，便于在本地部署。该指南降低了大模型工具调用开发门槛，推动个性化AI应用落地。\n\n---\n\n---\n\n## 🎬 视频链接\n\n**Bilibili**： <https://www.bilibili.com/video/BV1LHB3BHEJP>\n\n---\n\n*整理自橘鸦AI早报 | BV号：BV1LHB3BHEJP | 2025-12-24 09:03:39*"
}