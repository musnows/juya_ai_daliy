{
  "title": "通义千问发布Qwen-Image-2512；腾讯混元开源Youtu-LLM-2B；小米延长MiMo-V2-Flash公测【AI 早报 2026-01-01】",
  "publish_date": "2026-01-01",
  "bv_id": "BV18WiLBUEP6",
  "organize_time": "2026-01-01 09:12:59",
  "news_count": 13,
  "overview": "1. 🚀 通义千问发布Qwen-Image-2512图像生成模型\n2. 🚀 腾讯开源Youtu-LLM-2B小型大语言模型\n3. 🔧 小米延长MiMo-V2-Flash模型免费公测至1月20日\n4. 🔧 Qwen Code发布v0.6.0版本，新增实验性Skills功能\n5. 🚀 SK Telecom开源A.X-K1大模型，支持13万上下文\n6. 🚀 LG AI Research发布K-EXAONE-236B-A23B混合专家模型\n7. 🚀 Upstage发布Solar-Open-100B商用开源模型\n8. 🚀 NC-AI consortium开源VAETKI-112B-A10B多语言模型\n9. 🚀 细红线发布AI讲书应用“且听”\n10. 📈 月之暗面完成5亿美元C轮融资，估值达43亿美元\n11. 📈 英伟达洽谈30亿美元收购AI21 Labs\n12. 📈 软银40亿美元收购DigitalBridge布局AI算力\n13. 📈 xAI建设第三座超大规模数据中心",
  "html_content": "<h2 id=\"_1\">📋 本期概览</h2>\n<ol>\n<li>🚀 通义千问发布Qwen-Image-2512图像生成模型</li>\n<li>🚀 腾讯开源Youtu-LLM-2B小型大语言模型</li>\n<li>🔧 小米延长MiMo-V2-Flash模型免费公测至1月20日</li>\n<li>🔧 Qwen Code发布v0.6.0版本，新增实验性Skills功能</li>\n<li>🚀 SK Telecom开源A.X-K1大模型，支持13万上下文</li>\n<li>🚀 LG AI Research发布K-EXAONE-236B-A23B混合专家模型</li>\n<li>🚀 Upstage发布Solar-Open-100B商用开源模型</li>\n<li>🚀 NC-AI consortium开源VAETKI-112B-A10B多语言模型</li>\n<li>🚀 细红线发布AI讲书应用“且听”</li>\n<li>📈 月之暗面完成5亿美元C轮融资，估值达43亿美元</li>\n<li>📈 英伟达洽谈30亿美元收购AI21 Labs</li>\n<li>📈 软银40亿美元收购DigitalBridge布局AI算力</li>\n<li>📈 xAI建设第三座超大规模数据中心</li>\n</ol>\n<hr />\n<h3 id=\"1-通义千问发布Qwen-Image-2512图像生成模型\">1. 🚀 通义千问发布Qwen-Image-2512图像生成模型</h3>\n<p><strong>标签</strong>： <code>通义千问</code> <code>Qwen-Image-2512</code></p>\n<p>阿里巴巴通义千问于2026年1月1日正式发布新一代图像生成模型Qwen-Image-2512。该模型在人物质感、自然纹理渲染和复杂文字生成方面实现显著提升，有效降低生成图像的‘AI感’，使输出更接近真实摄影效果。目前该模型已在千问Chat平台上线，并在Hugging Face等平台开源权重。此次发布标志着通义千问在多模态AI领域的技术突破，尤其适用于广告设计、内容创作和数字媒体等对图像真实感要求较高的应用场景。</p>\n<hr />\n<h3 id=\"2-腾讯开源Youtu-LLM-2B小型大语言模型\">2. 🚀 腾讯开源Youtu-LLM-2B小型大语言模型</h3>\n<p><strong>标签</strong>： <code>腾讯</code> <code>Youtu-LLM-2B</code></p>\n<p>腾讯混元团队发布并开源了轻量级大语言模型Youtu-LLM-2B，该模型拥有19.6亿参数，支持长达13万token的超长上下文处理能力，具备原生智能体（Agent）功能。评测结果显示，其在同规模开源模型中表现领先。模型提供基础版和指令微调版两个版本，适用于边缘设备部署和长文本理解任务，如文档摘要、智能客服和多轮对话系统，显著提升了小参数模型的应用边界。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://huggingface.co/tencent/Youtu-LLM-2B\">https://huggingface.co/tencent/Youtu-LLM-2B</a></p>\n<hr />\n<h3 id=\"3-小米延长MiMo-V2-Flash模型免费公测至1月20日\">3. 🔧 小米延长MiMo-V2-Flash模型免费公测至1月20日</h3>\n<p><strong>标签</strong>： <code>小米</code> <code>MiMo-V2-Flash</code></p>\n<p>小米AI平台MiMo宣布将其MiMo-V2-Flash模型的免费公测期延长至2026年1月20日。官方支付系统即将上线，并公布未来定价策略：国内每百万输入token收费0.7元，输出token收费2.1元。该模型支持高效推理与低成本部署，适用于智能助手、内容生成等场景。延长公测旨在收集更多用户反馈，优化模型性能与服务稳定性。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://platform.xiaomimimo.com\">https://platform.xiaomimimo.com</a></p>\n<hr />\n<h3 id=\"4-Qwen-Code发布v060版本新增实验性Skills功能\">4. 🔧 Qwen Code发布v0.6.0版本，新增实验性Skills功能</h3>\n<p><strong>标签</strong>： <code>通义千问</code> <code>Qwen Code</code></p>\n<p>通义千问代码助手Qwen Code发布v0.6.0版本更新，引入实验性Skills功能，支持与Jamni和Anthropic服务商集成。此次更新优化了VS Code插件体验，新增压缩与摘要命令，提升非交互式编程场景下的效率。该版本进一步强化了代码理解、补全与重构能力，适用于开发者日常编码、文档生成和代码审查等任务。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/Alibaba_Qwen/status/2006025958055346222\">https://x.com/Alibaba_Qwen/status/2006025958055346222</a></p>\n<hr />\n<h3 id=\"5-SK-Telecom开源AX-K1大模型支持13万上下文\">5. 🚀 SK Telecom开源A.X-K1大模型，支持13万上下文</h3>\n<p><strong>标签</strong>： <code>SK Telecom</code> <code>A.X-K1</code></p>\n<p>韩国SK Telecom正式开源5191参数的大模型A.X-K1，采用稀疏混合专家（MoE）架构，支持13万token的上下文长度，并提供混合推理模式以平衡深度与延迟。该模型专为高效长文本处理设计，评估结果计划于2026年1月4日公布。其开源将推动韩语及东亚语言AI研究的发展，适用于法律文本分析、长文档摘要等复杂场景。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://huggingface.co/skt/A.X-K1\">https://huggingface.co/skt/A.X-K1</a></p>\n<hr />\n<h3 id=\"6-LG-AI-Research发布K-EXAONE-236B-\">6. 🚀 LG AI Research发布K-EXAONE-236B-A23B混合专家模型</h3>\n<p><strong>标签</strong>： <code>LG AI Research</code> <code>K-EXAONE-236B-A23B</code></p>\n<p>LG AI Research发布大规模混合专家模型K-EXAONE-236B-A23B，总参数量达236B，支持256K长文本输入。该模型采用多令牌预测技术，推理吞吐量提升1.5倍，涵盖中、英、韩、日等6种语言，并针对韩国文化背景进行专门优化。适用于多语言内容生成、跨文化交流与企业级AI应用，体现LG在垂直领域大模型布局的战略意图。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://huggingface.co/LGAI-EXAONE/K-EXAONE-236B-A23B\">https://huggingface.co/LGAI-EXAONE/K-EXAONE-236B-A23B</a></p>\n<hr />\n<h3 id=\"7-Upstage发布Solar-Open-100B商用开源模型\">7. 🚀 Upstage发布Solar-Open-100B商用开源模型</h3>\n<p><strong>标签</strong>： <code>Upstage</code> <code>Solar-Open-100B</code></p>\n<p>韩国AI公司Upstage发布旗舰级开源模型Solar-Open-100B，采用混合专家架构，预训练数据量达19.7万亿token，支持128K上下文长度。模型采用允许商用的开源协议，官方API预计于2026年1月正式上线。该模型面向企业级应用，适用于大规模文本生成、知识问答和自动化内容生产，具备高扩展性与部署灵活性。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://huggingface.co/upstage/Solar-Open-100B\">https://huggingface.co/upstage/Solar-Open-100B</a></p>\n<hr />\n<h3 id=\"8-NC-AI-consortium开源VAETKI-112B-\">8. 🚀 NC-AI consortium开源VAETKI-112B-A10B多语言模型</h3>\n<p><strong>标签</strong>： <code>NC-AI consortium</code> <code>VAETKI-112B-A10B</code></p>\n<p>韩国NC-AI财团发布并开源112B参数的混合专家模型VAETKI-112B-A10B，支持中、英、韩、日四种语言，特别针对工具调用任务优化推理模式。模型遵循MIT协议开源，代码与权重已在GitHub和Hugging Face平台发布。该模型适用于智能体系统、API调用自动化和多语言交互场景，推动开源AI生态的多元化发展。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://huggingface.co/NC-AI-consortium-VAETKI/VAETKI\">https://huggingface.co/NC-AI-consortium-VAETKI/VAETKI</a><br />\n- <a href=\"https://github.com/wbl-ncai/VAETKI/\">https://github.com/wbl-ncai/VAETKI/</a></p>\n<hr />\n<h3 id=\"9-细红线发布AI讲书应用且听\">9. 🚀 细红线发布AI讲书应用“且听”</h3>\n<p><strong>标签</strong>： <code>细红线</code> <code>且听</code></p>\n<p>罗永浩旗下细红线公司推出AI讲书应用“且听”，利用大模型技术对书籍进行结构化拆解与深度解读。每本书生成时长为1至2小时的精华讲解内容，涵盖核心观点、逻辑框架与实用建议。该应用面向知识付费与终身学习人群，旨在提升阅读效率与理解深度，是AI赋能教育内容消费的创新尝试。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://erduoshuku.cn/\">https://erduoshuku.cn/</a></p>\n<hr />\n<h3 id=\"10-月之暗面完成5亿美元C轮融资估值达43亿美元\">10. 📈 月之暗面完成5亿美元C轮融资，估值达43亿美元</h3>\n<p><strong>标签</strong>： <code>月之暗面</code> <code>K3模型</code></p>\n<p>AI公司月之暗面宣布完成5亿美元C轮融资，投后估值达到43亿美元。公司目前现金储备超过100亿元人民币，资金将主要用于研发下一代旗舰模型K3，目标在2026年实现预训练性能追平全球顶尖水平。此次融资反映资本市场对国产大模型技术路线的高度认可，有望加速其在对话AI与通用智能领域的布局。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://mp.weixin.qq.com/s/gtPTI2Cf2WwGUBcn_yc9uQ\">https://mp.weixin.qq.com/s/gtPTI2Cf2WwGUBcn_yc9uQ</a><br />\n- <a href=\"https://zhidx.com/p/525570.html\">https://zhidx.com/p/525570.html</a></p>\n<hr />\n<h3 id=\"11-英伟达洽谈30亿美元收购AI21-Labs\">11. 📈 英伟达洽谈30亿美元收购AI21 Labs</h3>\n<p><strong>标签</strong>： <code>英伟达</code> <code>AI21 Labs</code></p>\n<p>据媒体报道，英伟达正与以色列AI初创公司AI21 Labs进行谈判，拟以最高30亿美元的价格完成收购。此举主要目的在于获取AI21 Labs在自然语言处理领域的顶尖人才与技术积累。目前交易仍处于谈判阶段，若成功将进一步加强英伟达在生成式AI基础设施与软件生态中的战略地位。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://the-decoder.com/nvidia-reportedly-in-talks-to-acquire-ai-start-up-ai21-labs-for-up-to-3-billion/\">https://the-decoder.com/nvidia-reportedly-in-talks-to-acquire-ai-start-up-ai21-labs-for-up-to-3-billion/</a></p>\n<hr />\n<h3 id=\"12-软银40亿美元收购DigitalBridge布局AI算力\">12. 📈 软银40亿美元收购DigitalBridge布局AI算力</h3>\n<p><strong>标签</strong>： <code>软银</code> <code>DigitalBridge</code></p>\n<p>软银集团宣布将以约40亿美元收购数字基础设施公司DigitalBridge，交易预计在2026年下半年完成，尚需监管批准。此次收购旨在强化软银在AI数据中心与算力平台领域的布局，为其投资组合中的AI公司提供底层算力支持，应对日益增长的AI训练与推理需求。</p>\n<hr />\n<h3 id=\"13-xAI建设第三座超大规模数据中心\">13. 📈 xAI建设第三座超大规模数据中心</h3>\n<p><strong>标签</strong>： <code>xAI</code> <code>Grok</code></p>\n<p>马斯克旗下xAI公司正在建设第三座超大规模数据中心，通过改造现有仓库设施实现快速部署，计划于2026年开始运行。该设施将显著提升xAI的算力储备，支持其大模型训练与推理需求，尤其是为Grok系列模型的迭代提供基础设施保障，标志着xAI在算力自主化道路上的重要进展。</p>\n<hr />\n<hr />\n<h2 id=\"_2\">🎬 视频链接</h2>\n<p><strong>Bilibili</strong>： <a href=\"https://www.bilibili.com/video/BV18WiLBUEP6\">https://www.bilibili.com/video/BV18WiLBUEP6</a></p>\n<hr />\n<p><em>整理自橘鸦AI早报 | BV号：BV18WiLBUEP6 | 2026-01-01 09:12:59</em></p>",
  "content": "# 通义千问发布Qwen-Image-2512；腾讯混元开源Youtu-LLM-2B；小米延长MiMo-V2-Flash公测【AI 早报 2026-01-01】\n\n**📅 发布日期：** 2026-01-01\n**🎬 BV号：** [BV18WiLBUEP6](https://www.bilibili.com/video/BV18WiLBUEP6)\n**📝 整理时间：** 2026-01-01 09:12:59\n**📊 资讯数量：** 13 条\n\n---\n\n## 📋 本期概览\n\n1. 🚀 通义千问发布Qwen-Image-2512图像生成模型\n2. 🚀 腾讯开源Youtu-LLM-2B小型大语言模型\n3. 🔧 小米延长MiMo-V2-Flash模型免费公测至1月20日\n4. 🔧 Qwen Code发布v0.6.0版本，新增实验性Skills功能\n5. 🚀 SK Telecom开源A.X-K1大模型，支持13万上下文\n6. 🚀 LG AI Research发布K-EXAONE-236B-A23B混合专家模型\n7. 🚀 Upstage发布Solar-Open-100B商用开源模型\n8. 🚀 NC-AI consortium开源VAETKI-112B-A10B多语言模型\n9. 🚀 细红线发布AI讲书应用“且听”\n10. 📈 月之暗面完成5亿美元C轮融资，估值达43亿美元\n11. 📈 英伟达洽谈30亿美元收购AI21 Labs\n12. 📈 软银40亿美元收购DigitalBridge布局AI算力\n13. 📈 xAI建设第三座超大规模数据中心\n\n---\n\n### 1. 🚀 通义千问发布Qwen-Image-2512图像生成模型 {#1-通义千问发布Qwen-Image-2512图像生成模型}\n\n**标签**： `通义千问` `Qwen-Image-2512`\n\n阿里巴巴通义千问于2026年1月1日正式发布新一代图像生成模型Qwen-Image-2512。该模型在人物质感、自然纹理渲染和复杂文字生成方面实现显著提升，有效降低生成图像的‘AI感’，使输出更接近真实摄影效果。目前该模型已在千问Chat平台上线，并在Hugging Face等平台开源权重。此次发布标志着通义千问在多模态AI领域的技术突破，尤其适用于广告设计、内容创作和数字媒体等对图像真实感要求较高的应用场景。\n\n---\n\n### 2. 🚀 腾讯开源Youtu-LLM-2B小型大语言模型 {#2-腾讯开源Youtu-LLM-2B小型大语言模型}\n\n**标签**： `腾讯` `Youtu-LLM-2B`\n\n腾讯混元团队发布并开源了轻量级大语言模型Youtu-LLM-2B，该模型拥有19.6亿参数，支持长达13万token的超长上下文处理能力，具备原生智能体（Agent）功能。评测结果显示，其在同规模开源模型中表现领先。模型提供基础版和指令微调版两个版本，适用于边缘设备部署和长文本理解任务，如文档摘要、智能客服和多轮对话系统，显著提升了小参数模型的应用边界。\n\n**🔗 相关链接：**\n- <https://huggingface.co/tencent/Youtu-LLM-2B>\n\n---\n\n### 3. 🔧 小米延长MiMo-V2-Flash模型免费公测至1月20日 {#3-小米延长MiMo-V2-Flash模型免费公测至1月20日}\n\n**标签**： `小米` `MiMo-V2-Flash`\n\n小米AI平台MiMo宣布将其MiMo-V2-Flash模型的免费公测期延长至2026年1月20日。官方支付系统即将上线，并公布未来定价策略：国内每百万输入token收费0.7元，输出token收费2.1元。该模型支持高效推理与低成本部署，适用于智能助手、内容生成等场景。延长公测旨在收集更多用户反馈，优化模型性能与服务稳定性。\n\n**🔗 相关链接：**\n- <https://platform.xiaomimimo.com>\n\n---\n\n### 4. 🔧 Qwen Code发布v0.6.0版本，新增实验性Skills功能 {#4-Qwen-Code发布v060版本新增实验性Skills功能}\n\n**标签**： `通义千问` `Qwen Code`\n\n通义千问代码助手Qwen Code发布v0.6.0版本更新，引入实验性Skills功能，支持与Jamni和Anthropic服务商集成。此次更新优化了VS Code插件体验，新增压缩与摘要命令，提升非交互式编程场景下的效率。该版本进一步强化了代码理解、补全与重构能力，适用于开发者日常编码、文档生成和代码审查等任务。\n\n**🔗 相关链接：**\n- <https://x.com/Alibaba_Qwen/status/2006025958055346222>\n\n---\n\n### 5. 🚀 SK Telecom开源A.X-K1大模型，支持13万上下文 {#5-SK-Telecom开源AX-K1大模型支持13万上下文}\n\n**标签**： `SK Telecom` `A.X-K1`\n\n韩国SK Telecom正式开源5191参数的大模型A.X-K1，采用稀疏混合专家（MoE）架构，支持13万token的上下文长度，并提供混合推理模式以平衡深度与延迟。该模型专为高效长文本处理设计，评估结果计划于2026年1月4日公布。其开源将推动韩语及东亚语言AI研究的发展，适用于法律文本分析、长文档摘要等复杂场景。\n\n**🔗 相关链接：**\n- <https://huggingface.co/skt/A.X-K1>\n\n---\n\n### 6. 🚀 LG AI Research发布K-EXAONE-236B-A23B混合专家模型 {#6-LG-AI-Research发布K-EXAONE-236B-}\n\n**标签**： `LG AI Research` `K-EXAONE-236B-A23B`\n\nLG AI Research发布大规模混合专家模型K-EXAONE-236B-A23B，总参数量达236B，支持256K长文本输入。该模型采用多令牌预测技术，推理吞吐量提升1.5倍，涵盖中、英、韩、日等6种语言，并针对韩国文化背景进行专门优化。适用于多语言内容生成、跨文化交流与企业级AI应用，体现LG在垂直领域大模型布局的战略意图。\n\n**🔗 相关链接：**\n- <https://huggingface.co/LGAI-EXAONE/K-EXAONE-236B-A23B>\n\n---\n\n### 7. 🚀 Upstage发布Solar-Open-100B商用开源模型 {#7-Upstage发布Solar-Open-100B商用开源模型}\n\n**标签**： `Upstage` `Solar-Open-100B`\n\n韩国AI公司Upstage发布旗舰级开源模型Solar-Open-100B，采用混合专家架构，预训练数据量达19.7万亿token，支持128K上下文长度。模型采用允许商用的开源协议，官方API预计于2026年1月正式上线。该模型面向企业级应用，适用于大规模文本生成、知识问答和自动化内容生产，具备高扩展性与部署灵活性。\n\n**🔗 相关链接：**\n- <https://huggingface.co/upstage/Solar-Open-100B>\n\n---\n\n### 8. 🚀 NC-AI consortium开源VAETKI-112B-A10B多语言模型 {#8-NC-AI-consortium开源VAETKI-112B-}\n\n**标签**： `NC-AI consortium` `VAETKI-112B-A10B`\n\n韩国NC-AI财团发布并开源112B参数的混合专家模型VAETKI-112B-A10B，支持中、英、韩、日四种语言，特别针对工具调用任务优化推理模式。模型遵循MIT协议开源，代码与权重已在GitHub和Hugging Face平台发布。该模型适用于智能体系统、API调用自动化和多语言交互场景，推动开源AI生态的多元化发展。\n\n**🔗 相关链接：**\n- <https://huggingface.co/NC-AI-consortium-VAETKI/VAETKI>\n- <https://github.com/wbl-ncai/VAETKI/>\n\n---\n\n### 9. 🚀 细红线发布AI讲书应用“且听” {#9-细红线发布AI讲书应用且听}\n\n**标签**： `细红线` `且听`\n\n罗永浩旗下细红线公司推出AI讲书应用“且听”，利用大模型技术对书籍进行结构化拆解与深度解读。每本书生成时长为1至2小时的精华讲解内容，涵盖核心观点、逻辑框架与实用建议。该应用面向知识付费与终身学习人群，旨在提升阅读效率与理解深度，是AI赋能教育内容消费的创新尝试。\n\n**🔗 相关链接：**\n- <https://erduoshuku.cn/>\n\n---\n\n### 10. 📈 月之暗面完成5亿美元C轮融资，估值达43亿美元 {#10-月之暗面完成5亿美元C轮融资估值达43亿美元}\n\n**标签**： `月之暗面` `K3模型`\n\nAI公司月之暗面宣布完成5亿美元C轮融资，投后估值达到43亿美元。公司目前现金储备超过100亿元人民币，资金将主要用于研发下一代旗舰模型K3，目标在2026年实现预训练性能追平全球顶尖水平。此次融资反映资本市场对国产大模型技术路线的高度认可，有望加速其在对话AI与通用智能领域的布局。\n\n**🔗 相关链接：**\n- <https://mp.weixin.qq.com/s/gtPTI2Cf2WwGUBcn_yc9uQ>\n- <https://zhidx.com/p/525570.html>\n\n---\n\n### 11. 📈 英伟达洽谈30亿美元收购AI21 Labs {#11-英伟达洽谈30亿美元收购AI21-Labs}\n\n**标签**： `英伟达` `AI21 Labs`\n\n据媒体报道，英伟达正与以色列AI初创公司AI21 Labs进行谈判，拟以最高30亿美元的价格完成收购。此举主要目的在于获取AI21 Labs在自然语言处理领域的顶尖人才与技术积累。目前交易仍处于谈判阶段，若成功将进一步加强英伟达在生成式AI基础设施与软件生态中的战略地位。\n\n**🔗 相关链接：**\n- <https://the-decoder.com/nvidia-reportedly-in-talks-to-acquire-ai-start-up-ai21-labs-for-up-to-3-billion/>\n\n---\n\n### 12. 📈 软银40亿美元收购DigitalBridge布局AI算力 {#12-软银40亿美元收购DigitalBridge布局AI算力}\n\n**标签**： `软银` `DigitalBridge`\n\n软银集团宣布将以约40亿美元收购数字基础设施公司DigitalBridge，交易预计在2026年下半年完成，尚需监管批准。此次收购旨在强化软银在AI数据中心与算力平台领域的布局，为其投资组合中的AI公司提供底层算力支持，应对日益增长的AI训练与推理需求。\n\n---\n\n### 13. 📈 xAI建设第三座超大规模数据中心 {#13-xAI建设第三座超大规模数据中心}\n\n**标签**： `xAI` `Grok`\n\n马斯克旗下xAI公司正在建设第三座超大规模数据中心，通过改造现有仓库设施实现快速部署，计划于2026年开始运行。该设施将显著提升xAI的算力储备，支持其大模型训练与推理需求，尤其是为Grok系列模型的迭代提供基础设施保障，标志着xAI在算力自主化道路上的重要进展。\n\n---\n\n---\n\n## 🎬 视频链接\n\n**Bilibili**： <https://www.bilibili.com/video/BV18WiLBUEP6>\n\n---\n\n*整理自橘鸦AI早报 | BV号：BV18WiLBUEP6 | 2026-01-01 09:12:59*"
}