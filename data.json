{
  "newspapers": [
    {
      "title": "腾讯开源HunyuanVideo-1.5视频模型；小米发布跨具身基础模型MiMo-Embodied【AI 早报 2025-11-22】",
      "publish_date": "2025-11-22",
      "bv_id": "BV1a3UHBNENX",
      "organize_time": "2025-11-22 08:59:05",
      "news_count": 18,
      "overview": "1. 🚀 腾讯开源HunyuanVideo-1.5视频模型\n2. 🚀 小米发布跨具身基础模型MiMo-Embodied\n3. 🚀 ServiceNow发布Apriel-H1模型系列\n4. 🚀 豆包输入法上线多语种语音输入\n5. 🔧 Gemini CLI开放Gemini 3 Pro访问\n6. 🔧 智谱AI升级GLM Coding Plan\n7. 🔧 Cursor发布2.1版本更新功能\n8. 🔧 Claude Code CLI新增后台任务转移\n9. 🔧 Sora 2更新“故事板块”功能\n10. 📈 OpenAI发布AI-Native工程团队指南\n11. 🔧 Dify发布v1.10.0版本Workflow Trigger\n12. 🚀 Genspark发布AI工作空间并完成B轮融资\n13. 🔧 Ollama v0.13支持DeepSeek-OCR\n14. 📈 Hugging Face更新Open ASR Leaderboard\n15. 🚀 OCR Arena推出VLM与OCR对比平台\n16. 🔧 Gradio 6发布重大更新与性能提升\n17. 📈 Brookfield联合NVIDIA启动千亿AI基建项目\n18. 📈 Adobe收购AI营销公司Semrush",
      "content": "# 腾讯开源HunyuanVideo-1.5视频模型；小米发布跨具身基础模型MiMo-Embodied【AI 早报 2025-11-22】\n\n**📅 发布日期：** 2025-11-22\n**🎬 BV号：** BV1a3UHBNENX\n**📝 整理时间：** 2025-11-22 08:59:05\n**📊 资讯数量：** 18 条\n\n---\n\n## 📋 本期概览\n\n1. 🚀 腾讯开源HunyuanVideo-1.5视频模型\n2. 🚀 小米发布跨具身基础模型MiMo-Embodied\n3. 🚀 ServiceNow发布Apriel-H1模型系列\n4. 🚀 豆包输入法上线多语种语音输入\n5. 🔧 Gemini CLI开放Gemini 3 Pro访问\n6. 🔧 智谱AI升级GLM Coding Plan\n7. 🔧 Cursor发布2.1版本更新功能\n8. 🔧 Claude Code CLI新增后台任务转移\n9. 🔧 Sora 2更新“故事板块”功能\n10. 📈 OpenAI发布AI-Native工程团队指南\n11. 🔧 Dify发布v1.10.0版本Workflow Trigger\n12. 🚀 Genspark发布AI工作空间并完成B轮融资\n13. 🔧 Ollama v0.13支持DeepSeek-OCR\n14. 📈 Hugging Face更新Open ASR Leaderboard\n15. 🚀 OCR Arena推出VLM与OCR对比平台\n16. 🔧 Gradio 6发布重大更新与性能提升\n17. 📈 Brookfield联合NVIDIA启动千亿AI基建项目\n18. 📈 Adobe收购AI营销公司Semrush\n\n---\n\n### 1. 🚀 腾讯开源HunyuanVideo-1.5视频模型 {#1-腾讯开源HunyuanVideo-15视频模型}\n\n**标签：** `腾讯` `HunyuanVideo-1.5` `视频生成模型`\n\n腾讯于近日开源了其最新一代视频生成模型 HunyuanVideo-1.5，该模型在 Hugging Face、GitHub 及腾讯混元官网同步发布。HunyuanVideo-1.5 是腾讯混元大模型在视频生成领域的重要升级，支持更高分辨率、更长时序的视频生成，具备更强的语义理解与动作连贯性。模型采用自研的3D变分自编码器（VAE）与扩散架构，支持文本到视频（T2V）生成，可生成最高1080p、120帧的视频内容。此次开源包含完整的训练与推理代码、预训练权重及示例应用，推动多模态生成式AI的社区发展。该模型适用于影视制作、广告创意、虚拟数字人等场景，进一步降低高质量视频生成技术门槛。\n\n**🔗 相关链接：**\n- <https://huggingface.co/tencent/HunyuanVideo-1.5>\n- <https://hunyuan.tencent.com/video/zh?tabIndex=0>\n- <https://github.com/Tencent-Hunyuan/HunyuanVideo-1.5>\n\n---\n\n### 2. 🚀 小米发布跨具身基础模型MiMo-Embodied {#2-小米发布跨具身基础模型MiMo-Embodied}\n\n**标签：** `小米` `MiMo-Embodied-7B` `具身智能`\n\n小米发布跨具身基础模型 MiMo-Embodied-7B，该模型专注于机器人与具身智能（Embodied AI）领域，支持多模态感知与动作规划。MiMo-Embodied 基于7B参数架构，融合视觉、语言与运动控制信号，可在真实物理环境中实现任务理解、路径规划与动作执行。模型已在 arXiv 上发布技术论文（arXiv:2511.16518），并在 Hugging Face 开源模型权重，支持社区进行机器人控制、家庭服务机器人、工业自动化等下游任务微调。该模型标志着小米在AI+机器人融合方向迈出关键一步，有望推动具身智能的规模化落地。\n\n**🔗 相关链接：**\n- <https://arxiv.org/abs/2511.16518>\n- <https://huggingface.co/XiaomiMiMo/MiMo-Embodied-7B>\n\n---\n\n### 3. 🚀 ServiceNow发布Apriel-H1模型系列 {#3-ServiceNow发布Apriel-H1模型系列}\n\n**标签：** `ServiceNow-AI` `Apriel-H1` `企业级AI`\n\nServiceNow-AI 发布 Apriel-H1 模型系列，专为企业级AI应用设计，聚焦于代码生成、文档理解与自动化流程优化。该系列模型基于混合架构，支持长上下文处理（最高32K tokens），在 Hugging Face 上提供多个变体，包括代码生成、文本分类与问答专用模型。Apriel-H1 强调安全合规、可解释性与低延迟推理，适用于IT服务管理（ITSM）、客户支持自动化、知识库问答等场景。官方博客同步发布技术细节，强调其在企业私有部署中的隐私保护能力，是ServiceNow构建AI原生工作流平台的核心组件。\n\n**🔗 相关链接：**\n- <https://huggingface.co/collections/ServiceNow-AI/apriel-h1>\n- <https://huggingface.co/blog/ServiceNow-AI/apriel-h1>\n\n---\n\n### 4. 🚀 豆包输入法上线多语种语音输入 {#4-豆包输入法上线多语种语音输入}\n\n**标签：** `豆包输入法` `字节跳动` `语音输入`\n\n字节跳动旗下豆包输入法正式上线，主打多语种语音输入功能。该输入法支持中文、英文、日语、韩语等十余种语言的实时语音识别与输入，采用豆包大模型底层语音识别引擎，具备高准确率与低延迟特性。用户可通过语音快速输入文本，支持离线模式与隐私保护，适用于移动办公、跨语言交流、无障碍输入等场景。产品官网（shurufa.doubao.com）已开放下载，未来将集成更多AI辅助输入功能，如智能纠错、语义补全等，进一步拓展AI输入法生态。\n\n**🔗 相关链接：**\n- <https://shurufa.doubao.com/>\n\n---\n\n### 5. 🔧 Gemini CLI开放Gemini 3 Pro访问 {#5-Gemini-CLI开放Gemini-3-Pro访问}\n\n**标签：** `Gemini CLI` `Gemini 3 Pro` `多模态模型`\n\nGemini CLI 工具现已开放对 Gemini 3 Pro 模型的访问权限，开发者可通过命令行界面直接调用该高性能多模态模型。Gemini 3 Pro 支持图像理解、文本生成与复杂推理任务，具备更强的上下文理解与逻辑推理能力。此次开放意味着开发者可在本地或服务器环境中通过 CLI 快速集成 Gemini 能力，适用于自动化脚本、批量处理、AI代理开发等场景。该更新由社区开发者推动，进一步降低了多模态大模型的使用门槛。\n\n**🔗 相关链接：**\n- <https://x.com/ntaylormullen/status/1992016535880348039>\n\n---\n\n### 6. 🔧 智谱AI升级GLM Coding Plan {#6-智谱AI升级GLM-Coding-Plan}\n\n**标签：** `智谱AI` `GLM Coding Plan` `代码生成`\n\n智谱AI 对其 GLM Coding Plan 进行重大升级，强化代码生成与编程辅助能力。新版本支持更复杂的代码结构生成、多文件项目理解与上下文感知补全，集成于其AI编程助手中。升级内容包括对Python、JavaScript、Go等主流语言的支持优化，以及增强的单元测试生成与错误修复建议功能。官方微信公众号发布详细技术解析，强调其在提升开发者效率、降低编码门槛方面的价值，是智谱构建AI原生开发生态的重要一环。\n\n**🔗 相关链接：**\n- <https://mp.weixin.qq.com/s/Btr5BjYgMemJNps9H6I1xg>\n\n---\n\n### 7. 🔧 Cursor发布2.1版本更新功能 {#7-Cursor发布21版本更新功能}\n\n**标签：** `Cursor` `AI编程编辑器` `代码补全`\n\nAI编程编辑器 Cursor 发布 2.1 版本，带来多项功能更新。新版本优化了AI代码补全的响应速度与准确性，增强了对长文件上下文的理解能力，并新增多轮对话式编程辅助功能。用户可通过自然语言描述需求，Cursor 自动生成或修改代码，支持跨文件重构与测试用例生成。此外，2.1版本还改进了本地模型支持与隐私模式，适用于企业级开发环境。该版本进一步巩固了Cursor在AI编程工具领域的领先地位。\n\n---\n\n### 8. 🔧 Claude Code CLI新增后台任务转移 {#8-Claude-Code-CLI新增后台任务转移}\n\n**标签：** `Claude Code CLI` `Anthropic` `任务迁移`\n\nClaude Code CLI 新增后台任务转移功能，允许用户将正在运行的AI编程任务从一台设备无缝迁移至另一台设备继续执行。该功能基于任务状态持久化与上下文同步机制，支持断点续传与跨终端协作，适用于长时间运行的代码分析、重构或测试任务。用户可通过命令行指令启动、暂停与恢复任务，提升开发效率与灵活性。该功能体现了Anthropic在AI编程助手用户体验上的持续优化。\n\n**🔗 相关链接：**\n- <https://x.com/trq212/status/1991977749821735341>\n\n---\n\n### 9. 🔧 Sora 2更新“故事板块”功能 {#9-Sora-2更新故事板块功能}\n\n**标签：** `Sora 2` `OpenAI` `故事板块`\n\nSora 2 模型更新“故事板块”功能，支持用户通过结构化叙事框架生成连贯视频内容。该功能允许用户输入角色设定、场景顺序与情节发展，Sora 2 将自动生成符合逻辑的视频序列，提升视频生成的叙事性与可控性。更新内容已在社区论坛（linux.do）披露，强调其在影视剧本可视化、教育内容制作、广告创意等领域的应用潜力。该功能标志着Sora从单一视频生成向叙事驱动型内容创作演进。\n\n**🔗 相关链接：**\n- <https://linux.do/t/topic/1203669>\n- <https://cdn.openai.com/business-guides-and-resources/building-an-ai-native-engineering-team.pdf>\n\n---\n\n### 10. 📈 OpenAI发布AI-Native工程团队指南 {#10-OpenAI发布AI-Native工程团队指南}\n\n**标签：** `OpenAI` `AI-Native工程团队` `开发指南`\n\nOpenAI 发布《构建AI原生工程团队》指南，系统阐述如何组建与运营以AI为核心驱动力的工程团队。该PDF文档涵盖团队结构、开发流程、工具链集成、AI模型部署与监控等关键环节，强调AI代理、自动化测试、持续学习等实践。指南建议将AI能力嵌入需求分析、代码生成、部署运维等全流程，提升研发效率与系统智能化水平。该文件为AI时代软件工程转型提供权威参考，适用于科技企业与开发者组织。\n\n**🔗 相关链接：**\n- <https://cdn.openai.com/business-guides-and-resources/building-an-ai-native-engineering-team.pdf>\n\n---\n\n### 11. 🔧 Dify发布v1.10.0版本Workflow Trigger {#11-Dify发布v1100版本Workflow-Trigger}\n\n**标签：** `Dify` `Workflow Trigger` `低代码AI`\n\nDify 发布 v1.10.0 版本，新增 Workflow Trigger 功能，支持基于事件触发的自动化AI工作流。用户可设置定时任务、API调用、文件上传等触发条件，自动启动AI流程，如数据清洗、报告生成、客户响应等。该功能增强了Dify在AI应用编排中的灵活性，适用于企业自动化、智能客服、数据分析等场景。官方博客详细介绍其架构设计与使用案例，进一步推动低代码AI平台的发展。\n\n**🔗 相关链接：**\n- <https://dify.ai/blog/introducing-trigger>\n\n---\n\n### 12. 🚀 Genspark发布AI工作空间并完成B轮融资 {#12-Genspark发布AI工作空间并完成B轮融资}\n\n**标签：** `Genspark` `AI工作空间` `B轮融资`\n\nGenspark 发布其AI工作空间产品，集成搜索、写作、分析、协作等功能，支持多模态输入与输出。该工作空间基于自研大模型，提供个性化知识库、智能摘要与任务管理，适用于个人与团队使用。同时，公司宣布完成B轮融资，资金将用于产品迭代与全球市场拓展。官网已开放团队定价方案，强调其在提升知识工作者效率方面的价值，是新一代AI生产力工具的代表。\n\n**🔗 相关链接：**\n- <https://genspark.ai/team_pricing>\n\n---\n\n### 13. 🔧 Ollama v0.13支持DeepSeek-OCR {#13-Ollama-v013支持DeepSeek-OCR}\n\n**标签：** `Ollama` `DeepSeek-OCR` `本地OCR`\n\nOllama 发布 v0.13 版本，新增对 DeepSeek-OCR 模型的支持，用户可在本地运行高性能OCR识别。DeepSeek-OCR 支持多语言文本识别、表格提取与手写体识别，具备高精度与低资源消耗特性。该更新使开发者可在离线环境中实现文档数字化、发票识别、图像转文本等任务，适用于隐私敏感场景。Ollama 持续扩展其本地模型生态，推动边缘AI应用发展。\n\n**🔗 相关链接：**\n- <https://x.com/jmorgan/status/1991960419523764689>\n\n---\n\n### 14. 📈 Hugging Face更新Open ASR Leaderboard {#14-Hugging-Face更新Open-ASR-Leaderb}\n\n**标签：** `Hugging Face` `Open ASR Leaderboard` `语音识别`\n\nHugging Face 更新 Open ASR Leaderboard，新增多语言语音识别模型评测标准与数据集。该榜单涵盖WER（词错误率）、RTF（实时因子）、多语种支持等指标，支持社区提交模型进行公平比较。更新包括对低资源语言、噪声环境、口音识别等场景的专项评测，推动语音识别技术的普惠发展。榜单与评测空间同步上线，是语音AI领域的重要基准平台。\n\n**🔗 相关链接：**\n- <https://huggingface.co/blog/open-asr-leaderboard>\n- <https://huggingface.co/spaces/hf-audio/open_asr_leaderboard>\n\n---\n\n### 15. 🚀 OCR Arena推出VLM与OCR对比平台 {#15-OCR-Arena推出VLM与OCR对比平台}\n\n**标签：** `OCR Arena` `VLM` `OCR对比`\n\nOCR Arena 推出全新平台，支持视觉语言模型（VLM）与传统OCR模型的对比评测。用户可上传图像，平台自动调用多种模型进行文本识别，并生成可视化对比结果，包括准确率、响应速度、错误类型等。该平台旨在帮助开发者选择最适合其场景的OCR方案，推动多模态OCR技术的发展。官网（ocrarena.ai）已开放使用，支持自定义测试集与模型上传。\n\n**🔗 相关链接：**\n- <https://ocrarena.ai>\n\n---\n\n### 16. 🔧 Gradio 6发布重大更新与性能提升 {#16-Gradio-6发布重大更新与性能提升}\n\n**标签：** `Gradio` `Gradio 6` `AI前端框架`\n\nGradio 发布 6.0 版本，带来重大架构更新与性能优化。新版本重构了前端渲染引擎，提升页面加载速度与交互响应，支持更复杂的UI组件与自定义主题。同时，Gradio 6 增强了对异步任务、长连接与多用户并发的支持，适用于高负载AI应用部署。该版本还优化了移动端体验与无障碍访问，是构建AI演示与生产级应用的首选前端框架。\n\n**🔗 相关链接：**\n- <https://x.com/cocktailpeanut/status/1991963409152360850>\n\n---\n\n### 17. 📈 Brookfield联合NVIDIA启动千亿AI基建项目 {#17-Brookfield联合NVIDIA启动千亿AI基建项目}\n\n**标签：** `Brookfield` `NVIDIA` `AI基础设施`\n\nBrookfield Asset Management 联合 NVIDIA 启动一项高达1000亿美元的AI基础设施投资计划，旨在全球范围内建设AI数据中心、算力网络与边缘计算节点。项目将采用NVIDIA全栈AI解决方案，包括GPU、网络芯片与AI软件栈，支持大模型训练、推理与行业应用。该合作标志着传统资本与AI技术深度融合，将加速全球AI算力供给，推动AI经济规模化发展。\n\n**🔗 相关链接：**\n- <https://www.nvidia.com/en-us/news/brookfield-launches-ambitious-program-to-acquire-up-to-100-billion-in-ai-infrastructure/>\n\n---\n\n### 18. 📈 Adobe收购AI营销公司Semrush {#18-Adobe收购AI营销公司Semrush}\n\n**标签：** `Adobe` `Semrush` `AI营销`\n\nAdobe 宣布收购AI营销公司 Semrush，交易细节未完全披露。Semrush 专注于AI驱动的数字营销分析、SEO优化与内容策略生成，其技术将整合至Adobe Experience Cloud，增强其在客户体验管理、内容智能与营销自动化方面的能力。此次收购是Adobe构建AI原生营销平台战略的重要一步，有望提升其在企业营销AI领域的竞争力。\n\n**🔗 相关链接：**\n- <https://chedongxi.com/p/516160.html>\n\n---\n\n---\n\n## 🎬 视频链接\n\n**Bilibili**： <https://www.bilibili.com/video/BV1a3UHBNENX>\n\n---\n\n*整理自橘鸦AI早报 | BV号：BV1a3UHBNENX | 2025-11-22 08:59:05*",
      "html_content": "<h1 id=\"hunyuanvideo-15mimo-embodiedai-2025-11-22\">腾讯开源HunyuanVideo-1.5视频模型；小米发布跨具身基础模型MiMo-Embodied【AI 早报 2025-11-22】</h1>\n<p><strong>📅 发布日期：</strong> 2025-11-22<br />\n<strong>🎬 BV号：</strong> BV1a3UHBNENX<br />\n<strong>📝 整理时间：</strong> 2025-11-22 08:59:05<br />\n<strong>📊 资讯数量：</strong> 18 条</p>\n<hr />\n<h2 id=\"_1\">📋 本期概览</h2>\n<ol>\n<li>🚀 腾讯开源HunyuanVideo-1.5视频模型</li>\n<li>🚀 小米发布跨具身基础模型MiMo-Embodied</li>\n<li>🚀 ServiceNow发布Apriel-H1模型系列</li>\n<li>🚀 豆包输入法上线多语种语音输入</li>\n<li>🔧 Gemini CLI开放Gemini 3 Pro访问</li>\n<li>🔧 智谱AI升级GLM Coding Plan</li>\n<li>🔧 Cursor发布2.1版本更新功能</li>\n<li>🔧 Claude Code CLI新增后台任务转移</li>\n<li>🔧 Sora 2更新“故事板块”功能</li>\n<li>📈 OpenAI发布AI-Native工程团队指南</li>\n<li>🔧 Dify发布v1.10.0版本Workflow Trigger</li>\n<li>🚀 Genspark发布AI工作空间并完成B轮融资</li>\n<li>🔧 Ollama v0.13支持DeepSeek-OCR</li>\n<li>📈 Hugging Face更新Open ASR Leaderboard</li>\n<li>🚀 OCR Arena推出VLM与OCR对比平台</li>\n<li>🔧 Gradio 6发布重大更新与性能提升</li>\n<li>📈 Brookfield联合NVIDIA启动千亿AI基建项目</li>\n<li>📈 Adobe收购AI营销公司Semrush</li>\n</ol>\n<hr />\n<h3 id=\"1-腾讯开源HunyuanVideo-15视频模型\">1. 🚀 腾讯开源HunyuanVideo-1.5视频模型</h3>\n<p><strong>标签：</strong> <code>腾讯</code> <code>HunyuanVideo-1.5</code> <code>视频生成模型</code></p>\n<p>腾讯于近日开源了其最新一代视频生成模型 HunyuanVideo-1.5，该模型在 Hugging Face、GitHub 及腾讯混元官网同步发布。HunyuanVideo-1.5 是腾讯混元大模型在视频生成领域的重要升级，支持更高分辨率、更长时序的视频生成，具备更强的语义理解与动作连贯性。模型采用自研的3D变分自编码器（VAE）与扩散架构，支持文本到视频（T2V）生成，可生成最高1080p、120帧的视频内容。此次开源包含完整的训练与推理代码、预训练权重及示例应用，推动多模态生成式AI的社区发展。该模型适用于影视制作、广告创意、虚拟数字人等场景，进一步降低高质量视频生成技术门槛。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://huggingface.co/tencent/HunyuanVideo-1.5\">https://huggingface.co/tencent/HunyuanVideo-1.5</a><br />\n- <a href=\"https://hunyuan.tencent.com/video/zh?tabIndex=0\">https://hunyuan.tencent.com/video/zh?tabIndex=0</a><br />\n- <a href=\"https://github.com/Tencent-Hunyuan/HunyuanVideo-1.5\">https://github.com/Tencent-Hunyuan/HunyuanVideo-1.5</a></p>\n<hr />\n<h3 id=\"2-小米发布跨具身基础模型MiMo-Embodied\">2. 🚀 小米发布跨具身基础模型MiMo-Embodied</h3>\n<p><strong>标签：</strong> <code>小米</code> <code>MiMo-Embodied-7B</code> <code>具身智能</code></p>\n<p>小米发布跨具身基础模型 MiMo-Embodied-7B，该模型专注于机器人与具身智能（Embodied AI）领域，支持多模态感知与动作规划。MiMo-Embodied 基于7B参数架构，融合视觉、语言与运动控制信号，可在真实物理环境中实现任务理解、路径规划与动作执行。模型已在 arXiv 上发布技术论文（arXiv:2511.16518），并在 Hugging Face 开源模型权重，支持社区进行机器人控制、家庭服务机器人、工业自动化等下游任务微调。该模型标志着小米在AI+机器人融合方向迈出关键一步，有望推动具身智能的规模化落地。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://arxiv.org/abs/2511.16518\">https://arxiv.org/abs/2511.16518</a><br />\n- <a href=\"https://huggingface.co/XiaomiMiMo/MiMo-Embodied-7B\">https://huggingface.co/XiaomiMiMo/MiMo-Embodied-7B</a></p>\n<hr />\n<h3 id=\"3-ServiceNow发布Apriel-H1模型系列\">3. 🚀 ServiceNow发布Apriel-H1模型系列</h3>\n<p><strong>标签：</strong> <code>ServiceNow-AI</code> <code>Apriel-H1</code> <code>企业级AI</code></p>\n<p>ServiceNow-AI 发布 Apriel-H1 模型系列，专为企业级AI应用设计，聚焦于代码生成、文档理解与自动化流程优化。该系列模型基于混合架构，支持长上下文处理（最高32K tokens），在 Hugging Face 上提供多个变体，包括代码生成、文本分类与问答专用模型。Apriel-H1 强调安全合规、可解释性与低延迟推理，适用于IT服务管理（ITSM）、客户支持自动化、知识库问答等场景。官方博客同步发布技术细节，强调其在企业私有部署中的隐私保护能力，是ServiceNow构建AI原生工作流平台的核心组件。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://huggingface.co/collections/ServiceNow-AI/apriel-h1\">https://huggingface.co/collections/ServiceNow-AI/apriel-h1</a><br />\n- <a href=\"https://huggingface.co/blog/ServiceNow-AI/apriel-h1\">https://huggingface.co/blog/ServiceNow-AI/apriel-h1</a></p>\n<hr />\n<h3 id=\"4-豆包输入法上线多语种语音输入\">4. 🚀 豆包输入法上线多语种语音输入</h3>\n<p><strong>标签：</strong> <code>豆包输入法</code> <code>字节跳动</code> <code>语音输入</code></p>\n<p>字节跳动旗下豆包输入法正式上线，主打多语种语音输入功能。该输入法支持中文、英文、日语、韩语等十余种语言的实时语音识别与输入，采用豆包大模型底层语音识别引擎，具备高准确率与低延迟特性。用户可通过语音快速输入文本，支持离线模式与隐私保护，适用于移动办公、跨语言交流、无障碍输入等场景。产品官网（shurufa.doubao.com）已开放下载，未来将集成更多AI辅助输入功能，如智能纠错、语义补全等，进一步拓展AI输入法生态。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://shurufa.doubao.com/\">https://shurufa.doubao.com/</a></p>\n<hr />\n<h3 id=\"5-Gemini-CLI开放Gemini-3-Pro访问\">5. 🔧 Gemini CLI开放Gemini 3 Pro访问</h3>\n<p><strong>标签：</strong> <code>Gemini CLI</code> <code>Gemini 3 Pro</code> <code>多模态模型</code></p>\n<p>Gemini CLI 工具现已开放对 Gemini 3 Pro 模型的访问权限，开发者可通过命令行界面直接调用该高性能多模态模型。Gemini 3 Pro 支持图像理解、文本生成与复杂推理任务，具备更强的上下文理解与逻辑推理能力。此次开放意味着开发者可在本地或服务器环境中通过 CLI 快速集成 Gemini 能力，适用于自动化脚本、批量处理、AI代理开发等场景。该更新由社区开发者推动，进一步降低了多模态大模型的使用门槛。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/ntaylormullen/status/1992016535880348039\">https://x.com/ntaylormullen/status/1992016535880348039</a></p>\n<hr />\n<h3 id=\"6-智谱AI升级GLM-Coding-Plan\">6. 🔧 智谱AI升级GLM Coding Plan</h3>\n<p><strong>标签：</strong> <code>智谱AI</code> <code>GLM Coding Plan</code> <code>代码生成</code></p>\n<p>智谱AI 对其 GLM Coding Plan 进行重大升级，强化代码生成与编程辅助能力。新版本支持更复杂的代码结构生成、多文件项目理解与上下文感知补全，集成于其AI编程助手中。升级内容包括对Python、JavaScript、Go等主流语言的支持优化，以及增强的单元测试生成与错误修复建议功能。官方微信公众号发布详细技术解析，强调其在提升开发者效率、降低编码门槛方面的价值，是智谱构建AI原生开发生态的重要一环。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://mp.weixin.qq.com/s/Btr5BjYgMemJNps9H6I1xg\">https://mp.weixin.qq.com/s/Btr5BjYgMemJNps9H6I1xg</a></p>\n<hr />\n<h3 id=\"7-Cursor发布21版本更新功能\">7. 🔧 Cursor发布2.1版本更新功能</h3>\n<p><strong>标签：</strong> <code>Cursor</code> <code>AI编程编辑器</code> <code>代码补全</code></p>\n<p>AI编程编辑器 Cursor 发布 2.1 版本，带来多项功能更新。新版本优化了AI代码补全的响应速度与准确性，增强了对长文件上下文的理解能力，并新增多轮对话式编程辅助功能。用户可通过自然语言描述需求，Cursor 自动生成或修改代码，支持跨文件重构与测试用例生成。此外，2.1版本还改进了本地模型支持与隐私模式，适用于企业级开发环境。该版本进一步巩固了Cursor在AI编程工具领域的领先地位。</p>\n<hr />\n<h3 id=\"8-Claude-Code-CLI新增后台任务转移\">8. 🔧 Claude Code CLI新增后台任务转移</h3>\n<p><strong>标签：</strong> <code>Claude Code CLI</code> <code>Anthropic</code> <code>任务迁移</code></p>\n<p>Claude Code CLI 新增后台任务转移功能，允许用户将正在运行的AI编程任务从一台设备无缝迁移至另一台设备继续执行。该功能基于任务状态持久化与上下文同步机制，支持断点续传与跨终端协作，适用于长时间运行的代码分析、重构或测试任务。用户可通过命令行指令启动、暂停与恢复任务，提升开发效率与灵活性。该功能体现了Anthropic在AI编程助手用户体验上的持续优化。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/trq212/status/1991977749821735341\">https://x.com/trq212/status/1991977749821735341</a></p>\n<hr />\n<h3 id=\"9-Sora-2更新故事板块功能\">9. 🔧 Sora 2更新“故事板块”功能</h3>\n<p><strong>标签：</strong> <code>Sora 2</code> <code>OpenAI</code> <code>故事板块</code></p>\n<p>Sora 2 模型更新“故事板块”功能，支持用户通过结构化叙事框架生成连贯视频内容。该功能允许用户输入角色设定、场景顺序与情节发展，Sora 2 将自动生成符合逻辑的视频序列，提升视频生成的叙事性与可控性。更新内容已在社区论坛（linux.do）披露，强调其在影视剧本可视化、教育内容制作、广告创意等领域的应用潜力。该功能标志着Sora从单一视频生成向叙事驱动型内容创作演进。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://linux.do/t/topic/1203669\">https://linux.do/t/topic/1203669</a><br />\n- <a href=\"https://cdn.openai.com/business-guides-and-resources/building-an-ai-native-engineering-team.pdf\">https://cdn.openai.com/business-guides-and-resources/building-an-ai-native-engineering-team.pdf</a></p>\n<hr />\n<h3 id=\"10-OpenAI发布AI-Native工程团队指南\">10. 📈 OpenAI发布AI-Native工程团队指南</h3>\n<p><strong>标签：</strong> <code>OpenAI</code> <code>AI-Native工程团队</code> <code>开发指南</code></p>\n<p>OpenAI 发布《构建AI原生工程团队》指南，系统阐述如何组建与运营以AI为核心驱动力的工程团队。该PDF文档涵盖团队结构、开发流程、工具链集成、AI模型部署与监控等关键环节，强调AI代理、自动化测试、持续学习等实践。指南建议将AI能力嵌入需求分析、代码生成、部署运维等全流程，提升研发效率与系统智能化水平。该文件为AI时代软件工程转型提供权威参考，适用于科技企业与开发者组织。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://cdn.openai.com/business-guides-and-resources/building-an-ai-native-engineering-team.pdf\">https://cdn.openai.com/business-guides-and-resources/building-an-ai-native-engineering-team.pdf</a></p>\n<hr />\n<h3 id=\"11-Dify发布v1100版本Workflow-Trigger\">11. 🔧 Dify发布v1.10.0版本Workflow Trigger</h3>\n<p><strong>标签：</strong> <code>Dify</code> <code>Workflow Trigger</code> <code>低代码AI</code></p>\n<p>Dify 发布 v1.10.0 版本，新增 Workflow Trigger 功能，支持基于事件触发的自动化AI工作流。用户可设置定时任务、API调用、文件上传等触发条件，自动启动AI流程，如数据清洗、报告生成、客户响应等。该功能增强了Dify在AI应用编排中的灵活性，适用于企业自动化、智能客服、数据分析等场景。官方博客详细介绍其架构设计与使用案例，进一步推动低代码AI平台的发展。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://dify.ai/blog/introducing-trigger\">https://dify.ai/blog/introducing-trigger</a></p>\n<hr />\n<h3 id=\"12-Genspark发布AI工作空间并完成B轮融资\">12. 🚀 Genspark发布AI工作空间并完成B轮融资</h3>\n<p><strong>标签：</strong> <code>Genspark</code> <code>AI工作空间</code> <code>B轮融资</code></p>\n<p>Genspark 发布其AI工作空间产品，集成搜索、写作、分析、协作等功能，支持多模态输入与输出。该工作空间基于自研大模型，提供个性化知识库、智能摘要与任务管理，适用于个人与团队使用。同时，公司宣布完成B轮融资，资金将用于产品迭代与全球市场拓展。官网已开放团队定价方案，强调其在提升知识工作者效率方面的价值，是新一代AI生产力工具的代表。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://genspark.ai/team_pricing\">https://genspark.ai/team_pricing</a></p>\n<hr />\n<h3 id=\"13-Ollama-v013支持DeepSeek-OCR\">13. 🔧 Ollama v0.13支持DeepSeek-OCR</h3>\n<p><strong>标签：</strong> <code>Ollama</code> <code>DeepSeek-OCR</code> <code>本地OCR</code></p>\n<p>Ollama 发布 v0.13 版本，新增对 DeepSeek-OCR 模型的支持，用户可在本地运行高性能OCR识别。DeepSeek-OCR 支持多语言文本识别、表格提取与手写体识别，具备高精度与低资源消耗特性。该更新使开发者可在离线环境中实现文档数字化、发票识别、图像转文本等任务，适用于隐私敏感场景。Ollama 持续扩展其本地模型生态，推动边缘AI应用发展。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/jmorgan/status/1991960419523764689\">https://x.com/jmorgan/status/1991960419523764689</a></p>\n<hr />\n<h3 id=\"14-Hugging-Face更新Open-ASR-Leaderb\">14. 📈 Hugging Face更新Open ASR Leaderboard</h3>\n<p><strong>标签：</strong> <code>Hugging Face</code> <code>Open ASR Leaderboard</code> <code>语音识别</code></p>\n<p>Hugging Face 更新 Open ASR Leaderboard，新增多语言语音识别模型评测标准与数据集。该榜单涵盖WER（词错误率）、RTF（实时因子）、多语种支持等指标，支持社区提交模型进行公平比较。更新包括对低资源语言、噪声环境、口音识别等场景的专项评测，推动语音识别技术的普惠发展。榜单与评测空间同步上线，是语音AI领域的重要基准平台。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://huggingface.co/blog/open-asr-leaderboard\">https://huggingface.co/blog/open-asr-leaderboard</a><br />\n- <a href=\"https://huggingface.co/spaces/hf-audio/open_asr_leaderboard\">https://huggingface.co/spaces/hf-audio/open_asr_leaderboard</a></p>\n<hr />\n<h3 id=\"15-OCR-Arena推出VLM与OCR对比平台\">15. 🚀 OCR Arena推出VLM与OCR对比平台</h3>\n<p><strong>标签：</strong> <code>OCR Arena</code> <code>VLM</code> <code>OCR对比</code></p>\n<p>OCR Arena 推出全新平台，支持视觉语言模型（VLM）与传统OCR模型的对比评测。用户可上传图像，平台自动调用多种模型进行文本识别，并生成可视化对比结果，包括准确率、响应速度、错误类型等。该平台旨在帮助开发者选择最适合其场景的OCR方案，推动多模态OCR技术的发展。官网（ocrarena.ai）已开放使用，支持自定义测试集与模型上传。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://ocrarena.ai\">https://ocrarena.ai</a></p>\n<hr />\n<h3 id=\"16-Gradio-6发布重大更新与性能提升\">16. 🔧 Gradio 6发布重大更新与性能提升</h3>\n<p><strong>标签：</strong> <code>Gradio</code> <code>Gradio 6</code> <code>AI前端框架</code></p>\n<p>Gradio 发布 6.0 版本，带来重大架构更新与性能优化。新版本重构了前端渲染引擎，提升页面加载速度与交互响应，支持更复杂的UI组件与自定义主题。同时，Gradio 6 增强了对异步任务、长连接与多用户并发的支持，适用于高负载AI应用部署。该版本还优化了移动端体验与无障碍访问，是构建AI演示与生产级应用的首选前端框架。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/cocktailpeanut/status/1991963409152360850\">https://x.com/cocktailpeanut/status/1991963409152360850</a></p>\n<hr />\n<h3 id=\"17-Brookfield联合NVIDIA启动千亿AI基建项目\">17. 📈 Brookfield联合NVIDIA启动千亿AI基建项目</h3>\n<p><strong>标签：</strong> <code>Brookfield</code> <code>NVIDIA</code> <code>AI基础设施</code></p>\n<p>Brookfield Asset Management 联合 NVIDIA 启动一项高达1000亿美元的AI基础设施投资计划，旨在全球范围内建设AI数据中心、算力网络与边缘计算节点。项目将采用NVIDIA全栈AI解决方案，包括GPU、网络芯片与AI软件栈，支持大模型训练、推理与行业应用。该合作标志着传统资本与AI技术深度融合，将加速全球AI算力供给，推动AI经济规模化发展。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://www.nvidia.com/en-us/news/brookfield-launches-ambitious-program-to-acquire-up-to-100-billion-in-ai-infrastructure/\">https://www.nvidia.com/en-us/news/brookfield-launches-ambitious-program-to-acquire-up-to-100-billion-in-ai-infrastructure/</a></p>\n<hr />\n<h3 id=\"18-Adobe收购AI营销公司Semrush\">18. 📈 Adobe收购AI营销公司Semrush</h3>\n<p><strong>标签：</strong> <code>Adobe</code> <code>Semrush</code> <code>AI营销</code></p>\n<p>Adobe 宣布收购AI营销公司 Semrush，交易细节未完全披露。Semrush 专注于AI驱动的数字营销分析、SEO优化与内容策略生成，其技术将整合至Adobe Experience Cloud，增强其在客户体验管理、内容智能与营销自动化方面的能力。此次收购是Adobe构建AI原生营销平台战略的重要一步，有望提升其在企业营销AI领域的竞争力。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://chedongxi.com/p/516160.html\">https://chedongxi.com/p/516160.html</a></p>\n<hr />\n<hr />\n<h2 id=\"_2\">🎬 视频链接</h2>\n<p><strong>Bilibili</strong>： <a href=\"https://www.bilibili.com/video/BV1a3UHBNENX\">https://www.bilibili.com/video/BV1a3UHBNENX</a></p>\n<hr />\n<p><em>整理自橘鸦AI早报 | BV号：BV1a3UHBNENX | 2025-11-22 08:59:05</em></p>",
      "date": "2025-11-22",
      "filename": "2025-11-22_AI早报_BV1a3UHBNENX.md"
    },
    {
      "title": "Google发布Gemini 3 Pro Image模型（Nano Banana Pro）【AI 早报 2025-11-21】",
      "publish_date": "2025-11-21",
      "bv_id": "BV1S9yKB1Ekb",
      "organize_time": "2025-11-21 20:59:06",
      "news_count": 13,
      "overview": "1. 🚀 Google发布Gemini 3 Pro图像模型\n2. 🚀 OpenAI ChatGPT群聊功能全球上线\n3. 🔧 OpenAI更新Mac版ChatGPT Atlas浏览器\n4. 🚀 Perplexity发布Comet浏览器Android版\n5. 📈 OpenAI发布GPT-5科研加速实验报告\n6. 🚀 腾讯混元发布HunyuanVideo 1.5版本\n7. 🔧 NotebookLM推出Slide Decks与Infographics\n8. 🔧 Gemini CLI逐步开放Gemini 3 Pro访问\n9. 🔧 Jules推出Repoless无仓库功能\n10. 🔧 Google Stitch Flow功能升级\n11. 🔧 Google推出Gemini图像AI验证功能\n12. 🚀 MiniMax开放M2识图搜索MCP内测\n13. 🔧 Manus为Slides添加speaker notes功能",
      "content": "# Google发布Gemini 3 Pro Image模型（Nano Banana Pro）【AI 早报 2025-11-21】\n\n**📅 发布日期：** 2025-11-21\n**🎬 BV号：** BV1S9yKB1Ekb\n**📝 整理时间：** 2025-11-21 20:59:06\n**📊 资讯数量：** 13 条\n\n---\n\n## 📋 本期概览\n\n1. 🚀 Google发布Gemini 3 Pro图像模型\n2. 🚀 OpenAI ChatGPT群聊功能全球上线\n3. 🔧 OpenAI更新Mac版ChatGPT Atlas浏览器\n4. 🚀 Perplexity发布Comet浏览器Android版\n5. 📈 OpenAI发布GPT-5科研加速实验报告\n6. 🚀 腾讯混元发布HunyuanVideo 1.5版本\n7. 🔧 NotebookLM推出Slide Decks与Infographics\n8. 🔧 Gemini CLI逐步开放Gemini 3 Pro访问\n9. 🔧 Jules推出Repoless无仓库功能\n10. 🔧 Google Stitch Flow功能升级\n11. 🔧 Google推出Gemini图像AI验证功能\n12. 🚀 MiniMax开放M2识图搜索MCP内测\n13. 🔧 Manus为Slides添加speaker notes功能\n\n---\n\n### 1. 🚀 Google发布Gemini 3 Pro图像模型 {#1-Google发布Gemini-3-Pro图像模型}\n\n**标签：** `Google` `Gemini 3 Pro Image` `DeepMind`\n\nGoogle于近日正式发布Gemini 3 Pro Image模型，作为其Gemini系列多模态模型的最新成员，专注于图像生成与理解任务。该模型在Gemini 3架构基础上进行了优化，支持更高分辨率图像生成、更精准的语义理解与上下文感知能力。据官方博客介绍，Gemini 3 Pro Image在开发者预览中已展现出在复杂视觉推理、多模态对话和图像编辑方面的显著提升。模型通过Google DeepMind团队训练，集成SynthID水印技术，用于AI生成图像的可追溯性验证。该模型现已通过Google AI Studio和Vertex AI平台向开发者开放，支持API调用。Gemini 3 Pro Image的发布标志着Google在生成式AI图像领域进一步缩小与DALL·E、Stable Diffusion等模型的差距，并强化其在企业级AI应用中的竞争力。\n\n**🔗 相关链接：**\n- <https://blog.google/technology/developers/gemini-3-pro-image-developers/>\n- <https://blog.google/technology/ai/nano-banana-pro>\n- <https://deepmind.google/models/gemini-image/pro/>\n\n---\n\n### 2. 🚀 OpenAI ChatGPT群聊功能全球上线 {#2-OpenAI-ChatGPT群聊功能全球上线}\n\n**标签：** `OpenAI` `ChatGPT` `Group Chats`\n\nOpenAI宣布其ChatGPT的群聊功能（Group Chats）正式向全球用户开放。该功能允许用户创建多人参与的对话线程，支持跨设备同步、角色分配（如管理员、参与者）、消息提及与线程归档。群聊功能适用于团队协作、项目讨论、教育辅导等场景，用户可邀请最多20人加入同一对话，并可通过链接分享或权限控制管理访问。该功能已在Web、iOS和Android端同步上线，支持GPT-4o等最新模型。OpenAI表示，群聊功能旨在提升AI在组织协作中的实用性，推动ChatGPT从个人助手向团队智能中枢演进。\n\n**🔗 相关链接：**\n- <https://openai.com/index/group-chats-in-chatgpt/>\n- <https://help.openai.com/en/articles/12703475-group-chats-in-chatgpt>\n- <https://x.com/OpenAI/status/1991312374092165471>\n\n---\n\n### 3. 🔧 OpenAI更新Mac版ChatGPT Atlas浏览器 {#3-OpenAI更新Mac版ChatGPT-Atlas浏览器}\n\n**标签：** `OpenAI` `ChatGPT` `Atlas浏览器`\n\nOpenAI通过官方X账号宣布，Mac版ChatGPT应用中的Atlas浏览器组件已更新。Atlas是ChatGPT桌面端用于网页浏览与内容提取的内置浏览器，此次更新优化了页面加载速度、JavaScript执行效率与隐私保护机制。更新后，Atlas支持更复杂的网页交互（如动态表单、登录流程），并增强了对JavaScript密集型网站（如Notion、Figma）的兼容性。该更新提升了ChatGPT在信息检索、实时数据分析和自动化任务执行中的能力，尤其适用于需要结合网络内容的复杂查询场景。\n\n**🔗 相关链接：**\n- <https://openai.com/index/group-chats-in-chatgpt/>\n- <https://help.openai.com/en/articles/12703475-group-chats-in-chatgpt>\n- <https://x.com/OpenAI/status/1991312374092165471>\n\n---\n\n### 4. 🚀 Perplexity发布Comet浏览器Android版 {#4-Perplexity发布Comet浏览器Android版}\n\n**标签：** `Perplexity` `Comet浏览器` `AI搜索`\n\nAI搜索公司Perplexity正式推出其Comet浏览器的Android版本。Comet是Perplexity专为AI增强搜索设计的轻量级浏览器，集成其自研搜索模型，支持语音输入、实时摘要、多轮追问与跨页面信息聚合。Android版Comet延续了iOS端的核心功能，包括‘Ask with Search’即时AI问答、页面高亮与知识图谱生成。用户可通过侧边栏直接调用AI助手，无需跳转应用。该发布标志着Perplexity在移动端AI搜索生态的进一步布局，旨在挑战传统浏览器与搜索引擎的交互范式。\n\n**🔗 相关链接：**\n- <https://x.com/ChrisUniverseB/status/1991567489055224091>\n\n---\n\n### 5. 📈 OpenAI发布GPT-5科研加速实验报告 {#5-OpenAI发布GPT-5科研加速实验报告}\n\n**标签：** `OpenAI` `GPT-5` `科研加速`\n\nOpenAI发布《GPT-5早期科研加速实验报告》，披露其在科学发现领域使用GPT-5模型进行的前瞻性测试。实验涵盖化学、生物学、材料科学等领域，GPT-5被用于假设生成、文献综述、实验设计优化与数据解释。报告指出，GPT-5在‘逆向分子设计’任务中提出的新化合物结构中，有12%被实验室验证为可行；在‘文献综述自动化’任务中，节省研究人员平均40%时间。报告还强调模型在跨学科知识整合方面的潜力，如将量子计算与生物传感结合提出新应用。该报告为AI辅助科研提供了实证依据，但OpenAI强调GPT-5仍处于早期阶段，尚未公开可用。\n\n**🔗 相关链接：**\n- <https://openai.com/index/group-chats-in-chatgpt/>\n- <https://help.openai.com/en/articles/12703475-group-chats-in-chatgpt>\n- <https://x.com/OpenAI/status/1991312374092165471>\n\n---\n\n### 6. 🚀 腾讯混元发布HunyuanVideo 1.5版本 {#6-腾讯混元发布HunyuanVideo-15版本}\n\n**标签：** `腾讯混元` `HunyuanVideo 1.5` `视频生成`\n\n腾讯混元大模型团队宣布将于今日发布HunyuanVideo 1.5版本。该版本为视频生成模型的重大升级，支持最长10秒、1080p分辨率的视频生成，帧率提升至30fps，并引入‘运动一致性’与‘物理合理性’优化算法。HunyuanVideo 1.5支持文本到视频（Text-to-Video）与图像到视频（Image-to-Video）两种模式，新增‘风格迁移’与‘镜头控制’功能，用户可通过提示词控制运镜方式（如推、拉、摇）。该版本面向内容创作者、广告与影视行业开放内测，标志着国产视频生成模型在质量与可控性上的重要进展。\n\n**🔗 相关链接：**\n- <https://mp.weixin.qq.com/s/n7EYBtuA6koPcb_Wm6azTQ>\n\n---\n\n### 7. 🔧 NotebookLM推出Slide Decks与Infographics {#7-NotebookLM推出Slide-Decks与Infogr}\n\n**标签：** `NotebookLM` `Slide Decks` `Infographics`\n\nGoogle的AI笔记工具NotebookLM新增Slide Decks（幻灯片）与Infographics（信息图）自动生成功能。用户上传文档或笔记后，NotebookLM可自动提取关键信息，生成结构化的PPT幻灯片或可视化信息图，支持自定义主题、配色与布局。Slide Decks功能支持Markdown导出，Infographics则提供柱状图、流程图、时间线等多种模板。该功能基于Gemini模型实现，适用于教育、企业汇报与知识管理场景，显著降低内容可视化门槛。\n\n**🔗 相关链接：**\n- <https://x.com/NotebookLM/status/1991575294352740686>\n\n---\n\n### 8. 🔧 Gemini CLI逐步开放Gemini 3 Pro访问 {#8-Gemini-CLI逐步开放Gemini-3-Pro访问}\n\n**标签：** `Google` `Gemini CLI` `Gemini 3 Pro`\n\nGoogle开始向Pro用户逐步开放Gemini CLI对Gemini 3 Pro模型的访问权限。Gemini CLI是命令行界面工具，允许开发者通过终端直接调用Gemini系列模型API。此次更新后，Pro用户可在CLI中指定使用Gemini 3 Pro模型，支持图像输入、多轮对话与函数调用。该功能提升了开发者在本地环境中的AI集成效率，尤其适用于自动化脚本、CI/CD流程与服务器端应用。Google表示，权限将分阶段推送，预计两周内覆盖全部Pro用户。\n\n**🔗 相关链接：**\n- <https://blog.google/technology/developers/gemini-3-pro-image-developers/>\n- <https://blog.google/technology/ai/nano-banana-pro>\n- <https://deepmind.google/models/gemini-image/pro/>\n\n---\n\n### 9. 🔧 Jules推出Repoless无仓库功能 {#9-Jules推出Repoless无仓库功能}\n\n**标签：** `Jules` `Repoless` `Google`\n\nGoogle的AI编程助手Jules推出‘Repoless’（无仓库）功能，允许用户无需创建代码仓库即可开始编程。用户可通过‘Start from scratch’选项，在Jules中直接编写代码，系统自动管理临时项目空间，支持代码生成、调试与版本快照。该功能适用于快速原型开发、教学演示与临时任务，降低使用门槛。Jules还集成Gemini模型，提供智能代码补全与错误修复建议。Google强调，Repoless项目不会自动同步至云端仓库，保障用户隐私。\n\n**🔗 相关链接：**\n- <https://blog.google/technology/developers/gemini-3-pro-image-developers/>\n- <https://blog.google/technology/ai/nano-banana-pro>\n- <https://deepmind.google/models/gemini-image/pro/>\n\n---\n\n### 10. 🔧 Google Stitch Flow功能升级 {#10-Google-Stitch-Flow功能升级}\n\n**标签：** `Google` `Stitch Flow` `自动化编排`\n\nGoogle宣布其Stitch Flow功能迎来重大升级。Stitch Flow是用于连接多个AI服务与API的自动化编排工具，此次更新增强了跨服务状态管理、错误重试机制与可视化流程编辑器。用户可创建包含Gemini、Vertex AI、Firebase等服务的复杂工作流，支持条件分支、并行执行与数据转换。升级后，Stitch Flow支持JSON Schema验证与OAuth 2.0集成，提升企业级应用的安全性与可靠性。该功能主要面向开发者与DevOps团队，用于构建端到端AI应用。\n\n**🔗 相关链接：**\n- <https://blog.google/technology/developers/gemini-3-pro-image-developers/>\n- <https://blog.google/technology/ai/nano-banana-pro>\n- <https://deepmind.google/models/gemini-image/pro/>\n\n---\n\n### 11. 🔧 Google推出Gemini图像AI验证功能 {#11-Google推出Gemini图像AI验证功能}\n\n**标签：** `Google` `Gemini` `SynthID`\n\nGoogle在Gemini应用中推出AI图像验证功能，集成其DeepMind开发的SynthID水印技术。该功能可检测图像是否由AI生成，并在Gemini聊天中自动标注‘AI生成’标签。SynthID采用不可见数字水印，嵌入于图像像素中，支持跨格式（JPEG、PNG）与轻度编辑（裁剪、调色）下的识别。用户可在Gemini中上传图像，系统将返回生成概率评分与水印置信度。该功能旨在提升AI内容透明度，应对虚假信息风险，符合Google的AI安全承诺。\n\n**🔗 相关链接：**\n- <https://blog.google/technology/developers/gemini-3-pro-image-developers/>\n- <https://blog.google/technology/ai/nano-banana-pro>\n- <https://deepmind.google/models/gemini-image/pro/>\n\n---\n\n### 12. 🚀 MiniMax开放M2识图搜索MCP内测 {#12-MiniMax开放M2识图搜索MCP内测}\n\n**标签：** `MiniMax` `M2识图搜索` `MCP`\n\nAI公司MiniMax开放其M2识图搜索MCP（Multi-modal Context Platform）的内测申请。M2识图搜索支持用户上传图像，系统自动识别内容并返回相关文本、商品、地点或知识信息。MCP平台整合视觉理解、语义检索与知识图谱，支持多轮追问与上下文关联。据Linux.do社区公告，内测用户可访问API与Web界面，测试场景包括电商比价、教育辅助与图像溯源。MiniMax表示，M2模型在中文场景下表现优异，尤其在商品识别与OCR任务中准确率领先。\n\n**🔗 相关链接：**\n- <https://linux.do/t/topic/1200423>\n\n---\n\n### 13. 🔧 Manus为Slides添加speaker notes功能 {#13-Manus为Slides添加speaker-notes功能}\n\n**标签：** `Manus` `Slides` `speaker notes`\n\nAI演示工具Manus为其Slides功能新增speaker notes（演讲者备注）支持。用户在创建PPT时，可为每页幻灯片添加隐藏的备注文本，用于提示演讲内容、时间控制或补充信息。备注内容不会在演示中显示，但可在预览模式或导出PDF中查看。该功能基于Manus的AI内容生成能力，支持自动建议备注内容，如根据幻灯片标题生成讲解要点。Manus强调，speaker notes功能提升了AI生成演示文稿的实用性，适用于会议、教学与路演场景。\n\n---\n\n---\n\n## 🎬 视频链接\n\n**Bilibili：** <https://www.bilibili.com/video/BV1S9yKB1Ekb>\n\n---\n\n*整理自橘鸦AI早报 | BV号：BV1S9yKB1Ekb | 2025-11-21 20:59:06*",
      "html_content": "<h1 id=\"googlegemini-3-pro-imagenano-banana-proai-2025-11-21\">Google发布Gemini 3 Pro Image模型（Nano Banana Pro）【AI 早报 2025-11-21】</h1>\n<p><strong>📅 发布日期：</strong> 2025-11-21<br />\n<strong>🎬 BV号：</strong> BV1S9yKB1Ekb<br />\n<strong>📝 整理时间：</strong> 2025-11-21 20:59:06<br />\n<strong>📊 资讯数量：</strong> 13 条</p>\n<hr />\n<h2 id=\"_1\">📋 本期概览</h2>\n<ol>\n<li>🚀 Google发布Gemini 3 Pro图像模型</li>\n<li>🚀 OpenAI ChatGPT群聊功能全球上线</li>\n<li>🔧 OpenAI更新Mac版ChatGPT Atlas浏览器</li>\n<li>🚀 Perplexity发布Comet浏览器Android版</li>\n<li>📈 OpenAI发布GPT-5科研加速实验报告</li>\n<li>🚀 腾讯混元发布HunyuanVideo 1.5版本</li>\n<li>🔧 NotebookLM推出Slide Decks与Infographics</li>\n<li>🔧 Gemini CLI逐步开放Gemini 3 Pro访问</li>\n<li>🔧 Jules推出Repoless无仓库功能</li>\n<li>🔧 Google Stitch Flow功能升级</li>\n<li>🔧 Google推出Gemini图像AI验证功能</li>\n<li>🚀 MiniMax开放M2识图搜索MCP内测</li>\n<li>🔧 Manus为Slides添加speaker notes功能</li>\n</ol>\n<hr />\n<h3 id=\"1-Google发布Gemini-3-Pro图像模型\">1. 🚀 Google发布Gemini 3 Pro图像模型</h3>\n<p><strong>标签：</strong> <code>Google</code> <code>Gemini 3 Pro Image</code> <code>DeepMind</code></p>\n<p>Google于近日正式发布Gemini 3 Pro Image模型，作为其Gemini系列多模态模型的最新成员，专注于图像生成与理解任务。该模型在Gemini 3架构基础上进行了优化，支持更高分辨率图像生成、更精准的语义理解与上下文感知能力。据官方博客介绍，Gemini 3 Pro Image在开发者预览中已展现出在复杂视觉推理、多模态对话和图像编辑方面的显著提升。模型通过Google DeepMind团队训练，集成SynthID水印技术，用于AI生成图像的可追溯性验证。该模型现已通过Google AI Studio和Vertex AI平台向开发者开放，支持API调用。Gemini 3 Pro Image的发布标志着Google在生成式AI图像领域进一步缩小与DALL·E、Stable Diffusion等模型的差距，并强化其在企业级AI应用中的竞争力。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://blog.google/technology/developers/gemini-3-pro-image-developers/\">https://blog.google/technology/developers/gemini-3-pro-image-developers/</a><br />\n- <a href=\"https://blog.google/technology/ai/nano-banana-pro\">https://blog.google/technology/ai/nano-banana-pro</a><br />\n- <a href=\"https://deepmind.google/models/gemini-image/pro/\">https://deepmind.google/models/gemini-image/pro/</a></p>\n<hr />\n<h3 id=\"2-OpenAI-ChatGPT群聊功能全球上线\">2. 🚀 OpenAI ChatGPT群聊功能全球上线</h3>\n<p><strong>标签：</strong> <code>OpenAI</code> <code>ChatGPT</code> <code>Group Chats</code></p>\n<p>OpenAI宣布其ChatGPT的群聊功能（Group Chats）正式向全球用户开放。该功能允许用户创建多人参与的对话线程，支持跨设备同步、角色分配（如管理员、参与者）、消息提及与线程归档。群聊功能适用于团队协作、项目讨论、教育辅导等场景，用户可邀请最多20人加入同一对话，并可通过链接分享或权限控制管理访问。该功能已在Web、iOS和Android端同步上线，支持GPT-4o等最新模型。OpenAI表示，群聊功能旨在提升AI在组织协作中的实用性，推动ChatGPT从个人助手向团队智能中枢演进。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://openai.com/index/group-chats-in-chatgpt/\">https://openai.com/index/group-chats-in-chatgpt/</a><br />\n- <a href=\"https://help.openai.com/en/articles/12703475-group-chats-in-chatgpt\">https://help.openai.com/en/articles/12703475-group-chats-in-chatgpt</a><br />\n- <a href=\"https://x.com/OpenAI/status/1991312374092165471\">https://x.com/OpenAI/status/1991312374092165471</a></p>\n<hr />\n<h3 id=\"3-OpenAI更新Mac版ChatGPT-Atlas浏览器\">3. 🔧 OpenAI更新Mac版ChatGPT Atlas浏览器</h3>\n<p><strong>标签：</strong> <code>OpenAI</code> <code>ChatGPT</code> <code>Atlas浏览器</code></p>\n<p>OpenAI通过官方X账号宣布，Mac版ChatGPT应用中的Atlas浏览器组件已更新。Atlas是ChatGPT桌面端用于网页浏览与内容提取的内置浏览器，此次更新优化了页面加载速度、JavaScript执行效率与隐私保护机制。更新后，Atlas支持更复杂的网页交互（如动态表单、登录流程），并增强了对JavaScript密集型网站（如Notion、Figma）的兼容性。该更新提升了ChatGPT在信息检索、实时数据分析和自动化任务执行中的能力，尤其适用于需要结合网络内容的复杂查询场景。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://openai.com/index/group-chats-in-chatgpt/\">https://openai.com/index/group-chats-in-chatgpt/</a><br />\n- <a href=\"https://help.openai.com/en/articles/12703475-group-chats-in-chatgpt\">https://help.openai.com/en/articles/12703475-group-chats-in-chatgpt</a><br />\n- <a href=\"https://x.com/OpenAI/status/1991312374092165471\">https://x.com/OpenAI/status/1991312374092165471</a></p>\n<hr />\n<h3 id=\"4-Perplexity发布Comet浏览器Android版\">4. 🚀 Perplexity发布Comet浏览器Android版</h3>\n<p><strong>标签：</strong> <code>Perplexity</code> <code>Comet浏览器</code> <code>AI搜索</code></p>\n<p>AI搜索公司Perplexity正式推出其Comet浏览器的Android版本。Comet是Perplexity专为AI增强搜索设计的轻量级浏览器，集成其自研搜索模型，支持语音输入、实时摘要、多轮追问与跨页面信息聚合。Android版Comet延续了iOS端的核心功能，包括‘Ask with Search’即时AI问答、页面高亮与知识图谱生成。用户可通过侧边栏直接调用AI助手，无需跳转应用。该发布标志着Perplexity在移动端AI搜索生态的进一步布局，旨在挑战传统浏览器与搜索引擎的交互范式。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/ChrisUniverseB/status/1991567489055224091\">https://x.com/ChrisUniverseB/status/1991567489055224091</a></p>\n<hr />\n<h3 id=\"5-OpenAI发布GPT-5科研加速实验报告\">5. 📈 OpenAI发布GPT-5科研加速实验报告</h3>\n<p><strong>标签：</strong> <code>OpenAI</code> <code>GPT-5</code> <code>科研加速</code></p>\n<p>OpenAI发布《GPT-5早期科研加速实验报告》，披露其在科学发现领域使用GPT-5模型进行的前瞻性测试。实验涵盖化学、生物学、材料科学等领域，GPT-5被用于假设生成、文献综述、实验设计优化与数据解释。报告指出，GPT-5在‘逆向分子设计’任务中提出的新化合物结构中，有12%被实验室验证为可行；在‘文献综述自动化’任务中，节省研究人员平均40%时间。报告还强调模型在跨学科知识整合方面的潜力，如将量子计算与生物传感结合提出新应用。该报告为AI辅助科研提供了实证依据，但OpenAI强调GPT-5仍处于早期阶段，尚未公开可用。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://openai.com/index/group-chats-in-chatgpt/\">https://openai.com/index/group-chats-in-chatgpt/</a><br />\n- <a href=\"https://help.openai.com/en/articles/12703475-group-chats-in-chatgpt\">https://help.openai.com/en/articles/12703475-group-chats-in-chatgpt</a><br />\n- <a href=\"https://x.com/OpenAI/status/1991312374092165471\">https://x.com/OpenAI/status/1991312374092165471</a></p>\n<hr />\n<h3 id=\"6-腾讯混元发布HunyuanVideo-15版本\">6. 🚀 腾讯混元发布HunyuanVideo 1.5版本</h3>\n<p><strong>标签：</strong> <code>腾讯混元</code> <code>HunyuanVideo 1.5</code> <code>视频生成</code></p>\n<p>腾讯混元大模型团队宣布将于今日发布HunyuanVideo 1.5版本。该版本为视频生成模型的重大升级，支持最长10秒、1080p分辨率的视频生成，帧率提升至30fps，并引入‘运动一致性’与‘物理合理性’优化算法。HunyuanVideo 1.5支持文本到视频（Text-to-Video）与图像到视频（Image-to-Video）两种模式，新增‘风格迁移’与‘镜头控制’功能，用户可通过提示词控制运镜方式（如推、拉、摇）。该版本面向内容创作者、广告与影视行业开放内测，标志着国产视频生成模型在质量与可控性上的重要进展。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://mp.weixin.qq.com/s/n7EYBtuA6koPcb_Wm6azTQ\">https://mp.weixin.qq.com/s/n7EYBtuA6koPcb_Wm6azTQ</a></p>\n<hr />\n<h3 id=\"7-NotebookLM推出Slide-Decks与Infogr\">7. 🔧 NotebookLM推出Slide Decks与Infographics</h3>\n<p><strong>标签：</strong> <code>NotebookLM</code> <code>Slide Decks</code> <code>Infographics</code></p>\n<p>Google的AI笔记工具NotebookLM新增Slide Decks（幻灯片）与Infographics（信息图）自动生成功能。用户上传文档或笔记后，NotebookLM可自动提取关键信息，生成结构化的PPT幻灯片或可视化信息图，支持自定义主题、配色与布局。Slide Decks功能支持Markdown导出，Infographics则提供柱状图、流程图、时间线等多种模板。该功能基于Gemini模型实现，适用于教育、企业汇报与知识管理场景，显著降低内容可视化门槛。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/NotebookLM/status/1991575294352740686\">https://x.com/NotebookLM/status/1991575294352740686</a></p>\n<hr />\n<h3 id=\"8-Gemini-CLI逐步开放Gemini-3-Pro访问\">8. 🔧 Gemini CLI逐步开放Gemini 3 Pro访问</h3>\n<p><strong>标签：</strong> <code>Google</code> <code>Gemini CLI</code> <code>Gemini 3 Pro</code></p>\n<p>Google开始向Pro用户逐步开放Gemini CLI对Gemini 3 Pro模型的访问权限。Gemini CLI是命令行界面工具，允许开发者通过终端直接调用Gemini系列模型API。此次更新后，Pro用户可在CLI中指定使用Gemini 3 Pro模型，支持图像输入、多轮对话与函数调用。该功能提升了开发者在本地环境中的AI集成效率，尤其适用于自动化脚本、CI/CD流程与服务器端应用。Google表示，权限将分阶段推送，预计两周内覆盖全部Pro用户。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://blog.google/technology/developers/gemini-3-pro-image-developers/\">https://blog.google/technology/developers/gemini-3-pro-image-developers/</a><br />\n- <a href=\"https://blog.google/technology/ai/nano-banana-pro\">https://blog.google/technology/ai/nano-banana-pro</a><br />\n- <a href=\"https://deepmind.google/models/gemini-image/pro/\">https://deepmind.google/models/gemini-image/pro/</a></p>\n<hr />\n<h3 id=\"9-Jules推出Repoless无仓库功能\">9. 🔧 Jules推出Repoless无仓库功能</h3>\n<p><strong>标签：</strong> <code>Jules</code> <code>Repoless</code> <code>Google</code></p>\n<p>Google的AI编程助手Jules推出‘Repoless’（无仓库）功能，允许用户无需创建代码仓库即可开始编程。用户可通过‘Start from scratch’选项，在Jules中直接编写代码，系统自动管理临时项目空间，支持代码生成、调试与版本快照。该功能适用于快速原型开发、教学演示与临时任务，降低使用门槛。Jules还集成Gemini模型，提供智能代码补全与错误修复建议。Google强调，Repoless项目不会自动同步至云端仓库，保障用户隐私。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://blog.google/technology/developers/gemini-3-pro-image-developers/\">https://blog.google/technology/developers/gemini-3-pro-image-developers/</a><br />\n- <a href=\"https://blog.google/technology/ai/nano-banana-pro\">https://blog.google/technology/ai/nano-banana-pro</a><br />\n- <a href=\"https://deepmind.google/models/gemini-image/pro/\">https://deepmind.google/models/gemini-image/pro/</a></p>\n<hr />\n<h3 id=\"10-Google-Stitch-Flow功能升级\">10. 🔧 Google Stitch Flow功能升级</h3>\n<p><strong>标签：</strong> <code>Google</code> <code>Stitch Flow</code> <code>自动化编排</code></p>\n<p>Google宣布其Stitch Flow功能迎来重大升级。Stitch Flow是用于连接多个AI服务与API的自动化编排工具，此次更新增强了跨服务状态管理、错误重试机制与可视化流程编辑器。用户可创建包含Gemini、Vertex AI、Firebase等服务的复杂工作流，支持条件分支、并行执行与数据转换。升级后，Stitch Flow支持JSON Schema验证与OAuth 2.0集成，提升企业级应用的安全性与可靠性。该功能主要面向开发者与DevOps团队，用于构建端到端AI应用。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://blog.google/technology/developers/gemini-3-pro-image-developers/\">https://blog.google/technology/developers/gemini-3-pro-image-developers/</a><br />\n- <a href=\"https://blog.google/technology/ai/nano-banana-pro\">https://blog.google/technology/ai/nano-banana-pro</a><br />\n- <a href=\"https://deepmind.google/models/gemini-image/pro/\">https://deepmind.google/models/gemini-image/pro/</a></p>\n<hr />\n<h3 id=\"11-Google推出Gemini图像AI验证功能\">11. 🔧 Google推出Gemini图像AI验证功能</h3>\n<p><strong>标签：</strong> <code>Google</code> <code>Gemini</code> <code>SynthID</code></p>\n<p>Google在Gemini应用中推出AI图像验证功能，集成其DeepMind开发的SynthID水印技术。该功能可检测图像是否由AI生成，并在Gemini聊天中自动标注‘AI生成’标签。SynthID采用不可见数字水印，嵌入于图像像素中，支持跨格式（JPEG、PNG）与轻度编辑（裁剪、调色）下的识别。用户可在Gemini中上传图像，系统将返回生成概率评分与水印置信度。该功能旨在提升AI内容透明度，应对虚假信息风险，符合Google的AI安全承诺。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://blog.google/technology/developers/gemini-3-pro-image-developers/\">https://blog.google/technology/developers/gemini-3-pro-image-developers/</a><br />\n- <a href=\"https://blog.google/technology/ai/nano-banana-pro\">https://blog.google/technology/ai/nano-banana-pro</a><br />\n- <a href=\"https://deepmind.google/models/gemini-image/pro/\">https://deepmind.google/models/gemini-image/pro/</a></p>\n<hr />\n<h3 id=\"12-MiniMax开放M2识图搜索MCP内测\">12. 🚀 MiniMax开放M2识图搜索MCP内测</h3>\n<p><strong>标签：</strong> <code>MiniMax</code> <code>M2识图搜索</code> <code>MCP</code></p>\n<p>AI公司MiniMax开放其M2识图搜索MCP（Multi-modal Context Platform）的内测申请。M2识图搜索支持用户上传图像，系统自动识别内容并返回相关文本、商品、地点或知识信息。MCP平台整合视觉理解、语义检索与知识图谱，支持多轮追问与上下文关联。据Linux.do社区公告，内测用户可访问API与Web界面，测试场景包括电商比价、教育辅助与图像溯源。MiniMax表示，M2模型在中文场景下表现优异，尤其在商品识别与OCR任务中准确率领先。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://linux.do/t/topic/1200423\">https://linux.do/t/topic/1200423</a></p>\n<hr />\n<h3 id=\"13-Manus为Slides添加speaker-notes功能\">13. 🔧 Manus为Slides添加speaker notes功能</h3>\n<p><strong>标签：</strong> <code>Manus</code> <code>Slides</code> <code>speaker notes</code></p>\n<p>AI演示工具Manus为其Slides功能新增speaker notes（演讲者备注）支持。用户在创建PPT时，可为每页幻灯片添加隐藏的备注文本，用于提示演讲内容、时间控制或补充信息。备注内容不会在演示中显示，但可在预览模式或导出PDF中查看。该功能基于Manus的AI内容生成能力，支持自动建议备注内容，如根据幻灯片标题生成讲解要点。Manus强调，speaker notes功能提升了AI生成演示文稿的实用性，适用于会议、教学与路演场景。</p>\n<hr />\n<hr />\n<h2 id=\"_2\">🎬 视频链接</h2>\n<p><strong>Bilibili：</strong> <a href=\"https://www.bilibili.com/video/BV1S9yKB1Ekb\">https://www.bilibili.com/video/BV1S9yKB1Ekb</a></p>\n<hr />\n<p><em>整理自橘鸦AI早报 | BV号：BV1S9yKB1Ekb | 2025-11-21 20:59:06</em></p>",
      "date": "2025-11-21",
      "filename": "2025-11-21_AI早报_BV1S9yKB1Ekb.md"
    },
    {
      "title": "OpenAI发布 GPT-5.1-Codex-Max、上线GPT-5.1 Pro；xAI发布 Grok 4.1 Fast【AI 早报 2025-11-20】",
      "publish_date": "2025-11-20",
      "bv_id": "BV1PSCZB7EST",
      "organize_time": "2025-11-20 16:58:11",
      "news_count": 18,
      "overview": "1. 🚀 OpenAI发布GPT-5.1-Codex-Max编码模型\n2. 🚀 OpenAI上线GPT-5.1 Pro模型\n3. 🚀 xAI发布Grok 4.1 Fast模型及Agent Tools API\n4. 🚀 Meta发布SAM 3与SAM 3D模型\n5. 🚀 微软发布Copilot Agent 365控制平台\n6. 📈 Anthropic延长Claude Code免费额度\n7. 🚀 Gemini 3上线移动端与Jules工具\n8. 🔧 Google Gemini开放Photos导入功能\n9. 🔧 Stitch推出一键导出AI Studio功能\n10. 🚀 OpenAI发布ChatGPT for Teachers\n11. 🔧 Perplexity Pro/Max新增文档构建功能\n12. 🚀 Deep Cogito发布Cogito v2.1 671B模型\n13. 🚀 ZeroEntropy发布zerank-2重排序模型\n14. 🔧 Inclusion AI发布Awex RL权重同步框架\n15. 🚀 RadixArk发布Miles RL框架\n16. 📈 OpenAI发布企业AI评估框架指南\n17. 🔧 DeepSeek开源LPLB MoE负载均衡器\n18. 🔧 VARC框架用ViT解决ARC视觉推理",
      "content": "# OpenAI发布 GPT-5.1-Codex-Max、上线GPT-5.1 Pro；xAI发布 Grok 4.1 Fast【AI 早报 2025-11-20】\n\n**📅 发布日期：** 2025-11-20\n**🎬 BV号：** BV1PSCZB7EST\n**📝 整理时间：** 2025-11-20 16:58:11\n**📊 资讯数量：** 18 条\n\n---\n\n## 📋 本期概览\n\n1. 🚀 OpenAI发布GPT-5.1-Codex-Max编码模型\n2. 🚀 OpenAI上线GPT-5.1 Pro模型\n3. 🚀 xAI发布Grok 4.1 Fast模型及Agent Tools API\n4. 🚀 Meta发布SAM 3与SAM 3D模型\n5. 🚀 微软发布Copilot Agent 365控制平台\n6. 📈 Anthropic延长Claude Code免费额度\n7. 🚀 Gemini 3上线移动端与Jules工具\n8. 🔧 Google Gemini开放Photos导入功能\n9. 🔧 Stitch推出一键导出AI Studio功能\n10. 🚀 OpenAI发布ChatGPT for Teachers\n11. 🔧 Perplexity Pro/Max新增文档构建功能\n12. 🚀 Deep Cogito发布Cogito v2.1 671B模型\n13. 🚀 ZeroEntropy发布zerank-2重排序模型\n14. 🔧 Inclusion AI发布Awex RL权重同步框架\n15. 🚀 RadixArk发布Miles RL框架\n16. 📈 OpenAI发布企业AI评估框架指南\n17. 🔧 DeepSeek开源LPLB MoE负载均衡器\n18. 🔧 VARC框架用ViT解决ARC视觉推理\n\n---\n\n### 1. 🚀 OpenAI发布GPT-5.1-Codex-Max编码模型 {#1-OpenAI发布GPT-51-Codex-Max编码模型}\n\n**标签：** `OpenAI` `GPT-5.1-Codex-Max` `Agentic编码`\n\nOpenAI于近日发布GPT-5.1-Codex-Max，一款专注于Agentic编码场景的专用模型。该模型基于GPT-5.1架构，集成Codex能力，支持自主代码生成、调试、重构及多轮任务执行，具备上下文感知和工具调用能力，可模拟开发者行为完成端到端编码任务。其核心特性包括：支持多语言编程（Python、JavaScript、Go等）、API自动集成、代码安全性评估、与CI/CD流程对接。该模型适用于自动化开发、低代码平台、AI编程助手等场景，有望显著提升软件开发效率，降低人力成本。发布页面（<<https://openai.com/index/gpt-5-1-codex-max/>>）提供了技术文档与试用入口。\n\n**🔗 相关链接：**\n- <https://openai.com/index/gpt-5-1-codex-max/>\n- <https://x.com/OpenAI/status/1991266192905179613>\n- <https://openai.com/index/chatgpt-for-teachers/>\n\n---\n\n### 2. 🚀 OpenAI上线GPT-5.1 Pro模型 {#2-OpenAI上线GPT-51-Pro模型}\n\n**标签：** `OpenAI` `GPT-5.1 Pro` `API服务`\n\nOpenAI通过官方X账号（@OpenAI）宣布正式上线GPT-5.1 Pro模型，作为GPT-5.1系列的高性能版本，面向企业用户和开发者提供增强推理、更长上下文窗口（推测达128K tokens以上）及更高的多轮对话稳定性。该模型在数学推理、逻辑推理和长文档理解任务上表现优于前代，支持更复杂的指令遵循与结构化输出。GPT-5.1 Pro将集成至ChatGPT企业版及API服务中，适用于金融分析、法律文书处理、科研辅助等高要求场景。发布时间为2025年11月18日左右，具体技术细节尚未完全公开。\n\n**🔗 相关链接：**\n- <https://openai.com/index/gpt-5-1-codex-max/>\n- <https://x.com/OpenAI/status/1991266192905179613>\n- <https://openai.com/index/chatgpt-for-teachers/>\n\n---\n\n### 3. 🚀 xAI发布Grok 4.1 Fast模型及Agent Tools API {#3-xAI发布Grok-41-Fast模型及Agent-Tool}\n\n**标签：** `xAI` `Grok 4.1 Fast` `Agent Tools API`\n\nxAI发布Grok 4.1 Fast模型，作为Grok 4系列的轻量化高性能版本，专为低延迟响应和实时交互优化，推理速度较标准版提升约40%。同时推出Agent Tools API，允许开发者构建基于Grok的AI代理，支持工具调用（如搜索、代码执行、数据库查询）、状态记忆与多步任务规划。API提供Python SDK与REST接口，支持与LangChain等框架集成。Grok 4.1 Fast适用于客服机器人、实时数据分析、自动化运维等场景，标志着xAI向企业级AI代理平台迈进。详情见官方新闻页（<https://x.ai/news/grok-4-1-fast>）。\n\n**🔗 相关链接：**\n- <https://x.ai/news/grok-4-1-fast>\n\n---\n\n### 4. 🚀 Meta发布SAM 3与SAM 3D模型 {#4-Meta发布SAM-3与SAM-3D模型}\n\n**标签：** `Meta` `SAM 3` `SAM 3D`\n\nMeta发布新一代Segment Anything Model 3（SAM 3），在图像分割精度、速度和泛化能力上实现显著提升，支持更高分辨率输入（达4K）与多模态提示（文本+图像）。同时推出SAM 3D，首个基于SAM架构的3D场景重建模型，可从多视角图像或点云数据中自动分割并重建3D物体，支持NeRF与Mesh输出。SAM 3D采用分层注意力机制，实现跨视角一致性分割，适用于AR/VR内容生成、自动驾驶感知、数字孪生等场景。模型已在GitHub开源，技术博客（<https://ai.meta.com/blog/sam-3d/>）提供详细架构说明。\n\n**🔗 相关链接：**\n- <https://ai.meta.com/sam3/>\n- <https://ai.meta.com/blog/sam-3d/>\n\n---\n\n### 5. 🚀 微软发布Copilot Agent 365控制平台 {#5-微软发布Copilot-Agent-365控制平台}\n\n**标签：** `微软` `Copilot Agent 365` `Control Plane`\n\n微软发布Copilot Agent 365，作为AI代理的统一控制平面（Control Plane），用于管理、编排和监控企业内多个Copilot代理的运行。该平台支持代理生命周期管理、权限控制、任务调度、日志审计与性能监控，提供可视化仪表盘与API接口。Agent 365可集成Teams、Outlook、SharePoint等Microsoft 365服务，实现跨应用自动化流程，如会议纪要生成、邮件分类、文档审批等。其核心价值在于提升企业AI代理的可治理性与可扩展性，降低运维复杂度。发布信息详见微软官方博客（<https://www.microsoft.com/en-us/microsoft-365/blog/2025/11/18/microsoft-agent-365-the-control-plane-for-ai-agents/>）。\n\n**🔗 相关链接：**\n- <https://www.microsoft.com/en-us/microsoft-365/blog/2025/11/18/microsoft-agent-365-the-control-plane-for-ai-agents/>\n\n---\n\n### 6. 📈 Anthropic延长Claude Code免费额度 {#6-Anthropic延长Claude-Code免费额度}\n\n**标签：** `Anthropic` `Claude Code` `免费额度`\n\nAnthropic通过开发者Cat Wu（@_catwu）宣布，将Claude Code网页版免费使用额度有效期延长，具体延长时间未明确，但强调为支持开发者社区持续探索AI编程能力。Claude Code是Anthropic推出的AI编程助手，支持代码生成、解释、调试与文档撰写，集成于浏览器环境，无需本地部署。此次延长有助于降低开发者试用门槛，推动生态建设，尤其利好学生和初创团队。该举措也反映出AI编程工具市场竞争加剧，各厂商通过免费策略抢占用户。\n\n**🔗 相关链接：**\n- <https://x.com/_catwu/status/1991280133014278273>\n\n---\n\n### 7. 🚀 Gemini 3上线移动端与Jules工具 {#7-Gemini-3上线移动端与Jules工具}\n\n**标签：** `Gemini 3` `Jules` `移动端`\n\nGemini 3模型正式登陆移动端（iOS/Android），支持离线推理与低功耗模式，响应速度优化30%以上。同时推出Jules工具，专为开发者设计的命令行接口（CLI），支持本地代码分析、API调用与模型微调。Jules可与Gemini 3无缝集成，实现自动化代码审查、文档生成与测试用例编写。移动端支持语音输入、图像识别与多模态交互，适用于移动开发、现场运维、教育辅导等场景。发布信息由开发者Simpsoka（@simpsoka）在X平台披露。\n\n**🔗 相关链接：**\n- <https://x.com/simpsoka/status/1991209318096716109>\n- <https://x.com/testingcatalog/status/1991126479220949293>\n\n---\n\n### 8. 🔧 Google Gemini开放Photos导入功能 {#8-Google-Gemini开放Photos导入功能}\n\n**标签：** `Google Gemini` `Photos导入` `多模态分析`\n\nGoogle Gemini网页版新增Photos导入功能，用户可直接从Google Photos中选择图像上传至Gemini进行多模态分析。该功能支持批量上传（最多10张）、自动元数据读取（如拍摄时间、地点）与上下文关联分析，适用于图像内容识别、场景描述、OCR提取等任务。Gemini可结合图像与文本提示生成结构化报告，如旅行日志、产品清单、教学材料。此举强化了Gemini在个人助理与内容创作领域的竞争力，提升用户体验。功能已通过TestingCatalog（@testingcatalog）在X平台验证。\n\n**🔗 相关链接：**\n- <https://x.com/testingcatalog/status/1991126479220949293>\n\n---\n\n### 9. 🔧 Stitch推出一键导出AI Studio功能 {#9-Stitch推出一键导出AI-Studio功能}\n\n**标签：** `Stitch` `AI Studio` `一键导出`\n\nStitch（Google旗下低代码平台）推出一键导出AI Studio功能，用户可将Stitch中构建的AI应用（如聊天机器人、表单助手）直接导出为AI Studio项目，支持代码级自定义与部署。该功能支持导出为Python、Node.js项目，保留原有逻辑、数据源与UI组件，便于开发者进行二次开发与集成。AI Studio为Google的AI开发环境，支持模型训练、部署与监控。此举降低了低代码与专业开发之间的壁垒，提升开发效率。发布信息由Stitch官方账号（@stitchbygoogle）在X平台公布。\n\n**🔗 相关链接：**\n- <https://x.com/stitchbygoogle/status/1991232172678869093>\n\n---\n\n### 10. 🚀 OpenAI发布ChatGPT for Teachers {#10-OpenAI发布ChatGPT-for-Teachers}\n\n**标签：** `OpenAI` `ChatGPT for Teachers` `教育AI`\n\nOpenAI发布ChatGPT for Teachers，专为教育工作者设计的AI助手，集成于教育版ChatGPT中。该版本提供课程计划生成、作业批改、学生反馈撰写、个性化学习建议等功能，支持多语言教学场景。系统内置教育伦理审查机制，避免生成不当内容，并符合FERPA等数据隐私标准。教师可通过自然语言指令快速生成教学材料，如PPT大纲、测验题、阅读材料。该工具有望提升教学效率，推动AI在教育领域的普惠应用。详情见官方页面（<https://openai.com/index/chatgpt-for-teachers/>）。\n\n**🔗 相关链接：**\n- <https://openai.com/index/gpt-5-1-codex-max/>\n- <https://x.com/OpenAI/status/1991266192905179613>\n- <https://openai.com/index/chatgpt-for-teachers/>\n\n---\n\n### 11. 🔧 Perplexity Pro/Max新增文档构建功能 {#11-Perplexity-ProMax新增文档构建功能}\n\n**标签：** `Perplexity` `Pro/Max` `文档构建`\n\nPerplexity AI宣布其Pro与Max订阅用户新增文档构建与编辑功能，支持在对话中直接创建、修改和导出结构化文档（如报告、提案、论文）。用户可通过自然语言指令添加标题、段落、表格、图表，并实时预览排版效果。系统支持Markdown与PDF导出，集成AI写作建议与语法检查。该功能强化了Perplexity作为研究型AI助手的定位，适用于学术写作、市场分析、法律文书等场景。发布信息由官方账号（@perplexity_ai）在X平台公布。\n\n**🔗 相关链接：**\n- <https://x.com/perplexity_ai/status/1991206262563041316>\n\n---\n\n### 12. 🚀 Deep Cogito发布Cogito v2.1 671B模型 {#12-Deep-Cogito发布Cogito-v21-671B模型}\n\n**标签：** `Deep Cogito` `Cogito v2.1` `671B模型`\n\nDeep Cogito发布Cogito v2.1，参数规模达671B，为当前开源领域最大规模的推理专用模型之一。该模型在数学推理、逻辑推理与代码生成任务上表现优异，支持复杂指令遵循与多步推理。采用混合专家（MoE）架构，激活参数约120B，兼顾性能与效率。模型已在Hugging Face开源（<https://huggingface.co/deepcogito/cogito-671b-v2.1>），并提供技术报告（<https://www.deepcogito.com/research/cogito-v2-1>）。适用于科研、金融建模、自动化决策等高推理需求场景。\n\n**🔗 相关链接：**\n- <https://huggingface.co/deepcogito/cogito-671b-v2.1>\n- <https://www.deepcogito.com/research/cogito-v2-1>\n\n---\n\n### 13. 🚀 ZeroEntropy发布zerank-2重排序模型 {#13-ZeroEntropy发布zerank-2重排序模型}\n\n**标签：** `ZeroEntropy` `zerank-2` `重排序模型`\n\nZeroEntropy发布zerank-2，一款先进的指令遵循多模态重排序模型，支持文本、图像、音频输入，输出相关性排序与置信度评分。该模型在MS MARCO、TREC等基准测试中表现领先，支持细粒度指令解析（如'找红色圆形物体'），适用于搜索引擎、推荐系统、AI助手等场景。模型已在Hugging Face开源（https://huggingface.co/zeroentropy/zerank-2），并提供技术文章（<https://www.zeroentropy.dev/articles/zerank-2-advanced-instruction-following-multimodal-reranker>）。其多模态能力为下一代信息检索系统提供新范式。\n\n**🔗 相关链接：**\n- <https://huggingface.co/zeroentropy/zerank-2>\n- <https://www.zeroentropy.dev/articles/zerank-2-advanced-instruction-following-multimodal-reranker>\n\n---\n\n### 14. 🔧 Inclusion AI发布Awex RL权重同步框架 {#14-Inclusion-AI发布Awex-RL权重同步框架}\n\n**标签：** `Inclusion AI` `Awex` `RL权重同步`\n\nInclusion AI发布Awex，一款高性能强化学习（RL）权重同步框架，专为分布式训练设计。Awex采用异步梯度聚合与压缩通信机制，支持跨节点、跨GPU的实时权重同步，延迟低于10ms，带宽占用减少60%。框架支持PyTorch与JAX，集成于asystem-awex开源项目（<https://github.com/inclusionAI/asystem-awex>），适用于大规模RL训练、多智能体系统、边缘计算等场景。其高效同步机制可显著提升训练速度与资源利用率。\n\n**🔗 相关链接：**\n- <https://github.com/inclusionAI/asystem-awex>\n\n---\n\n### 15. 🚀 RadixArk发布Miles RL框架 {#15-RadixArk发布Miles-RL框架}\n\n**标签：** `RadixArk` `Miles` `RL框架`\n\nRadixArk发布Miles，一款轻量级强化学习（RL）框架，专为快速原型设计与实验验证优化。Miles支持模块化组件（环境、策略、奖励函数）、内置基准测试套件（如Atari、MuJoCo）与可视化工具，提供Python API与命令行接口。框架强调易用性与可扩展性，适用于学术研究、教学演示与小型项目。技术细节发表于LMSYS博客（<https://lmsys.org/blog/2025-11-19-miles/>），已在GitHub开源。Miles有望降低RL开发门槛，推动算法创新。\n\n**🔗 相关链接：**\n- <https://lmsys.org/blog/2025-11-19-miles/>\n\n---\n\n### 16. 📈 OpenAI发布企业AI评估框架指南 {#16-OpenAI发布企业AI评估框架指南}\n\n**标签：** `OpenAI` `AI评估框架` `Evals`\n\nOpenAI发布《企业AI评估框架指南》，系统阐述如何构建AI模型评估体系（Evals），涵盖指标设计、测试集构建、自动化评估与持续监控。指南提出分层评估模型：基础能力（如准确率）、业务价值（如转化率）、伦理合规（如偏见检测）。支持自定义评估器与集成CI/CD流程，适用于金融、医疗、制造等行业。该框架旨在帮助企业科学评估AI系统性能，降低部署风险。详情见官方页面（https://openai.com/index/evals-drive-next-chapter-of-ai/）。\n\n**🔗 相关链接：**\n- <https://openai.com/index/gpt-5-1-codex-max/>\n- <https://x.com/OpenAI/status/1991266192905179613>\n- <https://openai.com/index/chatgpt-for-teachers/>\n\n---\n\n### 17. 🔧 DeepSeek开源LPLB MoE负载均衡器 {#17-DeepSeek开源LPLB-MoE负载均衡器}\n\n**标签：** `DeepSeek` `LPLB` `MoE负载均衡`\n\nDeepSeek开源LPLB（Linear Programming Load Balancer），一款基于线性规划的MoE（混合专家）并行负载均衡器。LPLB通过数学优化模型动态分配专家计算任务，最小化通信开销与计算延迟，支持大规模分布式训练。实验表明，在1024 GPU集群上，负载均衡效率提升25%，训练吞吐量提高18%。代码已在GitHub开源（<https://github.com/deepseek-ai/LPLB>），适用于大模型训练、多任务学习等场景。该技术为MoE架构的高效训练提供新解决方案。\n\n**🔗 相关链接：**\n- <https://github.com/deepseek-ai/LPLB>\n\n---\n\n### 18. 🔧 VARC框架用ViT解决ARC视觉推理 {#18-VARC框架用ViT解决ARC视觉推理}\n\n**标签：** `VARC框架` `ViT` `ARC`\n\n研究提出VARC（Vision-Augmented Reasoning Chain）框架，首次成功利用Vision Transformer（ViT）解决Abstraction and Reasoning Corpus（ARC）视觉推理任务。VARC将图像输入ViT提取特征，结合符号推理模块生成逻辑链条，支持零样本迁移。在ARC基准测试中，VARC在未见任务上准确率达68.3%，显著优于传统CNN方法。该框架为通用人工智能（AGI）研究提供新路径，推动视觉-符号融合推理发展。研究细节未完全公开，但已在社区引发关注。\n\n---\n\n---\n\n## 🎬 视频链接\n\n**Bilibili：** <https://www.bilibili.com/video/BV1PSCZB7EST>\n\n---\n\n*整理自橘鸦AI早报 | BV号：BV1PSCZB7EST | 2025-11-20 16:58:11*",
      "html_content": "<h1 id=\"openai-gpt-51-codex-maxgpt-51-proxai-grok-41-fastai-2025-11-20\">OpenAI发布 GPT-5.1-Codex-Max、上线GPT-5.1 Pro；xAI发布 Grok 4.1 Fast【AI 早报 2025-11-20】</h1>\n<p><strong>📅 发布日期：</strong> 2025-11-20<br />\n<strong>🎬 BV号：</strong> BV1PSCZB7EST<br />\n<strong>📝 整理时间：</strong> 2025-11-20 16:58:11<br />\n<strong>📊 资讯数量：</strong> 18 条</p>\n<hr />\n<h2 id=\"_1\">📋 本期概览</h2>\n<ol>\n<li>🚀 OpenAI发布GPT-5.1-Codex-Max编码模型</li>\n<li>🚀 OpenAI上线GPT-5.1 Pro模型</li>\n<li>🚀 xAI发布Grok 4.1 Fast模型及Agent Tools API</li>\n<li>🚀 Meta发布SAM 3与SAM 3D模型</li>\n<li>🚀 微软发布Copilot Agent 365控制平台</li>\n<li>📈 Anthropic延长Claude Code免费额度</li>\n<li>🚀 Gemini 3上线移动端与Jules工具</li>\n<li>🔧 Google Gemini开放Photos导入功能</li>\n<li>🔧 Stitch推出一键导出AI Studio功能</li>\n<li>🚀 OpenAI发布ChatGPT for Teachers</li>\n<li>🔧 Perplexity Pro/Max新增文档构建功能</li>\n<li>🚀 Deep Cogito发布Cogito v2.1 671B模型</li>\n<li>🚀 ZeroEntropy发布zerank-2重排序模型</li>\n<li>🔧 Inclusion AI发布Awex RL权重同步框架</li>\n<li>🚀 RadixArk发布Miles RL框架</li>\n<li>📈 OpenAI发布企业AI评估框架指南</li>\n<li>🔧 DeepSeek开源LPLB MoE负载均衡器</li>\n<li>🔧 VARC框架用ViT解决ARC视觉推理</li>\n</ol>\n<hr />\n<h3 id=\"1-OpenAI发布GPT-51-Codex-Max编码模型\">1. 🚀 OpenAI发布GPT-5.1-Codex-Max编码模型</h3>\n<p><strong>标签：</strong> <code>OpenAI</code> <code>GPT-5.1-Codex-Max</code> <code>Agentic编码</code></p>\n<p>OpenAI于近日发布GPT-5.1-Codex-Max，一款专注于Agentic编码场景的专用模型。该模型基于GPT-5.1架构，集成Codex能力，支持自主代码生成、调试、重构及多轮任务执行，具备上下文感知和工具调用能力，可模拟开发者行为完成端到端编码任务。其核心特性包括：支持多语言编程（Python、JavaScript、Go等）、API自动集成、代码安全性评估、与CI/CD流程对接。该模型适用于自动化开发、低代码平台、AI编程助手等场景，有望显著提升软件开发效率，降低人力成本。发布页面（&lt;<a href=\"https://openai.com/index/gpt-5-1-codex-max/\">https://openai.com/index/gpt-5-1-codex-max/</a>&gt;）提供了技术文档与试用入口。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://openai.com/index/gpt-5-1-codex-max/\">https://openai.com/index/gpt-5-1-codex-max/</a><br />\n- <a href=\"https://x.com/OpenAI/status/1991266192905179613\">https://x.com/OpenAI/status/1991266192905179613</a><br />\n- <a href=\"https://openai.com/index/chatgpt-for-teachers/\">https://openai.com/index/chatgpt-for-teachers/</a></p>\n<hr />\n<h3 id=\"2-OpenAI上线GPT-51-Pro模型\">2. 🚀 OpenAI上线GPT-5.1 Pro模型</h3>\n<p><strong>标签：</strong> <code>OpenAI</code> <code>GPT-5.1 Pro</code> <code>API服务</code></p>\n<p>OpenAI通过官方X账号（@OpenAI）宣布正式上线GPT-5.1 Pro模型，作为GPT-5.1系列的高性能版本，面向企业用户和开发者提供增强推理、更长上下文窗口（推测达128K tokens以上）及更高的多轮对话稳定性。该模型在数学推理、逻辑推理和长文档理解任务上表现优于前代，支持更复杂的指令遵循与结构化输出。GPT-5.1 Pro将集成至ChatGPT企业版及API服务中，适用于金融分析、法律文书处理、科研辅助等高要求场景。发布时间为2025年11月18日左右，具体技术细节尚未完全公开。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://openai.com/index/gpt-5-1-codex-max/\">https://openai.com/index/gpt-5-1-codex-max/</a><br />\n- <a href=\"https://x.com/OpenAI/status/1991266192905179613\">https://x.com/OpenAI/status/1991266192905179613</a><br />\n- <a href=\"https://openai.com/index/chatgpt-for-teachers/\">https://openai.com/index/chatgpt-for-teachers/</a></p>\n<hr />\n<h3 id=\"3-xAI发布Grok-41-Fast模型及Agent-Tool\">3. 🚀 xAI发布Grok 4.1 Fast模型及Agent Tools API</h3>\n<p><strong>标签：</strong> <code>xAI</code> <code>Grok 4.1 Fast</code> <code>Agent Tools API</code></p>\n<p>xAI发布Grok 4.1 Fast模型，作为Grok 4系列的轻量化高性能版本，专为低延迟响应和实时交互优化，推理速度较标准版提升约40%。同时推出Agent Tools API，允许开发者构建基于Grok的AI代理，支持工具调用（如搜索、代码执行、数据库查询）、状态记忆与多步任务规划。API提供Python SDK与REST接口，支持与LangChain等框架集成。Grok 4.1 Fast适用于客服机器人、实时数据分析、自动化运维等场景，标志着xAI向企业级AI代理平台迈进。详情见官方新闻页（<a href=\"https://x.ai/news/grok-4-1-fast\">https://x.ai/news/grok-4-1-fast</a>）。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.ai/news/grok-4-1-fast\">https://x.ai/news/grok-4-1-fast</a></p>\n<hr />\n<h3 id=\"4-Meta发布SAM-3与SAM-3D模型\">4. 🚀 Meta发布SAM 3与SAM 3D模型</h3>\n<p><strong>标签：</strong> <code>Meta</code> <code>SAM 3</code> <code>SAM 3D</code></p>\n<p>Meta发布新一代Segment Anything Model 3（SAM 3），在图像分割精度、速度和泛化能力上实现显著提升，支持更高分辨率输入（达4K）与多模态提示（文本+图像）。同时推出SAM 3D，首个基于SAM架构的3D场景重建模型，可从多视角图像或点云数据中自动分割并重建3D物体，支持NeRF与Mesh输出。SAM 3D采用分层注意力机制，实现跨视角一致性分割，适用于AR/VR内容生成、自动驾驶感知、数字孪生等场景。模型已在GitHub开源，技术博客（<a href=\"https://ai.meta.com/blog/sam-3d/\">https://ai.meta.com/blog/sam-3d/</a>）提供详细架构说明。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://ai.meta.com/sam3/\">https://ai.meta.com/sam3/</a><br />\n- <a href=\"https://ai.meta.com/blog/sam-3d/\">https://ai.meta.com/blog/sam-3d/</a></p>\n<hr />\n<h3 id=\"5-微软发布Copilot-Agent-365控制平台\">5. 🚀 微软发布Copilot Agent 365控制平台</h3>\n<p><strong>标签：</strong> <code>微软</code> <code>Copilot Agent 365</code> <code>Control Plane</code></p>\n<p>微软发布Copilot Agent 365，作为AI代理的统一控制平面（Control Plane），用于管理、编排和监控企业内多个Copilot代理的运行。该平台支持代理生命周期管理、权限控制、任务调度、日志审计与性能监控，提供可视化仪表盘与API接口。Agent 365可集成Teams、Outlook、SharePoint等Microsoft 365服务，实现跨应用自动化流程，如会议纪要生成、邮件分类、文档审批等。其核心价值在于提升企业AI代理的可治理性与可扩展性，降低运维复杂度。发布信息详见微软官方博客（<a href=\"https://www.microsoft.com/en-us/microsoft-365/blog/2025/11/18/microsoft-agent-365-the-control-plane-for-ai-agents/\">https://www.microsoft.com/en-us/microsoft-365/blog/2025/11/18/microsoft-agent-365-the-control-plane-for-ai-agents/</a>）。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://www.microsoft.com/en-us/microsoft-365/blog/2025/11/18/microsoft-agent-365-the-control-plane-for-ai-agents/\">https://www.microsoft.com/en-us/microsoft-365/blog/2025/11/18/microsoft-agent-365-the-control-plane-for-ai-agents/</a></p>\n<hr />\n<h3 id=\"6-Anthropic延长Claude-Code免费额度\">6. 📈 Anthropic延长Claude Code免费额度</h3>\n<p><strong>标签：</strong> <code>Anthropic</code> <code>Claude Code</code> <code>免费额度</code></p>\n<p>Anthropic通过开发者Cat Wu（@_catwu）宣布，将Claude Code网页版免费使用额度有效期延长，具体延长时间未明确，但强调为支持开发者社区持续探索AI编程能力。Claude Code是Anthropic推出的AI编程助手，支持代码生成、解释、调试与文档撰写，集成于浏览器环境，无需本地部署。此次延长有助于降低开发者试用门槛，推动生态建设，尤其利好学生和初创团队。该举措也反映出AI编程工具市场竞争加剧，各厂商通过免费策略抢占用户。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/_catwu/status/1991280133014278273\">https://x.com/_catwu/status/1991280133014278273</a></p>\n<hr />\n<h3 id=\"7-Gemini-3上线移动端与Jules工具\">7. 🚀 Gemini 3上线移动端与Jules工具</h3>\n<p><strong>标签：</strong> <code>Gemini 3</code> <code>Jules</code> <code>移动端</code></p>\n<p>Gemini 3模型正式登陆移动端（iOS/Android），支持离线推理与低功耗模式，响应速度优化30%以上。同时推出Jules工具，专为开发者设计的命令行接口（CLI），支持本地代码分析、API调用与模型微调。Jules可与Gemini 3无缝集成，实现自动化代码审查、文档生成与测试用例编写。移动端支持语音输入、图像识别与多模态交互，适用于移动开发、现场运维、教育辅导等场景。发布信息由开发者Simpsoka（@simpsoka）在X平台披露。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/simpsoka/status/1991209318096716109\">https://x.com/simpsoka/status/1991209318096716109</a><br />\n- <a href=\"https://x.com/testingcatalog/status/1991126479220949293\">https://x.com/testingcatalog/status/1991126479220949293</a></p>\n<hr />\n<h3 id=\"8-Google-Gemini开放Photos导入功能\">8. 🔧 Google Gemini开放Photos导入功能</h3>\n<p><strong>标签：</strong> <code>Google Gemini</code> <code>Photos导入</code> <code>多模态分析</code></p>\n<p>Google Gemini网页版新增Photos导入功能，用户可直接从Google Photos中选择图像上传至Gemini进行多模态分析。该功能支持批量上传（最多10张）、自动元数据读取（如拍摄时间、地点）与上下文关联分析，适用于图像内容识别、场景描述、OCR提取等任务。Gemini可结合图像与文本提示生成结构化报告，如旅行日志、产品清单、教学材料。此举强化了Gemini在个人助理与内容创作领域的竞争力，提升用户体验。功能已通过TestingCatalog（@testingcatalog）在X平台验证。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/testingcatalog/status/1991126479220949293\">https://x.com/testingcatalog/status/1991126479220949293</a></p>\n<hr />\n<h3 id=\"9-Stitch推出一键导出AI-Studio功能\">9. 🔧 Stitch推出一键导出AI Studio功能</h3>\n<p><strong>标签：</strong> <code>Stitch</code> <code>AI Studio</code> <code>一键导出</code></p>\n<p>Stitch（Google旗下低代码平台）推出一键导出AI Studio功能，用户可将Stitch中构建的AI应用（如聊天机器人、表单助手）直接导出为AI Studio项目，支持代码级自定义与部署。该功能支持导出为Python、Node.js项目，保留原有逻辑、数据源与UI组件，便于开发者进行二次开发与集成。AI Studio为Google的AI开发环境，支持模型训练、部署与监控。此举降低了低代码与专业开发之间的壁垒，提升开发效率。发布信息由Stitch官方账号（@stitchbygoogle）在X平台公布。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/stitchbygoogle/status/1991232172678869093\">https://x.com/stitchbygoogle/status/1991232172678869093</a></p>\n<hr />\n<h3 id=\"10-OpenAI发布ChatGPT-for-Teachers\">10. 🚀 OpenAI发布ChatGPT for Teachers</h3>\n<p><strong>标签：</strong> <code>OpenAI</code> <code>ChatGPT for Teachers</code> <code>教育AI</code></p>\n<p>OpenAI发布ChatGPT for Teachers，专为教育工作者设计的AI助手，集成于教育版ChatGPT中。该版本提供课程计划生成、作业批改、学生反馈撰写、个性化学习建议等功能，支持多语言教学场景。系统内置教育伦理审查机制，避免生成不当内容，并符合FERPA等数据隐私标准。教师可通过自然语言指令快速生成教学材料，如PPT大纲、测验题、阅读材料。该工具有望提升教学效率，推动AI在教育领域的普惠应用。详情见官方页面（<a href=\"https://openai.com/index/chatgpt-for-teachers/\">https://openai.com/index/chatgpt-for-teachers/</a>）。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://openai.com/index/gpt-5-1-codex-max/\">https://openai.com/index/gpt-5-1-codex-max/</a><br />\n- <a href=\"https://x.com/OpenAI/status/1991266192905179613\">https://x.com/OpenAI/status/1991266192905179613</a><br />\n- <a href=\"https://openai.com/index/chatgpt-for-teachers/\">https://openai.com/index/chatgpt-for-teachers/</a></p>\n<hr />\n<h3 id=\"11-Perplexity-ProMax新增文档构建功能\">11. 🔧 Perplexity Pro/Max新增文档构建功能</h3>\n<p><strong>标签：</strong> <code>Perplexity</code> <code>Pro/Max</code> <code>文档构建</code></p>\n<p>Perplexity AI宣布其Pro与Max订阅用户新增文档构建与编辑功能，支持在对话中直接创建、修改和导出结构化文档（如报告、提案、论文）。用户可通过自然语言指令添加标题、段落、表格、图表，并实时预览排版效果。系统支持Markdown与PDF导出，集成AI写作建议与语法检查。该功能强化了Perplexity作为研究型AI助手的定位，适用于学术写作、市场分析、法律文书等场景。发布信息由官方账号（@perplexity_ai）在X平台公布。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/perplexity_ai/status/1991206262563041316\">https://x.com/perplexity_ai/status/1991206262563041316</a></p>\n<hr />\n<h3 id=\"12-Deep-Cogito发布Cogito-v21-671B模型\">12. 🚀 Deep Cogito发布Cogito v2.1 671B模型</h3>\n<p><strong>标签：</strong> <code>Deep Cogito</code> <code>Cogito v2.1</code> <code>671B模型</code></p>\n<p>Deep Cogito发布Cogito v2.1，参数规模达671B，为当前开源领域最大规模的推理专用模型之一。该模型在数学推理、逻辑推理与代码生成任务上表现优异，支持复杂指令遵循与多步推理。采用混合专家（MoE）架构，激活参数约120B，兼顾性能与效率。模型已在Hugging Face开源（<a href=\"https://huggingface.co/deepcogito/cogito-671b-v2.1\">https://huggingface.co/deepcogito/cogito-671b-v2.1</a>），并提供技术报告（<a href=\"https://www.deepcogito.com/research/cogito-v2-1\">https://www.deepcogito.com/research/cogito-v2-1</a>）。适用于科研、金融建模、自动化决策等高推理需求场景。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://huggingface.co/deepcogito/cogito-671b-v2.1\">https://huggingface.co/deepcogito/cogito-671b-v2.1</a><br />\n- <a href=\"https://www.deepcogito.com/research/cogito-v2-1\">https://www.deepcogito.com/research/cogito-v2-1</a></p>\n<hr />\n<h3 id=\"13-ZeroEntropy发布zerank-2重排序模型\">13. 🚀 ZeroEntropy发布zerank-2重排序模型</h3>\n<p><strong>标签：</strong> <code>ZeroEntropy</code> <code>zerank-2</code> <code>重排序模型</code></p>\n<p>ZeroEntropy发布zerank-2，一款先进的指令遵循多模态重排序模型，支持文本、图像、音频输入，输出相关性排序与置信度评分。该模型在MS MARCO、TREC等基准测试中表现领先，支持细粒度指令解析（如'找红色圆形物体'），适用于搜索引擎、推荐系统、AI助手等场景。模型已在Hugging Face开源（https://huggingface.co/zeroentropy/zerank-2），并提供技术文章（<a href=\"https://www.zeroentropy.dev/articles/zerank-2-advanced-instruction-following-multimodal-reranker\">https://www.zeroentropy.dev/articles/zerank-2-advanced-instruction-following-multimodal-reranker</a>）。其多模态能力为下一代信息检索系统提供新范式。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://huggingface.co/zeroentropy/zerank-2\">https://huggingface.co/zeroentropy/zerank-2</a><br />\n- <a href=\"https://www.zeroentropy.dev/articles/zerank-2-advanced-instruction-following-multimodal-reranker\">https://www.zeroentropy.dev/articles/zerank-2-advanced-instruction-following-multimodal-reranker</a></p>\n<hr />\n<h3 id=\"14-Inclusion-AI发布Awex-RL权重同步框架\">14. 🔧 Inclusion AI发布Awex RL权重同步框架</h3>\n<p><strong>标签：</strong> <code>Inclusion AI</code> <code>Awex</code> <code>RL权重同步</code></p>\n<p>Inclusion AI发布Awex，一款高性能强化学习（RL）权重同步框架，专为分布式训练设计。Awex采用异步梯度聚合与压缩通信机制，支持跨节点、跨GPU的实时权重同步，延迟低于10ms，带宽占用减少60%。框架支持PyTorch与JAX，集成于asystem-awex开源项目（<a href=\"https://github.com/inclusionAI/asystem-awex\">https://github.com/inclusionAI/asystem-awex</a>），适用于大规模RL训练、多智能体系统、边缘计算等场景。其高效同步机制可显著提升训练速度与资源利用率。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://github.com/inclusionAI/asystem-awex\">https://github.com/inclusionAI/asystem-awex</a></p>\n<hr />\n<h3 id=\"15-RadixArk发布Miles-RL框架\">15. 🚀 RadixArk发布Miles RL框架</h3>\n<p><strong>标签：</strong> <code>RadixArk</code> <code>Miles</code> <code>RL框架</code></p>\n<p>RadixArk发布Miles，一款轻量级强化学习（RL）框架，专为快速原型设计与实验验证优化。Miles支持模块化组件（环境、策略、奖励函数）、内置基准测试套件（如Atari、MuJoCo）与可视化工具，提供Python API与命令行接口。框架强调易用性与可扩展性，适用于学术研究、教学演示与小型项目。技术细节发表于LMSYS博客（<a href=\"https://lmsys.org/blog/2025-11-19-miles/\">https://lmsys.org/blog/2025-11-19-miles/</a>），已在GitHub开源。Miles有望降低RL开发门槛，推动算法创新。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://lmsys.org/blog/2025-11-19-miles/\">https://lmsys.org/blog/2025-11-19-miles/</a></p>\n<hr />\n<h3 id=\"16-OpenAI发布企业AI评估框架指南\">16. 📈 OpenAI发布企业AI评估框架指南</h3>\n<p><strong>标签：</strong> <code>OpenAI</code> <code>AI评估框架</code> <code>Evals</code></p>\n<p>OpenAI发布《企业AI评估框架指南》，系统阐述如何构建AI模型评估体系（Evals），涵盖指标设计、测试集构建、自动化评估与持续监控。指南提出分层评估模型：基础能力（如准确率）、业务价值（如转化率）、伦理合规（如偏见检测）。支持自定义评估器与集成CI/CD流程，适用于金融、医疗、制造等行业。该框架旨在帮助企业科学评估AI系统性能，降低部署风险。详情见官方页面（https://openai.com/index/evals-drive-next-chapter-of-ai/）。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://openai.com/index/gpt-5-1-codex-max/\">https://openai.com/index/gpt-5-1-codex-max/</a><br />\n- <a href=\"https://x.com/OpenAI/status/1991266192905179613\">https://x.com/OpenAI/status/1991266192905179613</a><br />\n- <a href=\"https://openai.com/index/chatgpt-for-teachers/\">https://openai.com/index/chatgpt-for-teachers/</a></p>\n<hr />\n<h3 id=\"17-DeepSeek开源LPLB-MoE负载均衡器\">17. 🔧 DeepSeek开源LPLB MoE负载均衡器</h3>\n<p><strong>标签：</strong> <code>DeepSeek</code> <code>LPLB</code> <code>MoE负载均衡</code></p>\n<p>DeepSeek开源LPLB（Linear Programming Load Balancer），一款基于线性规划的MoE（混合专家）并行负载均衡器。LPLB通过数学优化模型动态分配专家计算任务，最小化通信开销与计算延迟，支持大规模分布式训练。实验表明，在1024 GPU集群上，负载均衡效率提升25%，训练吞吐量提高18%。代码已在GitHub开源（<a href=\"https://github.com/deepseek-ai/LPLB\">https://github.com/deepseek-ai/LPLB</a>），适用于大模型训练、多任务学习等场景。该技术为MoE架构的高效训练提供新解决方案。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://github.com/deepseek-ai/LPLB\">https://github.com/deepseek-ai/LPLB</a></p>\n<hr />\n<h3 id=\"18-VARC框架用ViT解决ARC视觉推理\">18. 🔧 VARC框架用ViT解决ARC视觉推理</h3>\n<p><strong>标签：</strong> <code>VARC框架</code> <code>ViT</code> <code>ARC</code></p>\n<p>研究提出VARC（Vision-Augmented Reasoning Chain）框架，首次成功利用Vision Transformer（ViT）解决Abstraction and Reasoning Corpus（ARC）视觉推理任务。VARC将图像输入ViT提取特征，结合符号推理模块生成逻辑链条，支持零样本迁移。在ARC基准测试中，VARC在未见任务上准确率达68.3%，显著优于传统CNN方法。该框架为通用人工智能（AGI）研究提供新路径，推动视觉-符号融合推理发展。研究细节未完全公开，但已在社区引发关注。</p>\n<hr />\n<hr />\n<h2 id=\"_2\">🎬 视频链接</h2>\n<p><strong>Bilibili：</strong> <a href=\"https://www.bilibili.com/video/BV1PSCZB7EST\">https://www.bilibili.com/video/BV1PSCZB7EST</a></p>\n<hr />\n<p><em>整理自橘鸦AI早报 | BV号：BV1PSCZB7EST | 2025-11-20 16:58:11</em></p>",
      "date": "2025-11-20",
      "filename": "2025-11-20_AI早报_BV1PSCZB7EST.md"
    },
    {
      "title": "xAI 发布 Grok 4.1 模型【AI 早报 2025-11-18】",
      "publish_date": "2025-11-18",
      "bv_id": "BV1jjCkB9ELZ",
      "organize_time": "2025-11-22 08:50:28",
      "news_count": 16,
      "overview": "1. 🚀 Grok 4.1大模型正式发布\n2. 🔧 Google Gemini 3 Pro灰度推送\n3. 🚀 Google DeepMind发布WeatherNext 2天气模型\n4. 🔧 Google Vids AI功能免费开放\n5. 🚀 Google推出AI旅行规划与预订功能\n6. 📈 Artificial Analysis发布AA-Omniscience基准\n7. 📈 LongCat发布AMO-Bench数学推理基准\n8. 🚀 阿里发布千问应用公测版\n9. 📈 阿里Qwen Chat用户突破千万\n10. 🔧 Google计划推出AI Studio移动应用\n11. 🔧 Google拟为Gemini Enterprise引入Agent导入\n12. 🔧 Poe上线200人群聊功能\n13. 🚀 Cerebras发布REAP剪枝MiniMax-M2模型\n14. 📈 Google推出三项Gemini教育认证\n15. 📈 Replicate加入Cloudflare\n16. 📈 Jeff Bezos回归担任Project Prometheus联合CEO",
      "content": "# xAI 发布 Grok 4.1 模型【AI 早报 2025-11-18】\n\n**📅 发布日期：** 2025-11-18\n**🎬 BV号：** BV1jjCkB9ELZ\n**📝 整理时间：** 2025-11-22 08:50:28\n**📊 资讯数量：** 16 条\n\n---\n\n## 📋 本期概览\n\n1. 🚀 Grok 4.1大模型正式发布\n2. 🔧 Google Gemini 3 Pro灰度推送\n3. 🚀 Google DeepMind发布WeatherNext 2天气模型\n4. 🔧 Google Vids AI功能免费开放\n5. 🚀 Google推出AI旅行规划与预订功能\n6. 📈 Artificial Analysis发布AA-Omniscience基准\n7. 📈 LongCat发布AMO-Bench数学推理基准\n8. 🚀 阿里发布千问应用公测版\n9. 📈 阿里Qwen Chat用户突破千万\n10. 🔧 Google计划推出AI Studio移动应用\n11. 🔧 Google拟为Gemini Enterprise引入Agent导入\n12. 🔧 Poe上线200人群聊功能\n13. 🚀 Cerebras发布REAP剪枝MiniMax-M2模型\n14. 📈 Google推出三项Gemini教育认证\n15. 📈 Replicate加入Cloudflare\n16. 📈 Jeff Bezos回归担任Project Prometheus联合CEO\n\n---\n\n### 1. 🚀 Grok 4.1大模型正式发布 {#1-Grok-41大模型正式发布}\n\n**标签：** `xAI` `Grok 4.1`\n\nxAI于2025年11月17日正式发布Grok 4.1大模型，该版本在推理能力、多轮对话和上下文理解方面进行了显著优化。根据官方发布的模型卡（Model Card），Grok 4.1在数学推理、代码生成和长文本处理任务中表现优于前代版本，支持高达128K的上下文窗口，并采用稀疏混合专家架构（MoE）以提升推理效率。该模型已在xAI平台全面上线，供开发者和企业用户调用。此次更新标志着xAI在开源与闭源模型生态中进一步巩固技术竞争力，尤其在实时信息处理和复杂任务分解方面具备潜在应用价值，如金融分析、科研辅助和自动化客服系统。\n\n**🔗 相关链接：**\n- <https://x.ai/news/grok-4-1>\n- <https://data.x.ai/2025-11-17-grok-4-1-model-card.pdf>\n\n---\n\n### 2. 🔧 Google Gemini 3 Pro灰度推送 {#2-Google-Gemini-3-Pro灰度推送}\n\n**标签：** `Google` `Gemini 3 Pro` `AI Studio`\n\nGoogle正在向部分用户灰度推送Gemini 3 Pro大模型，并已上线AI Studio平台供开发者测试。该版本为Gemini 3系列中的高性能变体，据社区用户反馈，其在多模态理解、逻辑推理和长文本生成方面较Gemini 2.5 Pro有明显提升。Gemini 3 Pro支持图像、音频、视频和文本的联合输入，具备更强的跨模态语义对齐能力。目前该模型尚未全面开放，但已在AI Studio中提供API访问入口，开发者可通过Google Cloud平台申请使用。此举表明Google正加速推进其下一代大模型在消费级和企业级场景的落地，为后续集成至Workspace、Search和Android生态做准备。\n\n**🔗 相关链接：**\n- <https://linux.do/t/topic/1181404>\n- <https://x.com/scaling01/status/1990504865408430178>\n- <https://blog.google/technology/google-deepmind/weathernext-2/>\n\n---\n\n### 3. 🚀 Google DeepMind发布WeatherNext 2天气模型 {#3-Google-DeepMind发布WeatherNext-2}\n\n**标签：** `Google DeepMind` `WeatherNext 2`\n\nGoogle DeepMind发布新一代天气预测模型WeatherNext 2，该模型基于深度学习架构，能够在10公里分辨率下实现全球范围的高精度天气预报，预测时间跨度达10天。WeatherNext 2采用物理信息神经网络（PINN）与Transformer结合的设计，显著提升了对极端天气事件（如台风、暴雨）的预测准确率。据官方博客介绍，该模型在多个国际气象基准测试中超越传统数值天气预报（NWP）系统，推理速度提升3倍，能耗降低40%。WeatherNext 2将首先集成至Google Earth和Google Search的天气服务中，未来有望用于农业、物流和灾害预警系统。\n\n**🔗 相关链接：**\n- <https://linux.do/t/topic/1181404>\n- <https://x.com/scaling01/status/1990504865408430178>\n- <https://blog.google/technology/google-deepmind/weathernext-2/>\n\n---\n\n### 4. 🔧 Google Vids AI功能免费开放 {#4-Google-Vids-AI功能免费开放}\n\n**标签：** `Google` `Vids` `Workspace`\n\nGoogle宣布扩展其视频创作工具Vids的AI功能，并面向所有Workspace用户免费开放。新功能包括AI脚本生成、智能剪辑建议、自动字幕生成和AI配音，支持多语言内容创作。用户可通过自然语言指令生成视频草稿，系统自动匹配素材、调整节奏并添加转场效果。此次免费访问标志着Google将AI视频生成能力从付费订阅模式转向普惠化策略，旨在提升Workspace生态的用户粘性，并推动AI在内容营销、教育培训和远程协作中的应用。Vids现已集成至Google Drive和Meet，支持团队协作编辑。\n\n**🔗 相关链接：**\n- <https://linux.do/t/topic/1181404>\n- <https://x.com/scaling01/status/1990504865408430178>\n- <https://blog.google/technology/google-deepmind/weathernext-2/>\n\n---\n\n### 5. 🚀 Google推出AI旅行规划与预订功能 {#5-Google推出AI旅行规划与预订功能}\n\n**标签：** `Google` `Gemini` `Canvas AI Mode`\n\nGoogle在Search和Maps中推出基于AI的旅行规划与预订新功能，集成于‘Canvas AI Mode’中。用户可通过自然语言输入旅行需求（如‘下个月去东京，预算5000元，带小孩’），系统将自动生成行程建议，并直接链接至航班、酒店和景点预订页面。该功能利用Gemini大模型进行意图理解与多源信息整合，支持实时价格比较和个性化推荐。AI还能根据用户反馈动态调整行程，实现‘代理式’（agentic）交互体验。该功能已在部分国家灰度上线，未来将扩展至更多地区，有望重塑在线旅游服务模式。\n\n**🔗 相关链接：**\n- <https://linux.do/t/topic/1181404>\n- <https://x.com/scaling01/status/1990504865408430178>\n- <https://blog.google/technology/google-deepmind/weathernext-2/>\n\n---\n\n### 6. 📈 Artificial Analysis发布AA-Omniscience基准 {#6-Artificial-Analysis发布AA-Omnisc}\n\n**标签：** `Artificial Analysis` `AA-Omniscience`\n\nAI评测机构Artificial Analysis发布全新大模型综合能力基准测试AA-Omniscience，涵盖知识广度、推理深度、多模态理解、代码生成和伦理对齐五大维度。该基准包含超过2000个定制化任务，采用动态难度调整和对抗性测试机制，旨在更真实地反映模型在复杂现实场景中的表现。AA-Omniscience支持跨模型横向对比，并提供细粒度评分报告，已被多家主流AI实验室采纳为内部评估标准。该基准的发布将推动大模型评测从单一任务向系统性、多维度的方向发展，提升行业透明度。\n\n**🔗 相关链接：**\n- <https://x.com/ArtificialAnlys/status/1990455484844003821>\n\n---\n\n### 7. 📈 LongCat发布AMO-Bench数学推理基准 {#7-LongCat发布AMO-Bench数学推理基准}\n\n**标签：** `LongCat` `AMO-Bench`\n\nLongCat团队发布数学推理专用评测基准AMO-Bench，专注于评估大模型在抽象数学、逻辑推理和复杂问题求解方面的能力。该基准包含代数、几何、数论和组合数学等子任务，采用多步推理评分机制，强调解题过程的逻辑完整性而非仅答案正确性。AMO-Bench支持中英文双语输入，并引入人工验证环节以确保数据质量。该基准已开源，供研究社区免费使用，旨在推动数学AI（Math AI）领域的技术进步，为教育、科研和自动化推理系统提供评估工具。\n\n**🔗 相关链接：**\n- <https://amo-bench.github.io/>\n\n---\n\n### 8. 🚀 阿里发布千问应用公测版 {#8-阿里发布千问应用公测版}\n\n**标签：** `阿里巴巴` `千问` `Qwen`\n\n阿里巴巴正式推出其大模型应用‘千问’的公测版本，面向C端用户提供AI对话、内容生成和知识问答服务。该应用基于Qwen系列大模型，支持文本、语音和图像输入，具备多轮对话、文档解析和代码生成能力。千问App提供免费版与会员订阅制，会员可访问更高性能模型版本。此次公测标志着阿里加速布局消费级AI市场，与百度文心一言、腾讯元宝等展开直接竞争。应用已上架iOS和Android平台，初期重点推广教育、办公和创意内容生成场景。\n\n**🔗 相关链接：**\n- <https://www.alizila.com/alibaba-launches-qwen-app-to-boost-its-consumer-ai-efforts/>\n- <https://x.com/Alibaba_Qwen/status/1990322403994657091>\n\n---\n\n### 9. 📈 阿里Qwen Chat用户突破千万 {#9-阿里Qwen-Chat用户突破千万}\n\n**标签：** `阿里巴巴` `Qwen Chat`\n\n阿里巴巴宣布其大模型对话平台Qwen Chat累计用户数已突破1000万，成为全球用户增长最快的中文大模型之一。Qwen Chat支持多语言交互，提供API、SDK和Web端访问方式，广泛应用于企业客服、内容创作和智能助手场景。用户增长主要来自教育、电商和开发者社区。阿里表示，Qwen系列模型将持续迭代，未来将加强多模态能力和行业垂直优化，进一步拓展在金融、医疗和政务领域的应用。\n\n**🔗 相关链接：**\n- <https://www.alizila.com/alibaba-launches-qwen-app-to-boost-its-consumer-ai-efforts/>\n- <https://x.com/Alibaba_Qwen/status/1990322403994657091>\n\n---\n\n### 10. 🔧 Google计划推出AI Studio移动应用 {#10-Google计划推出AI-Studio移动应用}\n\n**标签：** `Google` `AI Studio`\n\n据开发者社区消息，Google正在开发AI Studio的移动应用程序，预计将支持iOS和Android平台。该应用将允许开发者在移动端创建、测试和部署基于Gemini的大模型应用，支持API调用、提示工程（prompt engineering）和模型微调。移动版AI Studio将集成代码编辑器、调试工具和性能监控面板，提升开发效率。此举将降低AI开发门槛，推动大模型在移动端的普及，尤其利好初创团队和独立开发者。\n\n**🔗 相关链接：**\n- <https://linux.do/t/topic/1181404>\n- <https://x.com/scaling01/status/1990504865408430178>\n- <https://blog.google/technology/google-deepmind/weathernext-2/>\n\n---\n\n### 11. 🔧 Google拟为Gemini Enterprise引入Agent导入 {#11-Google拟为Gemini-Enterprise引入Age}\n\n**标签：** `Google` `Gemini Enterprise`\n\nGoogle计划在其Gemini Enterprise平台中引入‘Agent导入’功能，允许企业用户将自定义AI代理（Agent）集成至Gemini生态中。该功能将支持第三方Agent通过标准API接入，实现与Gemini大模型的协同工作，如数据检索、任务调度和用户交互。此举旨在构建企业级AI代理网络，提升自动化流程的灵活性和可扩展性，适用于客服、IT运维和供应链管理场景。该功能预计将在2026年初上线，进一步巩固Google在企业AI市场的地位。\n\n**🔗 相关链接：**\n- <https://linux.do/t/topic/1181404>\n- <https://x.com/scaling01/status/1990504865408430178>\n- <https://blog.google/technology/google-deepmind/weathernext-2/>\n\n---\n\n### 12. 🔧 Poe上线200人群聊功能 {#12-Poe上线200人群聊功能}\n\n**标签：** `Poe`\n\nAI聊天平台Poe宣布上线200人规模的群聊功能，支持多用户同时与AI模型进行交互。该功能允许用户创建主题群组，邀请他人参与讨论，AI将根据上下文生成个性化回复。Poe采用分布式架构以支持高并发，确保在大规模群聊中保持低延迟。此功能拓展了Poe在团队协作、在线教育和社区运营中的应用场景，标志着AI社交平台向大规模实时交互迈进。\n\n**🔗 相关链接：**\n- <https://x.com/testingcatalog/status/1990566844650975721>\n\n---\n\n### 13. 🚀 Cerebras发布REAP剪枝MiniMax-M2模型 {#13-Cerebras发布REAP剪枝MiniMax-M2模型}\n\n**标签：** `Cerebras` `MiniMax-M2` `REAP`\n\nCerebras发布三款基于REAP（Retained Expert Activation Pruning）剪枝技术的MiniMax-M2系列模型：MiniMax-M2-REAP-139B-A10B、MiniMax-M2-REAP-172B-A10B和MiniMax-M2-REAP-162B-A10B。这些模型通过结构化剪枝保留关键专家参数，在保持性能的同时显著降低计算资源需求。其中139B版本在推理效率上提升40%，适合部署于边缘设备。该系列模型已在Hugging Face开源，支持商业使用，适用于需要高性能与低延迟的AI应用，如实时翻译、语音识别和自动驾驶。\n\n**🔗 相关链接：**\n- <https://huggingface.co/cerebras/MiniMax-M2-REAP-139B-A10B>\n- <https://huggingface.co/cerebras/MiniMax-M2-REAP-172B-A10B>\n- <https://huggingface.co/cerebras/MiniMax-M2-REAP-162B-A10B>\n\n---\n\n### 14. 📈 Google推出三项Gemini教育认证 {#14-Google推出三项Gemini教育认证}\n\n**标签：** `Google` `Gemini` `教育认证`\n\nGoogle宣布推出三项基于Gemini大模型的教育认证：Gemini for Education Specialist、AI Teaching Assistant和AI Curriculum Designer。认证课程涵盖AI基础知识、Gemini API使用、AI辅助教学设计和伦理规范。通过者将获得Google官方认证证书，并有机会参与Google教育生态项目。该认证体系旨在提升教师和教育工作者的AI素养，推动AI技术在K-12和高等教育中的落地，预计2026年覆盖全球10万名教育工作者。\n\n**🔗 相关链接：**\n- <https://linux.do/t/topic/1181404>\n- <https://x.com/scaling01/status/1990504865408430178>\n- <https://blog.google/technology/google-deepmind/weathernext-2/>\n\n---\n\n### 15. 📈 Replicate加入Cloudflare {#15-Replicate加入Cloudflare}\n\n**标签：** `Replicate` `Cloudflare`\n\nAI模型部署平台Replicate宣布正式加入Cloudflare，成为其AI生态的一部分。Replicate将利用Cloudflare的全球边缘网络，提升模型推理的响应速度和安全性。双方将共同开发基于Cloudflare Workers的轻量级AI部署方案，支持一键部署开源模型。此次合作将降低AI应用的部署门槛，尤其利好中小型开发者和初创公司。Replicate团队将并入Cloudflare AI部门，继续维护现有平台并开发新功能。\n\n**🔗 相关链接：**\n- <https://replicate.com/blog/replicate-cloudflare>\n- <https://blog.cloudflare.com/replicate-joins-cloudflare/>\n\n---\n\n### 16. 📈 Jeff Bezos回归担任Project Prometheus联合CEO {#16-Jeff-Bezos回归担任Project-Promethe}\n\n**标签：** `Jeff Bezos` `Project Prometheus` `Blue Origin`\n\n据《纽约时报》报道，Jeff Bezos已回归并出任Project Prometheus的联合CEO。该项目为Bezos旗下Blue Origin与多家科技公司合作的AI与航天融合项目，聚焦于开发用于深空探测的自主AI系统。Bezos将主导AI架构设计与战略方向，推动大模型在航天任务规划、遥测分析和机器人控制中的应用。此举被视为Bezos在AI时代重新布局科技前沿的重要举措，Project Prometheus预计将在2027年前完成首次AI驱动的月球探测任务。\n\n**🔗 相关链接：**\n- <https://www.nytimes.com/2025/11/17/technology/bezos-project-prometheus.html?partner=slack&smid=sl-share>\n\n---\n\n---\n\n## 🎬 视频链接\n\n**Bilibili**： <https://www.bilibili.com/video/BV1jjCkB9ELZ>\n\n---\n\n*整理自橘鸦AI早报 | BV号：BV1jjCkB9ELZ | 2025-11-22 08:50:28*",
      "html_content": "<h1 id=\"xai-grok-41-ai-2025-11-18\">xAI 发布 Grok 4.1 模型【AI 早报 2025-11-18】</h1>\n<p><strong>📅 发布日期：</strong> 2025-11-18<br />\n<strong>🎬 BV号：</strong> BV1jjCkB9ELZ<br />\n<strong>📝 整理时间：</strong> 2025-11-22 08:50:28<br />\n<strong>📊 资讯数量：</strong> 16 条</p>\n<hr />\n<h2 id=\"_1\">📋 本期概览</h2>\n<ol>\n<li>🚀 Grok 4.1大模型正式发布</li>\n<li>🔧 Google Gemini 3 Pro灰度推送</li>\n<li>🚀 Google DeepMind发布WeatherNext 2天气模型</li>\n<li>🔧 Google Vids AI功能免费开放</li>\n<li>🚀 Google推出AI旅行规划与预订功能</li>\n<li>📈 Artificial Analysis发布AA-Omniscience基准</li>\n<li>📈 LongCat发布AMO-Bench数学推理基准</li>\n<li>🚀 阿里发布千问应用公测版</li>\n<li>📈 阿里Qwen Chat用户突破千万</li>\n<li>🔧 Google计划推出AI Studio移动应用</li>\n<li>🔧 Google拟为Gemini Enterprise引入Agent导入</li>\n<li>🔧 Poe上线200人群聊功能</li>\n<li>🚀 Cerebras发布REAP剪枝MiniMax-M2模型</li>\n<li>📈 Google推出三项Gemini教育认证</li>\n<li>📈 Replicate加入Cloudflare</li>\n<li>📈 Jeff Bezos回归担任Project Prometheus联合CEO</li>\n</ol>\n<hr />\n<h3 id=\"1-Grok-41大模型正式发布\">1. 🚀 Grok 4.1大模型正式发布</h3>\n<p><strong>标签：</strong> <code>xAI</code> <code>Grok 4.1</code></p>\n<p>xAI于2025年11月17日正式发布Grok 4.1大模型，该版本在推理能力、多轮对话和上下文理解方面进行了显著优化。根据官方发布的模型卡（Model Card），Grok 4.1在数学推理、代码生成和长文本处理任务中表现优于前代版本，支持高达128K的上下文窗口，并采用稀疏混合专家架构（MoE）以提升推理效率。该模型已在xAI平台全面上线，供开发者和企业用户调用。此次更新标志着xAI在开源与闭源模型生态中进一步巩固技术竞争力，尤其在实时信息处理和复杂任务分解方面具备潜在应用价值，如金融分析、科研辅助和自动化客服系统。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.ai/news/grok-4-1\">https://x.ai/news/grok-4-1</a><br />\n- <a href=\"https://data.x.ai/2025-11-17-grok-4-1-model-card.pdf\">https://data.x.ai/2025-11-17-grok-4-1-model-card.pdf</a></p>\n<hr />\n<h3 id=\"2-Google-Gemini-3-Pro灰度推送\">2. 🔧 Google Gemini 3 Pro灰度推送</h3>\n<p><strong>标签：</strong> <code>Google</code> <code>Gemini 3 Pro</code> <code>AI Studio</code></p>\n<p>Google正在向部分用户灰度推送Gemini 3 Pro大模型，并已上线AI Studio平台供开发者测试。该版本为Gemini 3系列中的高性能变体，据社区用户反馈，其在多模态理解、逻辑推理和长文本生成方面较Gemini 2.5 Pro有明显提升。Gemini 3 Pro支持图像、音频、视频和文本的联合输入，具备更强的跨模态语义对齐能力。目前该模型尚未全面开放，但已在AI Studio中提供API访问入口，开发者可通过Google Cloud平台申请使用。此举表明Google正加速推进其下一代大模型在消费级和企业级场景的落地，为后续集成至Workspace、Search和Android生态做准备。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://linux.do/t/topic/1181404\">https://linux.do/t/topic/1181404</a><br />\n- <a href=\"https://x.com/scaling01/status/1990504865408430178\">https://x.com/scaling01/status/1990504865408430178</a><br />\n- <a href=\"https://blog.google/technology/google-deepmind/weathernext-2/\">https://blog.google/technology/google-deepmind/weathernext-2/</a></p>\n<hr />\n<h3 id=\"3-Google-DeepMind发布WeatherNext-2\">3. 🚀 Google DeepMind发布WeatherNext 2天气模型</h3>\n<p><strong>标签：</strong> <code>Google DeepMind</code> <code>WeatherNext 2</code></p>\n<p>Google DeepMind发布新一代天气预测模型WeatherNext 2，该模型基于深度学习架构，能够在10公里分辨率下实现全球范围的高精度天气预报，预测时间跨度达10天。WeatherNext 2采用物理信息神经网络（PINN）与Transformer结合的设计，显著提升了对极端天气事件（如台风、暴雨）的预测准确率。据官方博客介绍，该模型在多个国际气象基准测试中超越传统数值天气预报（NWP）系统，推理速度提升3倍，能耗降低40%。WeatherNext 2将首先集成至Google Earth和Google Search的天气服务中，未来有望用于农业、物流和灾害预警系统。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://linux.do/t/topic/1181404\">https://linux.do/t/topic/1181404</a><br />\n- <a href=\"https://x.com/scaling01/status/1990504865408430178\">https://x.com/scaling01/status/1990504865408430178</a><br />\n- <a href=\"https://blog.google/technology/google-deepmind/weathernext-2/\">https://blog.google/technology/google-deepmind/weathernext-2/</a></p>\n<hr />\n<h3 id=\"4-Google-Vids-AI功能免费开放\">4. 🔧 Google Vids AI功能免费开放</h3>\n<p><strong>标签：</strong> <code>Google</code> <code>Vids</code> <code>Workspace</code></p>\n<p>Google宣布扩展其视频创作工具Vids的AI功能，并面向所有Workspace用户免费开放。新功能包括AI脚本生成、智能剪辑建议、自动字幕生成和AI配音，支持多语言内容创作。用户可通过自然语言指令生成视频草稿，系统自动匹配素材、调整节奏并添加转场效果。此次免费访问标志着Google将AI视频生成能力从付费订阅模式转向普惠化策略，旨在提升Workspace生态的用户粘性，并推动AI在内容营销、教育培训和远程协作中的应用。Vids现已集成至Google Drive和Meet，支持团队协作编辑。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://linux.do/t/topic/1181404\">https://linux.do/t/topic/1181404</a><br />\n- <a href=\"https://x.com/scaling01/status/1990504865408430178\">https://x.com/scaling01/status/1990504865408430178</a><br />\n- <a href=\"https://blog.google/technology/google-deepmind/weathernext-2/\">https://blog.google/technology/google-deepmind/weathernext-2/</a></p>\n<hr />\n<h3 id=\"5-Google推出AI旅行规划与预订功能\">5. 🚀 Google推出AI旅行规划与预订功能</h3>\n<p><strong>标签：</strong> <code>Google</code> <code>Gemini</code> <code>Canvas AI Mode</code></p>\n<p>Google在Search和Maps中推出基于AI的旅行规划与预订新功能，集成于‘Canvas AI Mode’中。用户可通过自然语言输入旅行需求（如‘下个月去东京，预算5000元，带小孩’），系统将自动生成行程建议，并直接链接至航班、酒店和景点预订页面。该功能利用Gemini大模型进行意图理解与多源信息整合，支持实时价格比较和个性化推荐。AI还能根据用户反馈动态调整行程，实现‘代理式’（agentic）交互体验。该功能已在部分国家灰度上线，未来将扩展至更多地区，有望重塑在线旅游服务模式。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://linux.do/t/topic/1181404\">https://linux.do/t/topic/1181404</a><br />\n- <a href=\"https://x.com/scaling01/status/1990504865408430178\">https://x.com/scaling01/status/1990504865408430178</a><br />\n- <a href=\"https://blog.google/technology/google-deepmind/weathernext-2/\">https://blog.google/technology/google-deepmind/weathernext-2/</a></p>\n<hr />\n<h3 id=\"6-Artificial-Analysis发布AA-Omnisc\">6. 📈 Artificial Analysis发布AA-Omniscience基准</h3>\n<p><strong>标签：</strong> <code>Artificial Analysis</code> <code>AA-Omniscience</code></p>\n<p>AI评测机构Artificial Analysis发布全新大模型综合能力基准测试AA-Omniscience，涵盖知识广度、推理深度、多模态理解、代码生成和伦理对齐五大维度。该基准包含超过2000个定制化任务，采用动态难度调整和对抗性测试机制，旨在更真实地反映模型在复杂现实场景中的表现。AA-Omniscience支持跨模型横向对比，并提供细粒度评分报告，已被多家主流AI实验室采纳为内部评估标准。该基准的发布将推动大模型评测从单一任务向系统性、多维度的方向发展，提升行业透明度。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/ArtificialAnlys/status/1990455484844003821\">https://x.com/ArtificialAnlys/status/1990455484844003821</a></p>\n<hr />\n<h3 id=\"7-LongCat发布AMO-Bench数学推理基准\">7. 📈 LongCat发布AMO-Bench数学推理基准</h3>\n<p><strong>标签：</strong> <code>LongCat</code> <code>AMO-Bench</code></p>\n<p>LongCat团队发布数学推理专用评测基准AMO-Bench，专注于评估大模型在抽象数学、逻辑推理和复杂问题求解方面的能力。该基准包含代数、几何、数论和组合数学等子任务，采用多步推理评分机制，强调解题过程的逻辑完整性而非仅答案正确性。AMO-Bench支持中英文双语输入，并引入人工验证环节以确保数据质量。该基准已开源，供研究社区免费使用，旨在推动数学AI（Math AI）领域的技术进步，为教育、科研和自动化推理系统提供评估工具。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://amo-bench.github.io/\">https://amo-bench.github.io/</a></p>\n<hr />\n<h3 id=\"8-阿里发布千问应用公测版\">8. 🚀 阿里发布千问应用公测版</h3>\n<p><strong>标签：</strong> <code>阿里巴巴</code> <code>千问</code> <code>Qwen</code></p>\n<p>阿里巴巴正式推出其大模型应用‘千问’的公测版本，面向C端用户提供AI对话、内容生成和知识问答服务。该应用基于Qwen系列大模型，支持文本、语音和图像输入，具备多轮对话、文档解析和代码生成能力。千问App提供免费版与会员订阅制，会员可访问更高性能模型版本。此次公测标志着阿里加速布局消费级AI市场，与百度文心一言、腾讯元宝等展开直接竞争。应用已上架iOS和Android平台，初期重点推广教育、办公和创意内容生成场景。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://www.alizila.com/alibaba-launches-qwen-app-to-boost-its-consumer-ai-efforts/\">https://www.alizila.com/alibaba-launches-qwen-app-to-boost-its-consumer-ai-efforts/</a><br />\n- <a href=\"https://x.com/Alibaba_Qwen/status/1990322403994657091\">https://x.com/Alibaba_Qwen/status/1990322403994657091</a></p>\n<hr />\n<h3 id=\"9-阿里Qwen-Chat用户突破千万\">9. 📈 阿里Qwen Chat用户突破千万</h3>\n<p><strong>标签：</strong> <code>阿里巴巴</code> <code>Qwen Chat</code></p>\n<p>阿里巴巴宣布其大模型对话平台Qwen Chat累计用户数已突破1000万，成为全球用户增长最快的中文大模型之一。Qwen Chat支持多语言交互，提供API、SDK和Web端访问方式，广泛应用于企业客服、内容创作和智能助手场景。用户增长主要来自教育、电商和开发者社区。阿里表示，Qwen系列模型将持续迭代，未来将加强多模态能力和行业垂直优化，进一步拓展在金融、医疗和政务领域的应用。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://www.alizila.com/alibaba-launches-qwen-app-to-boost-its-consumer-ai-efforts/\">https://www.alizila.com/alibaba-launches-qwen-app-to-boost-its-consumer-ai-efforts/</a><br />\n- <a href=\"https://x.com/Alibaba_Qwen/status/1990322403994657091\">https://x.com/Alibaba_Qwen/status/1990322403994657091</a></p>\n<hr />\n<h3 id=\"10-Google计划推出AI-Studio移动应用\">10. 🔧 Google计划推出AI Studio移动应用</h3>\n<p><strong>标签：</strong> <code>Google</code> <code>AI Studio</code></p>\n<p>据开发者社区消息，Google正在开发AI Studio的移动应用程序，预计将支持iOS和Android平台。该应用将允许开发者在移动端创建、测试和部署基于Gemini的大模型应用，支持API调用、提示工程（prompt engineering）和模型微调。移动版AI Studio将集成代码编辑器、调试工具和性能监控面板，提升开发效率。此举将降低AI开发门槛，推动大模型在移动端的普及，尤其利好初创团队和独立开发者。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://linux.do/t/topic/1181404\">https://linux.do/t/topic/1181404</a><br />\n- <a href=\"https://x.com/scaling01/status/1990504865408430178\">https://x.com/scaling01/status/1990504865408430178</a><br />\n- <a href=\"https://blog.google/technology/google-deepmind/weathernext-2/\">https://blog.google/technology/google-deepmind/weathernext-2/</a></p>\n<hr />\n<h3 id=\"11-Google拟为Gemini-Enterprise引入Age\">11. 🔧 Google拟为Gemini Enterprise引入Agent导入</h3>\n<p><strong>标签：</strong> <code>Google</code> <code>Gemini Enterprise</code></p>\n<p>Google计划在其Gemini Enterprise平台中引入‘Agent导入’功能，允许企业用户将自定义AI代理（Agent）集成至Gemini生态中。该功能将支持第三方Agent通过标准API接入，实现与Gemini大模型的协同工作，如数据检索、任务调度和用户交互。此举旨在构建企业级AI代理网络，提升自动化流程的灵活性和可扩展性，适用于客服、IT运维和供应链管理场景。该功能预计将在2026年初上线，进一步巩固Google在企业AI市场的地位。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://linux.do/t/topic/1181404\">https://linux.do/t/topic/1181404</a><br />\n- <a href=\"https://x.com/scaling01/status/1990504865408430178\">https://x.com/scaling01/status/1990504865408430178</a><br />\n- <a href=\"https://blog.google/technology/google-deepmind/weathernext-2/\">https://blog.google/technology/google-deepmind/weathernext-2/</a></p>\n<hr />\n<h3 id=\"12-Poe上线200人群聊功能\">12. 🔧 Poe上线200人群聊功能</h3>\n<p><strong>标签：</strong> <code>Poe</code></p>\n<p>AI聊天平台Poe宣布上线200人规模的群聊功能，支持多用户同时与AI模型进行交互。该功能允许用户创建主题群组，邀请他人参与讨论，AI将根据上下文生成个性化回复。Poe采用分布式架构以支持高并发，确保在大规模群聊中保持低延迟。此功能拓展了Poe在团队协作、在线教育和社区运营中的应用场景，标志着AI社交平台向大规模实时交互迈进。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/testingcatalog/status/1990566844650975721\">https://x.com/testingcatalog/status/1990566844650975721</a></p>\n<hr />\n<h3 id=\"13-Cerebras发布REAP剪枝MiniMax-M2模型\">13. 🚀 Cerebras发布REAP剪枝MiniMax-M2模型</h3>\n<p><strong>标签：</strong> <code>Cerebras</code> <code>MiniMax-M2</code> <code>REAP</code></p>\n<p>Cerebras发布三款基于REAP（Retained Expert Activation Pruning）剪枝技术的MiniMax-M2系列模型：MiniMax-M2-REAP-139B-A10B、MiniMax-M2-REAP-172B-A10B和MiniMax-M2-REAP-162B-A10B。这些模型通过结构化剪枝保留关键专家参数，在保持性能的同时显著降低计算资源需求。其中139B版本在推理效率上提升40%，适合部署于边缘设备。该系列模型已在Hugging Face开源，支持商业使用，适用于需要高性能与低延迟的AI应用，如实时翻译、语音识别和自动驾驶。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://huggingface.co/cerebras/MiniMax-M2-REAP-139B-A10B\">https://huggingface.co/cerebras/MiniMax-M2-REAP-139B-A10B</a><br />\n- <a href=\"https://huggingface.co/cerebras/MiniMax-M2-REAP-172B-A10B\">https://huggingface.co/cerebras/MiniMax-M2-REAP-172B-A10B</a><br />\n- <a href=\"https://huggingface.co/cerebras/MiniMax-M2-REAP-162B-A10B\">https://huggingface.co/cerebras/MiniMax-M2-REAP-162B-A10B</a></p>\n<hr />\n<h3 id=\"14-Google推出三项Gemini教育认证\">14. 📈 Google推出三项Gemini教育认证</h3>\n<p><strong>标签：</strong> <code>Google</code> <code>Gemini</code> <code>教育认证</code></p>\n<p>Google宣布推出三项基于Gemini大模型的教育认证：Gemini for Education Specialist、AI Teaching Assistant和AI Curriculum Designer。认证课程涵盖AI基础知识、Gemini API使用、AI辅助教学设计和伦理规范。通过者将获得Google官方认证证书，并有机会参与Google教育生态项目。该认证体系旨在提升教师和教育工作者的AI素养，推动AI技术在K-12和高等教育中的落地，预计2026年覆盖全球10万名教育工作者。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://linux.do/t/topic/1181404\">https://linux.do/t/topic/1181404</a><br />\n- <a href=\"https://x.com/scaling01/status/1990504865408430178\">https://x.com/scaling01/status/1990504865408430178</a><br />\n- <a href=\"https://blog.google/technology/google-deepmind/weathernext-2/\">https://blog.google/technology/google-deepmind/weathernext-2/</a></p>\n<hr />\n<h3 id=\"15-Replicate加入Cloudflare\">15. 📈 Replicate加入Cloudflare</h3>\n<p><strong>标签：</strong> <code>Replicate</code> <code>Cloudflare</code></p>\n<p>AI模型部署平台Replicate宣布正式加入Cloudflare，成为其AI生态的一部分。Replicate将利用Cloudflare的全球边缘网络，提升模型推理的响应速度和安全性。双方将共同开发基于Cloudflare Workers的轻量级AI部署方案，支持一键部署开源模型。此次合作将降低AI应用的部署门槛，尤其利好中小型开发者和初创公司。Replicate团队将并入Cloudflare AI部门，继续维护现有平台并开发新功能。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://replicate.com/blog/replicate-cloudflare\">https://replicate.com/blog/replicate-cloudflare</a><br />\n- <a href=\"https://blog.cloudflare.com/replicate-joins-cloudflare/\">https://blog.cloudflare.com/replicate-joins-cloudflare/</a></p>\n<hr />\n<h3 id=\"16-Jeff-Bezos回归担任Project-Promethe\">16. 📈 Jeff Bezos回归担任Project Prometheus联合CEO</h3>\n<p><strong>标签：</strong> <code>Jeff Bezos</code> <code>Project Prometheus</code> <code>Blue Origin</code></p>\n<p>据《纽约时报》报道，Jeff Bezos已回归并出任Project Prometheus的联合CEO。该项目为Bezos旗下Blue Origin与多家科技公司合作的AI与航天融合项目，聚焦于开发用于深空探测的自主AI系统。Bezos将主导AI架构设计与战略方向，推动大模型在航天任务规划、遥测分析和机器人控制中的应用。此举被视为Bezos在AI时代重新布局科技前沿的重要举措，Project Prometheus预计将在2027年前完成首次AI驱动的月球探测任务。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://www.nytimes.com/2025/11/17/technology/bezos-project-prometheus.html?partner=slack&amp;smid=sl-share\">https://www.nytimes.com/2025/11/17/technology/bezos-project-prometheus.html?partner=slack&amp;smid=sl-share</a></p>\n<hr />\n<hr />\n<h2 id=\"_2\">🎬 视频链接</h2>\n<p><strong>Bilibili</strong>： <a href=\"https://www.bilibili.com/video/BV1jjCkB9ELZ\">https://www.bilibili.com/video/BV1jjCkB9ELZ</a></p>\n<hr />\n<p><em>整理自橘鸦AI早报 | BV号：BV1jjCkB9ELZ | 2025-11-22 08:50:28</em></p>",
      "date": "2025-11-18",
      "filename": "2025-11-18_AI早报_BV1jjCkB9ELZ.md"
    },
    {
      "title": "Google将发Nano Banana Pro【AI 早报 2025-11-17】",
      "publish_date": "2025-11-17",
      "bv_id": "BV1rUChBAEGE",
      "organize_time": "2025-11-22 08:50:37",
      "news_count": 3,
      "overview": "1. 🚀 Google将发布Nano Banana Pro\n2. 🔧 Google Enterprise内测多Agent锦标赛\n3. 🔧 EverMind AI开源智能记忆系统EverMemOS",
      "content": "# Google将发Nano Banana Pro【AI 早报 2025-11-17】\n\n**📅 发布日期：** 2025-11-17\n**🎬 BV号：** BV1rUChBAEGE\n**📝 整理时间：** 2025-11-22 08:50:37\n**📊 资讯数量：** 3 条\n\n---\n\n## 📋 本期概览\n\n1. 🚀 Google将发布Nano Banana Pro\n2. 🔧 Google Enterprise内测多Agent锦标赛\n3. 🔧 EverMind AI开源智能记忆系统EverMemOS\n\n---\n\n### 1. 🚀 Google将发布Nano Banana Pro {#1-Google将发布Nano-Banana-Pro}\n\n**标签：** `Google` `Nano Banana Pro` `Gemini 3 Pro`\n\nGoogle计划于下周发布新一代AI设备Nano Banana Pro，该设备将搭载Gemini 3 Pro大模型。根据Testing Catalog消息，Nano Banana Pro定位为轻量级、高性能AI终端，延续了前代产品的紧凑设计，但在计算能力、多模态交互和本地推理效率方面实现显著升级。Gemini 3 Pro作为其核心引擎，支持更复杂的上下文理解、实时翻译、图像识别与语音合成，并具备增强的隐私保护机制，可在设备端完成更多AI任务，减少云端依赖。该设备有望面向开发者、研究人员及高端消费者，推动边缘AI应用普及，提升AI助手在移动场景下的响应速度与安全性。\n\n**🔗 相关链接：**\n- <https://www.testingcatalog.com/google-to-release-nano-banana-pro-powered-by-gemini-3-pro-next-week/>\n- <https://www.testingcatalog.com/google-to-enable-research-automation-on-gemini-enterprise/>\n\n---\n\n### 2. 🔧 Google Enterprise内测多Agent锦标赛 {#2-Google-Enterprise内测多Agent锦标赛}\n\n**标签：** `Google Enterprise` `Gemini Enterprise` `Multi-Agent Tournament`\n\nGoogle Enterprise正在内部测试一项名为‘多Agent锦标赛’（Multi-Agent Tournament）的新功能，旨在通过竞争性协作机制提升企业AI自动化水平。该功能基于Gemini Enterprise平台，允许多个AI代理（Agent）针对同一任务（如市场分析报告生成、客户支持响应优化）独立提出解决方案，并通过评估框架进行自动评分与优胜选择。系统将利用Gemini 3 Pro的推理能力对代理输出进行质量、准确性和合规性评估，最终输出最优结果。该机制可显著提升复杂任务的执行效率与鲁棒性，适用于金融、法律、研发等需要高精度决策的领域，标志着AI自动化从单代理执行向多代理协同演进的里程碑。\n\n**🔗 相关链接：**\n- <https://www.testingcatalog.com/google-to-enable-research-automation-on-gemini-enterprise/>\n\n---\n\n### 3. 🔧 EverMind AI开源智能记忆系统EverMemOS {#3-EverMind-AI开源智能记忆系统EverMemOS}\n\n**标签：** `EverMind AI` `EverMemOS` `GitHub`\n\nEverMind AI正式开源其智能记忆操作系统EverMemOS，项目代码已托管于GitHub（https://github.com/EverMind-AI/EverMemOS），并同步上线官方网站（https://everm.ai/）。EverMemOS是一个基于AI的长期记忆管理框架，旨在为个人和团队构建可持久化、可检索、可推理的数字记忆库。系统支持自然语言输入、自动摘要、时间线组织、语义检索与上下文关联，利用大模型技术实现记忆的智能分类与主动提醒。其核心特性包括端到端加密、本地部署支持、跨平台同步以及API接口，允许开发者将其集成至笔记、日程、项目管理等应用中。EverMemOS的开源将推动个性化AI助手的演进，为构建‘数字第二大脑’提供基础设施支持，具有广泛的应用潜力，涵盖知识管理、教育、心理健康等领域。\n\n**🔗 相关链接：**\n- <https://github.com/EverMind-AI/EverMemOS>\n- <https://everm.ai/>\n\n---\n\n---\n\n## 🎬 视频链接\n\n**Bilibili**： <https://www.bilibili.com/video/BV1rUChBAEGE>\n\n---\n\n*整理自橘鸦AI早报 | BV号：BV1rUChBAEGE | 2025-11-22 08:50:37*",
      "html_content": "<h1 id=\"googlenano-banana-proai-2025-11-17\">Google将发Nano Banana Pro【AI 早报 2025-11-17】</h1>\n<p><strong>📅 发布日期：</strong> 2025-11-17<br />\n<strong>🎬 BV号：</strong> BV1rUChBAEGE<br />\n<strong>📝 整理时间：</strong> 2025-11-22 08:50:37<br />\n<strong>📊 资讯数量：</strong> 3 条</p>\n<hr />\n<h2 id=\"_1\">📋 本期概览</h2>\n<ol>\n<li>🚀 Google将发布Nano Banana Pro</li>\n<li>🔧 Google Enterprise内测多Agent锦标赛</li>\n<li>🔧 EverMind AI开源智能记忆系统EverMemOS</li>\n</ol>\n<hr />\n<h3 id=\"1-Google将发布Nano-Banana-Pro\">1. 🚀 Google将发布Nano Banana Pro</h3>\n<p><strong>标签：</strong> <code>Google</code> <code>Nano Banana Pro</code> <code>Gemini 3 Pro</code></p>\n<p>Google计划于下周发布新一代AI设备Nano Banana Pro，该设备将搭载Gemini 3 Pro大模型。根据Testing Catalog消息，Nano Banana Pro定位为轻量级、高性能AI终端，延续了前代产品的紧凑设计，但在计算能力、多模态交互和本地推理效率方面实现显著升级。Gemini 3 Pro作为其核心引擎，支持更复杂的上下文理解、实时翻译、图像识别与语音合成，并具备增强的隐私保护机制，可在设备端完成更多AI任务，减少云端依赖。该设备有望面向开发者、研究人员及高端消费者，推动边缘AI应用普及，提升AI助手在移动场景下的响应速度与安全性。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://www.testingcatalog.com/google-to-release-nano-banana-pro-powered-by-gemini-3-pro-next-week/\">https://www.testingcatalog.com/google-to-release-nano-banana-pro-powered-by-gemini-3-pro-next-week/</a><br />\n- <a href=\"https://www.testingcatalog.com/google-to-enable-research-automation-on-gemini-enterprise/\">https://www.testingcatalog.com/google-to-enable-research-automation-on-gemini-enterprise/</a></p>\n<hr />\n<h3 id=\"2-Google-Enterprise内测多Agent锦标赛\">2. 🔧 Google Enterprise内测多Agent锦标赛</h3>\n<p><strong>标签：</strong> <code>Google Enterprise</code> <code>Gemini Enterprise</code> <code>Multi-Agent Tournament</code></p>\n<p>Google Enterprise正在内部测试一项名为‘多Agent锦标赛’（Multi-Agent Tournament）的新功能，旨在通过竞争性协作机制提升企业AI自动化水平。该功能基于Gemini Enterprise平台，允许多个AI代理（Agent）针对同一任务（如市场分析报告生成、客户支持响应优化）独立提出解决方案，并通过评估框架进行自动评分与优胜选择。系统将利用Gemini 3 Pro的推理能力对代理输出进行质量、准确性和合规性评估，最终输出最优结果。该机制可显著提升复杂任务的执行效率与鲁棒性，适用于金融、法律、研发等需要高精度决策的领域，标志着AI自动化从单代理执行向多代理协同演进的里程碑。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://www.testingcatalog.com/google-to-enable-research-automation-on-gemini-enterprise/\">https://www.testingcatalog.com/google-to-enable-research-automation-on-gemini-enterprise/</a></p>\n<hr />\n<h3 id=\"3-EverMind-AI开源智能记忆系统EverMemOS\">3. 🔧 EverMind AI开源智能记忆系统EverMemOS</h3>\n<p><strong>标签：</strong> <code>EverMind AI</code> <code>EverMemOS</code> <code>GitHub</code></p>\n<p>EverMind AI正式开源其智能记忆操作系统EverMemOS，项目代码已托管于GitHub（https://github.com/EverMind-AI/EverMemOS），并同步上线官方网站（https://everm.ai/）。EverMemOS是一个基于AI的长期记忆管理框架，旨在为个人和团队构建可持久化、可检索、可推理的数字记忆库。系统支持自然语言输入、自动摘要、时间线组织、语义检索与上下文关联，利用大模型技术实现记忆的智能分类与主动提醒。其核心特性包括端到端加密、本地部署支持、跨平台同步以及API接口，允许开发者将其集成至笔记、日程、项目管理等应用中。EverMemOS的开源将推动个性化AI助手的演进，为构建‘数字第二大脑’提供基础设施支持，具有广泛的应用潜力，涵盖知识管理、教育、心理健康等领域。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://github.com/EverMind-AI/EverMemOS\">https://github.com/EverMind-AI/EverMemOS</a><br />\n- <a href=\"https://everm.ai/\">https://everm.ai/</a></p>\n<hr />\n<hr />\n<h2 id=\"_2\">🎬 视频链接</h2>\n<p><strong>Bilibili</strong>： <a href=\"https://www.bilibili.com/video/BV1rUChBAEGE\">https://www.bilibili.com/video/BV1rUChBAEGE</a></p>\n<hr />\n<p><em>整理自橘鸦AI早报 | BV号：BV1rUChBAEGE | 2025-11-22 08:50:37</em></p>",
      "date": "2025-11-17",
      "filename": "2025-11-17_AI早报_BV1rUChBAEGE.md"
    },
    {
      "title": "OpenRouter 上线 Sherlock 系列测试模型【AI 早报 2025-11-16】",
      "publish_date": "2025-11-16",
      "bv_id": "BV1WjCDBdEeM",
      "organize_time": "2025-11-22 08:50:54",
      "news_count": 8,
      "overview": "1. 🚀 OpenRouter上线Sherlock系列模型\n2. 🔧 GitHub Copilot公测Raptor mini模型\n3. 🚀 iFlow CLI免费开放MiniMax-M2与Kimi-K2-Thinking\n4. 🔧 Gemini CLI发布v0.15.1补丁\n5. 🚀 Factory推出Ultra订阅档\n6. 🔧 Cerebras发布MiniMax-M2-REAP-162B-A10B稀疏模型\n7. 📈 AMD启动高校春雨计划\n8. 📈 Similarweb：Gemini占比升至13.7%紧逼ChatGPT",
      "content": "# OpenRouter 上线 Sherlock 系列测试模型【AI 早报 2025-11-16】\n\n**📅 发布日期：** 2025-11-16\n**🎬 BV号：** BV1WjCDBdEeM\n**📝 整理时间：** 2025-11-22 08:50:54\n**📊 资讯数量：** 8 条\n\n---\n\n## 📋 本期概览\n\n1. 🚀 OpenRouter上线Sherlock系列模型\n2. 🔧 GitHub Copilot公测Raptor mini模型\n3. 🚀 iFlow CLI免费开放MiniMax-M2与Kimi-K2-Thinking\n4. 🔧 Gemini CLI发布v0.15.1补丁\n5. 🚀 Factory推出Ultra订阅档\n6. 🔧 Cerebras发布MiniMax-M2-REAP-162B-A10B稀疏模型\n7. 📈 AMD启动高校春雨计划\n8. 📈 Similarweb：Gemini占比升至13.7%紧逼ChatGPT\n\n---\n\n### 1. 🚀 OpenRouter上线Sherlock系列模型 {#1-OpenRouter上线Sherlock系列模型}\n\n**标签：** `OpenRouter` `Sherlock系列模型`\n\nOpenRouter于近日正式在其平台上线Sherlock系列AI模型，进一步丰富其多模型推理服务生态。该系列模型专注于增强逻辑推理、代码理解与复杂任务分解能力，支持高并发API调用，适用于开发者构建智能代理、自动化分析系统。Sherlock系列模型的接入，使OpenRouter用户可通过统一接口灵活调用多种前沿推理模型，提升开发效率与系统鲁棒性。此次上线时间为2025年11月10日左右，具体模型参数与性能细节尚未完全公开，但据官方推文显示，其推理能力对标当前主流长思维链（long-CoT）模型。\n\n**🔗 相关链接：**\n- <https://x.com/OpenRouterAI/status/1989793538142605602>\n\n---\n\n### 2. 🔧 GitHub Copilot公测Raptor mini模型 {#2-GitHub-Copilot公测Raptor-mini模型}\n\n**标签：** `GitHub Copilot` `Raptor mini`\n\nGitHub于2025年11月10日宣布，其AI编程助手Copilot正式开启Raptor mini模型的公开预览（public preview）。Raptor mini是GitHub专为轻量化、低延迟代码补全场景优化的小型语言模型，旨在提升IDE内响应速度与资源效率，尤其适用于本地开发环境或低带宽网络。该模型支持主流编程语言，具备上下文感知能力，可在不牺牲准确率的前提下显著降低推理延迟。此次公测标志着GitHub在模型轻量化与边缘部署方向迈出关键一步，未来有望集成至更多开发者工具链中。\n\n**🔗 相关链接：**\n- <https://github.blog/changelog/2025-11-10-raptor-mini-is-rolling-out-in-public-preview-for-github-copilot/>\n\n---\n\n### 3. 🚀 iFlow CLI免费开放MiniMax-M2与Kimi-K2-Thinking {#3-iFlow-CLI免费开放MiniMax-M2与Kimi-K}\n\n**标签：** `iFlow CLI` `MiniMax-M2` `Kimi-K2-Thinking`\n\niFlow CLI于近日宣布免费开放对MiniMax-M2与Kimi-K2-Thinking两大推理模型的调用支持，用户可通过命令行工具直接访问这两款高性能模型。MiniMax-M2以多轮对话与长文本生成见长，Kimi-K2-Thinking则专注于增强型推理与问题分解能力。此次开放基于Linux.do社区公告，表明iFlow正推动开源生态下的模型可访问性，降低开发者使用门槛。此举有望促进AI工具链的模块化与自动化集成，尤其利好自动化运维、脚本生成与智能助手开发场景。\n\n**🔗 相关链接：**\n- <https://linux.do/t/topic/1173582>\n- <https://huggingface.co/cerebras/MiniMax-M2-REAP-162B-A10B>\n\n---\n\n### 4. 🔧 Gemini CLI发布v0.15.1补丁 {#4-Gemini-CLI发布v0151补丁}\n\n**标签：** `Gemini CLI` `Google Gemini`\n\nGemini CLI于2025年11月10日左右发布v0.15.1版本补丁，主要修复此前版本中存在的API连接稳定性、认证失败及日志输出异常等问题。该CLI工具为开发者提供与Google Gemini模型交互的命令行接口，支持批量请求、流式输出与本地缓存管理。v0.15.1版本优化了错误重试机制，并增强了对多区域端点的兼容性，提升了在复杂网络环境下的可用性。此次更新虽为补丁级别，但对依赖CLI进行自动化测试与部署的用户具有重要意义。\n\n**🔗 相关链接：**\n- <https://x.com/JackWoth98/status/1989739338435817908>\n\n---\n\n### 5. 🚀 Factory推出Ultra订阅档 {#5-Factory推出Ultra订阅档}\n\n**标签：** `Factory` `Ultra订阅档`\n\nAI开发平台Factory于2025年11月9日左右推出全新Ultra订阅档位，面向企业级用户提供更高性能、更大配额与专属支持服务。Ultra档包含优先模型访问权、更高并发请求上限、专属API端点及SLA保障，支持私有模型部署与定制化微调流程。该档位旨在满足大型团队与关键业务场景对稳定性与扩展性的需求，标志着Factory从开发者工具向企业级AI基础设施转型。订阅价格尚未公开，但据官方推文，已有部分客户进入早期接入阶段。\n\n**🔗 相关链接：**\n- <https://x.com/FactoryAI/status/1989483223630712966>\n\n---\n\n### 6. 🔧 Cerebras发布MiniMax-M2-REAP-162B-A10B稀疏模型 {#6-Cerebras发布MiniMax-M2-REAP-162B}\n\n**标签：** `Cerebras` `MiniMax-M2-REAP-162B-A10B`\n\nCerebras在Hugging Face平台发布MiniMax-M2-REAP-162B-A10B稀疏模型，该模型基于MiniMax-M2架构，采用REAP（Retrieval-Enhanced Adaptive Pruning）技术实现162B总参数、10B活跃参数的高效稀疏结构。模型在保持高性能的同时显著降低计算与内存开销，适用于长文本生成、多轮对话与知识密集型任务。其稀疏设计特别适合Cerebras晶圆级芯片（Wafer-Scale Engine）的硬件特性，实现高吞吐低延迟推理。该模型已开源，支持商业使用，为稀疏大模型部署提供新范式。\n\n**🔗 相关链接：**\n- <https://huggingface.co/cerebras/MiniMax-M2-REAP-162B-A10B>\n\n---\n\n### 7. 📈 AMD启动高校春雨计划 {#7-AMD启动高校春雨计划}\n\n**标签：** `AMD` `高校春雨计划`\n\nAMD于2025年11月启动“高校春雨计划”，旨在通过捐赠AI计算资源、提供技术培训与共建联合实验室等方式，支持中国高校在人工智能领域的科研与教学。该计划覆盖GPU硬件、ROCm开源软件栈及AI开发工具链，重点支持大模型训练、科学计算与边缘AI应用。首批合作院校包括多所985与双一流高校，AMD将提供Instinct系列加速器及技术支持，助力本土AI人才培养与技术创新。此举强化了AMD在亚太区教育生态的布局。\n\n**🔗 相关链接：**\n- <https://zhidx.com/p/515395.html>\n\n---\n\n### 8. 📈 Similarweb：Gemini占比升至13.7%紧逼ChatGPT {#8-SimilarwebGemini占比升至137紧逼ChatG}\n\n**标签：** `Similarweb` `Gemini` `ChatGPT`\n\n据Similarweb于2025年11月9日发布的最新数据，Google Gemini在全球AI聊天机器人流量中的占比已上升至13.7%，较此前显著增长，正迅速逼近市场领导者ChatGPT。数据显示，Gemini在移动端与集成搜索场景中的使用率持续攀升，尤其在Android生态与Google Workspace用户中渗透率较高。其增长得益于Google在搜索、邮件、文档等产品中的深度集成策略。尽管ChatGPT仍占据主导地位，但Gemini的增速表明多模态与原生集成正成为竞争关键。\n\n**🔗 相关链接：**\n- <https://x.com/JackWoth98/status/1989739338435817908>\n- <https://x.com/Similarweb/status/1988879389992386897>\n\n---\n\n---\n\n## 🎬 视频链接\n\n**Bilibili**： <https://www.bilibili.com/video/BV1WjCDBdEeM>\n\n---\n\n*整理自橘鸦AI早报 | BV号：BV1WjCDBdEeM | 2025-11-22 08:50:54*",
      "html_content": "<h1 id=\"openrouter-sherlock-ai-2025-11-16\">OpenRouter 上线 Sherlock 系列测试模型【AI 早报 2025-11-16】</h1>\n<p><strong>📅 发布日期：</strong> 2025-11-16<br />\n<strong>🎬 BV号：</strong> BV1WjCDBdEeM<br />\n<strong>📝 整理时间：</strong> 2025-11-22 08:50:54<br />\n<strong>📊 资讯数量：</strong> 8 条</p>\n<hr />\n<h2 id=\"_1\">📋 本期概览</h2>\n<ol>\n<li>🚀 OpenRouter上线Sherlock系列模型</li>\n<li>🔧 GitHub Copilot公测Raptor mini模型</li>\n<li>🚀 iFlow CLI免费开放MiniMax-M2与Kimi-K2-Thinking</li>\n<li>🔧 Gemini CLI发布v0.15.1补丁</li>\n<li>🚀 Factory推出Ultra订阅档</li>\n<li>🔧 Cerebras发布MiniMax-M2-REAP-162B-A10B稀疏模型</li>\n<li>📈 AMD启动高校春雨计划</li>\n<li>📈 Similarweb：Gemini占比升至13.7%紧逼ChatGPT</li>\n</ol>\n<hr />\n<h3 id=\"1-OpenRouter上线Sherlock系列模型\">1. 🚀 OpenRouter上线Sherlock系列模型</h3>\n<p><strong>标签：</strong> <code>OpenRouter</code> <code>Sherlock系列模型</code></p>\n<p>OpenRouter于近日正式在其平台上线Sherlock系列AI模型，进一步丰富其多模型推理服务生态。该系列模型专注于增强逻辑推理、代码理解与复杂任务分解能力，支持高并发API调用，适用于开发者构建智能代理、自动化分析系统。Sherlock系列模型的接入，使OpenRouter用户可通过统一接口灵活调用多种前沿推理模型，提升开发效率与系统鲁棒性。此次上线时间为2025年11月10日左右，具体模型参数与性能细节尚未完全公开，但据官方推文显示，其推理能力对标当前主流长思维链（long-CoT）模型。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/OpenRouterAI/status/1989793538142605602\">https://x.com/OpenRouterAI/status/1989793538142605602</a></p>\n<hr />\n<h3 id=\"2-GitHub-Copilot公测Raptor-mini模型\">2. 🔧 GitHub Copilot公测Raptor mini模型</h3>\n<p><strong>标签：</strong> <code>GitHub Copilot</code> <code>Raptor mini</code></p>\n<p>GitHub于2025年11月10日宣布，其AI编程助手Copilot正式开启Raptor mini模型的公开预览（public preview）。Raptor mini是GitHub专为轻量化、低延迟代码补全场景优化的小型语言模型，旨在提升IDE内响应速度与资源效率，尤其适用于本地开发环境或低带宽网络。该模型支持主流编程语言，具备上下文感知能力，可在不牺牲准确率的前提下显著降低推理延迟。此次公测标志着GitHub在模型轻量化与边缘部署方向迈出关键一步，未来有望集成至更多开发者工具链中。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://github.blog/changelog/2025-11-10-raptor-mini-is-rolling-out-in-public-preview-for-github-copilot/\">https://github.blog/changelog/2025-11-10-raptor-mini-is-rolling-out-in-public-preview-for-github-copilot/</a></p>\n<hr />\n<h3 id=\"3-iFlow-CLI免费开放MiniMax-M2与Kimi-K\">3. 🚀 iFlow CLI免费开放MiniMax-M2与Kimi-K2-Thinking</h3>\n<p><strong>标签：</strong> <code>iFlow CLI</code> <code>MiniMax-M2</code> <code>Kimi-K2-Thinking</code></p>\n<p>iFlow CLI于近日宣布免费开放对MiniMax-M2与Kimi-K2-Thinking两大推理模型的调用支持，用户可通过命令行工具直接访问这两款高性能模型。MiniMax-M2以多轮对话与长文本生成见长，Kimi-K2-Thinking则专注于增强型推理与问题分解能力。此次开放基于Linux.do社区公告，表明iFlow正推动开源生态下的模型可访问性，降低开发者使用门槛。此举有望促进AI工具链的模块化与自动化集成，尤其利好自动化运维、脚本生成与智能助手开发场景。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://linux.do/t/topic/1173582\">https://linux.do/t/topic/1173582</a><br />\n- <a href=\"https://huggingface.co/cerebras/MiniMax-M2-REAP-162B-A10B\">https://huggingface.co/cerebras/MiniMax-M2-REAP-162B-A10B</a></p>\n<hr />\n<h3 id=\"4-Gemini-CLI发布v0151补丁\">4. 🔧 Gemini CLI发布v0.15.1补丁</h3>\n<p><strong>标签：</strong> <code>Gemini CLI</code> <code>Google Gemini</code></p>\n<p>Gemini CLI于2025年11月10日左右发布v0.15.1版本补丁，主要修复此前版本中存在的API连接稳定性、认证失败及日志输出异常等问题。该CLI工具为开发者提供与Google Gemini模型交互的命令行接口，支持批量请求、流式输出与本地缓存管理。v0.15.1版本优化了错误重试机制，并增强了对多区域端点的兼容性，提升了在复杂网络环境下的可用性。此次更新虽为补丁级别，但对依赖CLI进行自动化测试与部署的用户具有重要意义。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/JackWoth98/status/1989739338435817908\">https://x.com/JackWoth98/status/1989739338435817908</a></p>\n<hr />\n<h3 id=\"5-Factory推出Ultra订阅档\">5. 🚀 Factory推出Ultra订阅档</h3>\n<p><strong>标签：</strong> <code>Factory</code> <code>Ultra订阅档</code></p>\n<p>AI开发平台Factory于2025年11月9日左右推出全新Ultra订阅档位，面向企业级用户提供更高性能、更大配额与专属支持服务。Ultra档包含优先模型访问权、更高并发请求上限、专属API端点及SLA保障，支持私有模型部署与定制化微调流程。该档位旨在满足大型团队与关键业务场景对稳定性与扩展性的需求，标志着Factory从开发者工具向企业级AI基础设施转型。订阅价格尚未公开，但据官方推文，已有部分客户进入早期接入阶段。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/FactoryAI/status/1989483223630712966\">https://x.com/FactoryAI/status/1989483223630712966</a></p>\n<hr />\n<h3 id=\"6-Cerebras发布MiniMax-M2-REAP-162B\">6. 🔧 Cerebras发布MiniMax-M2-REAP-162B-A10B稀疏模型</h3>\n<p><strong>标签：</strong> <code>Cerebras</code> <code>MiniMax-M2-REAP-162B-A10B</code></p>\n<p>Cerebras在Hugging Face平台发布MiniMax-M2-REAP-162B-A10B稀疏模型，该模型基于MiniMax-M2架构，采用REAP（Retrieval-Enhanced Adaptive Pruning）技术实现162B总参数、10B活跃参数的高效稀疏结构。模型在保持高性能的同时显著降低计算与内存开销，适用于长文本生成、多轮对话与知识密集型任务。其稀疏设计特别适合Cerebras晶圆级芯片（Wafer-Scale Engine）的硬件特性，实现高吞吐低延迟推理。该模型已开源，支持商业使用，为稀疏大模型部署提供新范式。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://huggingface.co/cerebras/MiniMax-M2-REAP-162B-A10B\">https://huggingface.co/cerebras/MiniMax-M2-REAP-162B-A10B</a></p>\n<hr />\n<h3 id=\"7-AMD启动高校春雨计划\">7. 📈 AMD启动高校春雨计划</h3>\n<p><strong>标签：</strong> <code>AMD</code> <code>高校春雨计划</code></p>\n<p>AMD于2025年11月启动“高校春雨计划”，旨在通过捐赠AI计算资源、提供技术培训与共建联合实验室等方式，支持中国高校在人工智能领域的科研与教学。该计划覆盖GPU硬件、ROCm开源软件栈及AI开发工具链，重点支持大模型训练、科学计算与边缘AI应用。首批合作院校包括多所985与双一流高校，AMD将提供Instinct系列加速器及技术支持，助力本土AI人才培养与技术创新。此举强化了AMD在亚太区教育生态的布局。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://zhidx.com/p/515395.html\">https://zhidx.com/p/515395.html</a></p>\n<hr />\n<h3 id=\"8-SimilarwebGemini占比升至137紧逼ChatG\">8. 📈 Similarweb：Gemini占比升至13.7%紧逼ChatGPT</h3>\n<p><strong>标签：</strong> <code>Similarweb</code> <code>Gemini</code> <code>ChatGPT</code></p>\n<p>据Similarweb于2025年11月9日发布的最新数据，Google Gemini在全球AI聊天机器人流量中的占比已上升至13.7%，较此前显著增长，正迅速逼近市场领导者ChatGPT。数据显示，Gemini在移动端与集成搜索场景中的使用率持续攀升，尤其在Android生态与Google Workspace用户中渗透率较高。其增长得益于Google在搜索、邮件、文档等产品中的深度集成策略。尽管ChatGPT仍占据主导地位，但Gemini的增速表明多模态与原生集成正成为竞争关键。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/JackWoth98/status/1989739338435817908\">https://x.com/JackWoth98/status/1989739338435817908</a><br />\n- <a href=\"https://x.com/Similarweb/status/1988879389992386897\">https://x.com/Similarweb/status/1988879389992386897</a></p>\n<hr />\n<hr />\n<h2 id=\"_2\">🎬 视频链接</h2>\n<p><strong>Bilibili</strong>： <a href=\"https://www.bilibili.com/video/BV1WjCDBdEeM\">https://www.bilibili.com/video/BV1WjCDBdEeM</a></p>\n<hr />\n<p><em>整理自橘鸦AI早报 | BV号：BV1WjCDBdEeM | 2025-11-22 08:50:54</em></p>",
      "date": "2025-11-16",
      "filename": "2025-11-16_AI早报_BV1WjCDBdEeM.md"
    },
    {
      "title": "有望下周发布！Gemini3.0能碾压GPT-5.1吗！【AI 早报 2025-11-15】",
      "publish_date": "2025-11-15",
      "bv_id": "BV1G5CLB3EUa",
      "organize_time": "2025-11-22 08:51:18",
      "news_count": 17,
      "overview": "1. 🚀 OpenAI试点ChatGPT群聊功能\n2. 🚀 Google推出Code Wiki知识库\n3. 🔧 Google Colab开放Gemini与Gemma模型\n4. 🚀 美团发布CatPaw IDE Windows版\n5. 🚀 MiniMax推出Coding Plan订阅服务\n6. 🚀 智谱GLM Coding Plan特供版上线魔搭\n7. 🔧 小米开源Miloco智能家居AI内核\n8. 🔧 Claude平台支持结构化输出\n9. 🔧 NotebookLM支持图片信息源上传\n10. 🔧 Qwen Code发布v0.2.1版本\n11. 🔧 Google Gemini App更新Deep Research\n12. 🔧 Google Veo 3.1支持多图参考生成\n13. 📈 硅基流动平台服务与活动规则调整\n14. 🔧 OpenAI研究稀疏电路提升可解释性\n15. 🚀 UI2Code^N发布交互式UI转代码模型\n16. 🚀 Decart发布LSD v2实时视频风格化模型\n17. 📈 Kaggle发布《Prototype to Production》白皮书",
      "content": "# 有望下周发布！Gemini3.0能碾压GPT-5.1吗！【AI 早报 2025-11-15】\n\n**📅 发布日期：** 2025-11-15\n**🎬 BV号：** BV1G5CLB3EUa\n**📝 整理时间：** 2025-11-22 08:51:18\n**📊 资讯数量：** 17 条\n\n---\n\n## 📋 本期概览\n\n1. 🚀 OpenAI试点ChatGPT群聊功能\n2. 🚀 Google推出Code Wiki知识库\n3. 🔧 Google Colab开放Gemini与Gemma模型\n4. 🚀 美团发布CatPaw IDE Windows版\n5. 🚀 MiniMax推出Coding Plan订阅服务\n6. 🚀 智谱GLM Coding Plan特供版上线魔搭\n7. 🔧 小米开源Miloco智能家居AI内核\n8. 🔧 Claude平台支持结构化输出\n9. 🔧 NotebookLM支持图片信息源上传\n10. 🔧 Qwen Code发布v0.2.1版本\n11. 🔧 Google Gemini App更新Deep Research\n12. 🔧 Google Veo 3.1支持多图参考生成\n13. 📈 硅基流动平台服务与活动规则调整\n14. 🔧 OpenAI研究稀疏电路提升可解释性\n15. 🚀 UI2Code^N发布交互式UI转代码模型\n16. 🚀 Decart发布LSD v2实时视频风格化模型\n17. 📈 Kaggle发布《Prototype to Production》白皮书\n\n---\n\n### 1. 🚀 OpenAI试点ChatGPT群聊功能 {#1-OpenAI试点ChatGPT群聊功能}\n\n**标签：** `OpenAI` `ChatGPT`\n\nOpenAI于近日试点推出ChatGPT群聊功能，允许用户在多人对话场景中使用ChatGPT进行协作交流。该功能支持多用户同时参与同一聊天线程，AI可识别不同发言者并生成上下文连贯的响应，提升团队沟通效率。群聊功能目前处于试点阶段，未来可能逐步向更多用户开放。该功能有望广泛应用于远程协作、项目讨论、教育辅导等场景，增强AI在多人交互中的实用性。\n\n**🔗 相关链接：**\n- <https://openai.com/index/group-chats-in-chatgpt/>\n- <https://openai.com/index/understanding-neural-networks-through-sparse-circuits/>\n\n---\n\n### 2. 🚀 Google推出Code Wiki知识库 {#2-Google推出Code-Wiki知识库}\n\n**标签：** `Google` `Code Wiki`\n\nGoogle正式发布Code Wiki，一个面向开发者的代码知识共享平台。该平台旨在整合代码片段、最佳实践、API文档和调试技巧，支持社区协作编辑与版本管理。Code Wiki通过结构化内容组织，帮助开发者快速查找和复用代码资源，提升开发效率。平台支持多语言、多框架，并与Google开发者生态深度集成，有望成为开源社区的重要知识基础设施。\n\n**🔗 相关链接：**\n- <https://codewiki.google/>\n- <https://x.com/dotey/status/1989402550366605777>\n- <https://goo.gle/47QTmnB>\n\n---\n\n### 3. 🔧 Google Colab开放Gemini与Gemma模型 {#3-Google-Colab开放Gemini与Gemma模型}\n\n**标签：** `Google` `Google Colab` `Gemini` `Gemma`\n\nGoogle Colab宣布向所有用户免费开放Gemini和Gemma系列AI模型的调用权限，通过Colab Python库即可直接集成。此次更新包括Gemini 1.5 Pro、Gemini 1.5 Flash和Gemma 2等模型，支持文本生成、代码补全、数据分析等任务。同时，Colab已集成VS Code开发环境，用户可在Notebook中直接使用VS Code进行调试与版本控制。此举显著降低了AI模型的使用门槛，推动教育与研究领域的AI普及。\n\n**🔗 相关链接：**\n- <https://codewiki.google/>\n- <https://x.com/dotey/status/1989402550366605777>\n- <https://goo.gle/47QTmnB>\n\n---\n\n### 4. 🚀 美团发布CatPaw IDE Windows版 {#4-美团发布CatPaw-IDE-Windows版}\n\n**标签：** `美团` `CatPaw IDE`\n\n美团正式推出其自研AI原生集成开发环境CatPaw的Windows版本，支持跨平台开发。CatPaw IDE深度集成AI编程助手，提供智能代码补全、错误检测、重构建议等功能，支持Python、Java、JavaScript等主流语言。其核心优势在于与美团内部开发流程深度耦合，同时支持插件扩展，适用于企业级应用开发。Windows版本的发布标志着CatPaw向更广泛开发者群体开放。\n\n**🔗 相关链接：**\n- <https://catpaw.meituan.com/>\n\n---\n\n### 5. 🚀 MiniMax推出Coding Plan订阅服务 {#5-MiniMax推出Coding-Plan订阅服务}\n\n**标签：** `MiniMax` `Coding Plan`\n\nMiniMax发布面向开发者的Coding Plan订阅服务，提供专属AI编程支持。该服务包含代码生成、调试辅助、性能优化建议等功能，支持多语言开发环境。订阅用户可获得更高调用额度、优先响应和定制化模型微调权限。服务定价与资源配额详见官方文档，旨在为中小企业和个人开发者提供高性价比的AI编程解决方案。\n\n**🔗 相关链接：**\n- <https://platform.minimaxi.com/subscribe/coding-plan>\n- <https://platform.minimaxi.com/docs/coding-plan/faq>\n- <https://mp.weixin.qq.com/s/HKc92GnyPrHH6044fQKeUQ>\n\n---\n\n### 6. 🚀 智谱GLM Coding Plan特供版上线魔搭 {#6-智谱GLM-Coding-Plan特供版上线魔搭}\n\n**标签：** `智谱AI` `GLM` `魔搭社区`\n\n智谱AI在魔搭社区推出GLM Coding Plan特供版，专为代码生成与编程辅助优化。该版本基于GLM-4模型进行微调，支持代码补全、注释生成、错误定位等功能，兼容主流IDE插件。特供版提供更高并发与响应速度，面向订阅用户开放，进一步推动国产大模型在开发领域的落地应用。\n\n**🔗 相关链接：**\n- <https://mp.weixin.qq.com/s/HKc92GnyPrHH6044fQKeUQ>\n\n---\n\n### 7. 🔧 小米开源Miloco智能家居AI内核 {#7-小米开源Miloco智能家居AI内核}\n\n**标签：** `小米` `Miloco`\n\n小米开源其AI内核智能家居探索方案Miloco，项目已托管于GitHub。Miloco旨在构建统一的AI驱动智能家居控制框架，支持多设备协同、语音交互、场景自动化等功能。其核心包括设备抽象层、意图理解引擎与执行调度器，采用模块化设计，便于第三方开发者集成与扩展。该开源项目有望推动智能家居生态的标准化与AI化。\n\n**🔗 相关链接：**\n- <https://github.com/XiaoMi/xiaomi-miloco>\n\n---\n\n### 8. 🔧 Claude平台支持结构化输出 {#8-Claude平台支持结构化输出}\n\n**标签：** `Anthropic` `Claude`\n\nAnthropic在Claude开发者平台推出结构化输出功能，允许开发者通过JSON Schema定义AI响应格式。该功能确保模型输出符合预定义的数据结构，提升API调用的可靠性与可解析性。支持嵌套对象、数组、类型约束等，适用于表单生成、数据提取、自动化流程等场景。该更新显著增强了Claude在结构化任务中的实用性，降低后处理成本。\n\n**🔗 相关链接：**\n- <https://claude.com/blog/structured-outputs-on-the-claude-developer-platform>\n- <https://docs.claude.com/en/docs/build-with-claude/structured-outputs>\n\n---\n\n### 9. 🔧 NotebookLM支持图片信息源上传 {#9-NotebookLM支持图片信息源上传}\n\n**标签：** `Google` `NotebookLM`\n\nGoogle NotebookLM新增支持上传图片作为信息源，用户可将PDF、截图、图表等图像文件导入，AI将自动提取文本与视觉信息进行分析。该功能结合OCR与多模态理解能力，支持基于图像内容的问答、摘要生成与知识关联。此举扩展了NotebookLM在科研、教育、文档管理等场景的应用边界。\n\n**🔗 相关链接：**\n- <https://codewiki.google/>\n- <https://x.com/dotey/status/1989402550366605777>\n- <https://goo.gle/47QTmnB>\n\n---\n\n### 10. 🔧 Qwen Code发布v0.2.1版本 {#10-Qwen-Code发布v021版本}\n\n**标签：** `阿里云` `Qwen Code`\n\n阿里云发布Qwen Code v0.2.1版本，为通义千问系列代码专用模型的更新版本。该版本优化了代码生成准确率、上下文理解能力与长序列处理能力，支持Python、Java、C++等主流语言。v0.2.1引入更高效的推理机制，降低延迟，提升在复杂项目中的实用性。更新内容已在官方渠道公布，供开发者集成使用。\n\n**🔗 相关链接：**\n- <https://x.com/Alibaba_Qwen/status/1989368317011009901>\n\n---\n\n### 11. 🔧 Google Gemini App更新Deep Research {#11-Google-Gemini-App更新Deep-Resear}\n\n**标签：** `Google` `Gemini App`\n\nGoogle Gemini App推出Deep Research功能更新，增强其深度研究能力。该功能可自动检索、分析并整合多源信息，生成结构化研究报告。更新后支持更复杂的查询逻辑、多轮推理与跨文档关联，适用于市场分析、学术研究、技术调研等场景。用户可通过自然语言指令启动研究流程，提升信息获取效率。\n\n**🔗 相关链接：**\n- <https://codewiki.google/>\n- <https://x.com/dotey/status/1989402550366605777>\n- <https://goo.gle/47QTmnB>\n\n---\n\n### 12. 🔧 Google Veo 3.1支持多图参考生成 {#12-Google-Veo-31支持多图参考生成}\n\n**标签：** `Google` `Veo`\n\nGoogle发布Veo 3.1版本，其视频生成模型新增支持多图参考功能。用户可同时上传多张图像作为风格或内容参考，Veo将融合多图信息生成连贯视频。该功能提升视频生成的可控性与一致性，适用于广告、动画、内容创作等领域。3.1版本还优化了生成速度与画质，进一步推动AI视频生成技术的实用化。\n\n**🔗 相关链接：**\n- <https://codewiki.google/>\n- <https://x.com/dotey/status/1989402550366605777>\n- <https://goo.gle/47QTmnB>\n\n---\n\n### 13. 📈 硅基流动平台服务与活动规则调整 {#13-硅基流动平台服务与活动规则调整}\n\n**标签：** `硅基流动`\n\n硅基流动宣布对其AI平台服务架构与活动规则进行系统性调整。具体包括API调用配额、计费策略、开发者激励计划的更新，旨在优化资源分配与用户体验。调整涉及模型访问权限、免费额度、企业合作方案等，具体细则已在其官网公布。此次更新反映平台在规模化运营中的策略演进，可能影响现有开发者的使用成本。\n\n---\n\n### 14. 🔧 OpenAI研究稀疏电路提升可解释性 {#14-OpenAI研究稀疏电路提升可解释性}\n\n**标签：** `OpenAI` `稀疏电路`\n\nOpenAI发布最新研究，提出通过稀疏电路（Sparse Circuits）方法提升神经网络模型的可解释性。该研究识别出模型中关键神经元子集，这些子集在特定任务中起决定性作用，且结构稀疏、易于分析。实验表明，稀疏电路可解释模型决策路径，有助于发现偏见、提升安全性。该成果为AI透明化与可信AI发展提供新路径。\n\n**🔗 相关链接：**\n- <https://openai.com/index/group-chats-in-chatgpt/>\n- <https://openai.com/index/understanding-neural-networks-through-sparse-circuits/>\n\n---\n\n### 15. 🚀 UI2Code^N发布交互式UI转代码模型 {#15-UI2CodeN发布交互式UI转代码模型}\n\n**标签：** `zai-org` `UI2Code^N`\n\nzai-org团队发布UI2Code^N，一款交互式UI-to-Code视觉语言模型，支持将设计稿或截图直接转换为前端代码。该模型基于多模态架构，支持HTML、CSS、React等输出格式，具备上下文感知与用户反馈机制，可迭代优化生成结果。模型已开源，提供Hugging Face与GitHub入口，适用于快速原型开发与设计系统自动化。\n\n**🔗 相关链接：**\n- <https://github.com/zai-org/UI2Code_N>\n- <https://huggingface.co/zai-org/UI2Code_N>\n\n---\n\n### 16. 🚀 Decart发布LSD v2实时视频风格化模型 {#16-Decart发布LSD-v2实时视频风格化模型}\n\n**标签：** `Decart` `LSD v2`\n\nDecart推出LSD v2实时视频风格化模型，支持低延迟、高保真度的视频风格迁移。该模型可在GPU上实现实时处理，支持多种艺术风格（如油画、水彩、卡通），适用于直播、视频会议、内容创作等场景。v2版本优化了风格一致性、边缘处理与色彩还原，显著提升用户体验。模型已在社交平台展示演示效果。\n\n**🔗 相关链接：**\n- <https://x.com/kimmonismus/status/1989479481895989693>\n- <https://x.com/DecartAI/status/1989425986891583763>\n\n---\n\n### 17. 📈 Kaggle发布《Prototype to Production》白皮书 {#17-Kaggle发布Prototype-to-Productio}\n\n**标签：** `Kaggle`\n\nKaggle发布《Prototype to Production》白皮书，系统阐述从AI原型到生产部署的全流程方法论。内容涵盖数据工程、模型训练、评估、部署、监控与团队协作，结合真实案例与最佳实践。白皮书强调MLOps、可复现性、伦理合规等关键要素，面向数据科学家与工程团队，助力AI项目规模化落地。\n\n---\n\n---\n\n## 🎬 视频链接\n\n**Bilibili**： <https://www.bilibili.com/video/BV1G5CLB3EUa>\n\n---\n\n*整理自橘鸦AI早报 | BV号：BV1G5CLB3EUa | 2025-11-22 08:51:18*",
      "html_content": "<h1 id=\"gemini30gpt-51ai-2025-11-15\">有望下周发布！Gemini3.0能碾压GPT-5.1吗！【AI 早报 2025-11-15】</h1>\n<p><strong>📅 发布日期：</strong> 2025-11-15<br />\n<strong>🎬 BV号：</strong> BV1G5CLB3EUa<br />\n<strong>📝 整理时间：</strong> 2025-11-22 08:51:18<br />\n<strong>📊 资讯数量：</strong> 17 条</p>\n<hr />\n<h2 id=\"_1\">📋 本期概览</h2>\n<ol>\n<li>🚀 OpenAI试点ChatGPT群聊功能</li>\n<li>🚀 Google推出Code Wiki知识库</li>\n<li>🔧 Google Colab开放Gemini与Gemma模型</li>\n<li>🚀 美团发布CatPaw IDE Windows版</li>\n<li>🚀 MiniMax推出Coding Plan订阅服务</li>\n<li>🚀 智谱GLM Coding Plan特供版上线魔搭</li>\n<li>🔧 小米开源Miloco智能家居AI内核</li>\n<li>🔧 Claude平台支持结构化输出</li>\n<li>🔧 NotebookLM支持图片信息源上传</li>\n<li>🔧 Qwen Code发布v0.2.1版本</li>\n<li>🔧 Google Gemini App更新Deep Research</li>\n<li>🔧 Google Veo 3.1支持多图参考生成</li>\n<li>📈 硅基流动平台服务与活动规则调整</li>\n<li>🔧 OpenAI研究稀疏电路提升可解释性</li>\n<li>🚀 UI2Code^N发布交互式UI转代码模型</li>\n<li>🚀 Decart发布LSD v2实时视频风格化模型</li>\n<li>📈 Kaggle发布《Prototype to Production》白皮书</li>\n</ol>\n<hr />\n<h3 id=\"1-OpenAI试点ChatGPT群聊功能\">1. 🚀 OpenAI试点ChatGPT群聊功能</h3>\n<p><strong>标签：</strong> <code>OpenAI</code> <code>ChatGPT</code></p>\n<p>OpenAI于近日试点推出ChatGPT群聊功能，允许用户在多人对话场景中使用ChatGPT进行协作交流。该功能支持多用户同时参与同一聊天线程，AI可识别不同发言者并生成上下文连贯的响应，提升团队沟通效率。群聊功能目前处于试点阶段，未来可能逐步向更多用户开放。该功能有望广泛应用于远程协作、项目讨论、教育辅导等场景，增强AI在多人交互中的实用性。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://openai.com/index/group-chats-in-chatgpt/\">https://openai.com/index/group-chats-in-chatgpt/</a><br />\n- <a href=\"https://openai.com/index/understanding-neural-networks-through-sparse-circuits/\">https://openai.com/index/understanding-neural-networks-through-sparse-circuits/</a></p>\n<hr />\n<h3 id=\"2-Google推出Code-Wiki知识库\">2. 🚀 Google推出Code Wiki知识库</h3>\n<p><strong>标签：</strong> <code>Google</code> <code>Code Wiki</code></p>\n<p>Google正式发布Code Wiki，一个面向开发者的代码知识共享平台。该平台旨在整合代码片段、最佳实践、API文档和调试技巧，支持社区协作编辑与版本管理。Code Wiki通过结构化内容组织，帮助开发者快速查找和复用代码资源，提升开发效率。平台支持多语言、多框架，并与Google开发者生态深度集成，有望成为开源社区的重要知识基础设施。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://codewiki.google/\">https://codewiki.google/</a><br />\n- <a href=\"https://x.com/dotey/status/1989402550366605777\">https://x.com/dotey/status/1989402550366605777</a><br />\n- <a href=\"https://goo.gle/47QTmnB\">https://goo.gle/47QTmnB</a></p>\n<hr />\n<h3 id=\"3-Google-Colab开放Gemini与Gemma模型\">3. 🔧 Google Colab开放Gemini与Gemma模型</h3>\n<p><strong>标签：</strong> <code>Google</code> <code>Google Colab</code> <code>Gemini</code> <code>Gemma</code></p>\n<p>Google Colab宣布向所有用户免费开放Gemini和Gemma系列AI模型的调用权限，通过Colab Python库即可直接集成。此次更新包括Gemini 1.5 Pro、Gemini 1.5 Flash和Gemma 2等模型，支持文本生成、代码补全、数据分析等任务。同时，Colab已集成VS Code开发环境，用户可在Notebook中直接使用VS Code进行调试与版本控制。此举显著降低了AI模型的使用门槛，推动教育与研究领域的AI普及。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://codewiki.google/\">https://codewiki.google/</a><br />\n- <a href=\"https://x.com/dotey/status/1989402550366605777\">https://x.com/dotey/status/1989402550366605777</a><br />\n- <a href=\"https://goo.gle/47QTmnB\">https://goo.gle/47QTmnB</a></p>\n<hr />\n<h3 id=\"4-美团发布CatPaw-IDE-Windows版\">4. 🚀 美团发布CatPaw IDE Windows版</h3>\n<p><strong>标签：</strong> <code>美团</code> <code>CatPaw IDE</code></p>\n<p>美团正式推出其自研AI原生集成开发环境CatPaw的Windows版本，支持跨平台开发。CatPaw IDE深度集成AI编程助手，提供智能代码补全、错误检测、重构建议等功能，支持Python、Java、JavaScript等主流语言。其核心优势在于与美团内部开发流程深度耦合，同时支持插件扩展，适用于企业级应用开发。Windows版本的发布标志着CatPaw向更广泛开发者群体开放。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://catpaw.meituan.com/\">https://catpaw.meituan.com/</a></p>\n<hr />\n<h3 id=\"5-MiniMax推出Coding-Plan订阅服务\">5. 🚀 MiniMax推出Coding Plan订阅服务</h3>\n<p><strong>标签：</strong> <code>MiniMax</code> <code>Coding Plan</code></p>\n<p>MiniMax发布面向开发者的Coding Plan订阅服务，提供专属AI编程支持。该服务包含代码生成、调试辅助、性能优化建议等功能，支持多语言开发环境。订阅用户可获得更高调用额度、优先响应和定制化模型微调权限。服务定价与资源配额详见官方文档，旨在为中小企业和个人开发者提供高性价比的AI编程解决方案。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://platform.minimaxi.com/subscribe/coding-plan\">https://platform.minimaxi.com/subscribe/coding-plan</a><br />\n- <a href=\"https://platform.minimaxi.com/docs/coding-plan/faq\">https://platform.minimaxi.com/docs/coding-plan/faq</a><br />\n- <a href=\"https://mp.weixin.qq.com/s/HKc92GnyPrHH6044fQKeUQ\">https://mp.weixin.qq.com/s/HKc92GnyPrHH6044fQKeUQ</a></p>\n<hr />\n<h3 id=\"6-智谱GLM-Coding-Plan特供版上线魔搭\">6. 🚀 智谱GLM Coding Plan特供版上线魔搭</h3>\n<p><strong>标签：</strong> <code>智谱AI</code> <code>GLM</code> <code>魔搭社区</code></p>\n<p>智谱AI在魔搭社区推出GLM Coding Plan特供版，专为代码生成与编程辅助优化。该版本基于GLM-4模型进行微调，支持代码补全、注释生成、错误定位等功能，兼容主流IDE插件。特供版提供更高并发与响应速度，面向订阅用户开放，进一步推动国产大模型在开发领域的落地应用。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://mp.weixin.qq.com/s/HKc92GnyPrHH6044fQKeUQ\">https://mp.weixin.qq.com/s/HKc92GnyPrHH6044fQKeUQ</a></p>\n<hr />\n<h3 id=\"7-小米开源Miloco智能家居AI内核\">7. 🔧 小米开源Miloco智能家居AI内核</h3>\n<p><strong>标签：</strong> <code>小米</code> <code>Miloco</code></p>\n<p>小米开源其AI内核智能家居探索方案Miloco，项目已托管于GitHub。Miloco旨在构建统一的AI驱动智能家居控制框架，支持多设备协同、语音交互、场景自动化等功能。其核心包括设备抽象层、意图理解引擎与执行调度器，采用模块化设计，便于第三方开发者集成与扩展。该开源项目有望推动智能家居生态的标准化与AI化。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://github.com/XiaoMi/xiaomi-miloco\">https://github.com/XiaoMi/xiaomi-miloco</a></p>\n<hr />\n<h3 id=\"8-Claude平台支持结构化输出\">8. 🔧 Claude平台支持结构化输出</h3>\n<p><strong>标签：</strong> <code>Anthropic</code> <code>Claude</code></p>\n<p>Anthropic在Claude开发者平台推出结构化输出功能，允许开发者通过JSON Schema定义AI响应格式。该功能确保模型输出符合预定义的数据结构，提升API调用的可靠性与可解析性。支持嵌套对象、数组、类型约束等，适用于表单生成、数据提取、自动化流程等场景。该更新显著增强了Claude在结构化任务中的实用性，降低后处理成本。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://claude.com/blog/structured-outputs-on-the-claude-developer-platform\">https://claude.com/blog/structured-outputs-on-the-claude-developer-platform</a><br />\n- <a href=\"https://docs.claude.com/en/docs/build-with-claude/structured-outputs\">https://docs.claude.com/en/docs/build-with-claude/structured-outputs</a></p>\n<hr />\n<h3 id=\"9-NotebookLM支持图片信息源上传\">9. 🔧 NotebookLM支持图片信息源上传</h3>\n<p><strong>标签：</strong> <code>Google</code> <code>NotebookLM</code></p>\n<p>Google NotebookLM新增支持上传图片作为信息源，用户可将PDF、截图、图表等图像文件导入，AI将自动提取文本与视觉信息进行分析。该功能结合OCR与多模态理解能力，支持基于图像内容的问答、摘要生成与知识关联。此举扩展了NotebookLM在科研、教育、文档管理等场景的应用边界。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://codewiki.google/\">https://codewiki.google/</a><br />\n- <a href=\"https://x.com/dotey/status/1989402550366605777\">https://x.com/dotey/status/1989402550366605777</a><br />\n- <a href=\"https://goo.gle/47QTmnB\">https://goo.gle/47QTmnB</a></p>\n<hr />\n<h3 id=\"10-Qwen-Code发布v021版本\">10. 🔧 Qwen Code发布v0.2.1版本</h3>\n<p><strong>标签：</strong> <code>阿里云</code> <code>Qwen Code</code></p>\n<p>阿里云发布Qwen Code v0.2.1版本，为通义千问系列代码专用模型的更新版本。该版本优化了代码生成准确率、上下文理解能力与长序列处理能力，支持Python、Java、C++等主流语言。v0.2.1引入更高效的推理机制，降低延迟，提升在复杂项目中的实用性。更新内容已在官方渠道公布，供开发者集成使用。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/Alibaba_Qwen/status/1989368317011009901\">https://x.com/Alibaba_Qwen/status/1989368317011009901</a></p>\n<hr />\n<h3 id=\"11-Google-Gemini-App更新Deep-Resear\">11. 🔧 Google Gemini App更新Deep Research</h3>\n<p><strong>标签：</strong> <code>Google</code> <code>Gemini App</code></p>\n<p>Google Gemini App推出Deep Research功能更新，增强其深度研究能力。该功能可自动检索、分析并整合多源信息，生成结构化研究报告。更新后支持更复杂的查询逻辑、多轮推理与跨文档关联，适用于市场分析、学术研究、技术调研等场景。用户可通过自然语言指令启动研究流程，提升信息获取效率。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://codewiki.google/\">https://codewiki.google/</a><br />\n- <a href=\"https://x.com/dotey/status/1989402550366605777\">https://x.com/dotey/status/1989402550366605777</a><br />\n- <a href=\"https://goo.gle/47QTmnB\">https://goo.gle/47QTmnB</a></p>\n<hr />\n<h3 id=\"12-Google-Veo-31支持多图参考生成\">12. 🔧 Google Veo 3.1支持多图参考生成</h3>\n<p><strong>标签：</strong> <code>Google</code> <code>Veo</code></p>\n<p>Google发布Veo 3.1版本，其视频生成模型新增支持多图参考功能。用户可同时上传多张图像作为风格或内容参考，Veo将融合多图信息生成连贯视频。该功能提升视频生成的可控性与一致性，适用于广告、动画、内容创作等领域。3.1版本还优化了生成速度与画质，进一步推动AI视频生成技术的实用化。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://codewiki.google/\">https://codewiki.google/</a><br />\n- <a href=\"https://x.com/dotey/status/1989402550366605777\">https://x.com/dotey/status/1989402550366605777</a><br />\n- <a href=\"https://goo.gle/47QTmnB\">https://goo.gle/47QTmnB</a></p>\n<hr />\n<h3 id=\"13-硅基流动平台服务与活动规则调整\">13. 📈 硅基流动平台服务与活动规则调整</h3>\n<p><strong>标签：</strong> <code>硅基流动</code></p>\n<p>硅基流动宣布对其AI平台服务架构与活动规则进行系统性调整。具体包括API调用配额、计费策略、开发者激励计划的更新，旨在优化资源分配与用户体验。调整涉及模型访问权限、免费额度、企业合作方案等，具体细则已在其官网公布。此次更新反映平台在规模化运营中的策略演进，可能影响现有开发者的使用成本。</p>\n<hr />\n<h3 id=\"14-OpenAI研究稀疏电路提升可解释性\">14. 🔧 OpenAI研究稀疏电路提升可解释性</h3>\n<p><strong>标签：</strong> <code>OpenAI</code> <code>稀疏电路</code></p>\n<p>OpenAI发布最新研究，提出通过稀疏电路（Sparse Circuits）方法提升神经网络模型的可解释性。该研究识别出模型中关键神经元子集，这些子集在特定任务中起决定性作用，且结构稀疏、易于分析。实验表明，稀疏电路可解释模型决策路径，有助于发现偏见、提升安全性。该成果为AI透明化与可信AI发展提供新路径。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://openai.com/index/group-chats-in-chatgpt/\">https://openai.com/index/group-chats-in-chatgpt/</a><br />\n- <a href=\"https://openai.com/index/understanding-neural-networks-through-sparse-circuits/\">https://openai.com/index/understanding-neural-networks-through-sparse-circuits/</a></p>\n<hr />\n<h3 id=\"15-UI2CodeN发布交互式UI转代码模型\">15. 🚀 UI2Code^N发布交互式UI转代码模型</h3>\n<p><strong>标签：</strong> <code>zai-org</code> <code>UI2Code^N</code></p>\n<p>zai-org团队发布UI2Code^N，一款交互式UI-to-Code视觉语言模型，支持将设计稿或截图直接转换为前端代码。该模型基于多模态架构，支持HTML、CSS、React等输出格式，具备上下文感知与用户反馈机制，可迭代优化生成结果。模型已开源，提供Hugging Face与GitHub入口，适用于快速原型开发与设计系统自动化。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://github.com/zai-org/UI2Code_N\">https://github.com/zai-org/UI2Code_N</a><br />\n- <a href=\"https://huggingface.co/zai-org/UI2Code_N\">https://huggingface.co/zai-org/UI2Code_N</a></p>\n<hr />\n<h3 id=\"16-Decart发布LSD-v2实时视频风格化模型\">16. 🚀 Decart发布LSD v2实时视频风格化模型</h3>\n<p><strong>标签：</strong> <code>Decart</code> <code>LSD v2</code></p>\n<p>Decart推出LSD v2实时视频风格化模型，支持低延迟、高保真度的视频风格迁移。该模型可在GPU上实现实时处理，支持多种艺术风格（如油画、水彩、卡通），适用于直播、视频会议、内容创作等场景。v2版本优化了风格一致性、边缘处理与色彩还原，显著提升用户体验。模型已在社交平台展示演示效果。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/kimmonismus/status/1989479481895989693\">https://x.com/kimmonismus/status/1989479481895989693</a><br />\n- <a href=\"https://x.com/DecartAI/status/1989425986891583763\">https://x.com/DecartAI/status/1989425986891583763</a></p>\n<hr />\n<h3 id=\"17-Kaggle发布Prototype-to-Productio\">17. 📈 Kaggle发布《Prototype to Production》白皮书</h3>\n<p><strong>标签：</strong> <code>Kaggle</code></p>\n<p>Kaggle发布《Prototype to Production》白皮书，系统阐述从AI原型到生产部署的全流程方法论。内容涵盖数据工程、模型训练、评估、部署、监控与团队协作，结合真实案例与最佳实践。白皮书强调MLOps、可复现性、伦理合规等关键要素，面向数据科学家与工程团队，助力AI项目规模化落地。</p>\n<hr />\n<hr />\n<h2 id=\"_2\">🎬 视频链接</h2>\n<p><strong>Bilibili</strong>： <a href=\"https://www.bilibili.com/video/BV1G5CLB3EUa\">https://www.bilibili.com/video/BV1G5CLB3EUa</a></p>\n<hr />\n<p><em>整理自橘鸦AI早报 | BV号：BV1G5CLB3EUa | 2025-11-22 08:51:18</em></p>",
      "date": "2025-11-15",
      "filename": "2025-11-15_AI早报_BV1G5CLB3EUa.md"
    },
    {
      "title": "Gemini 3 现身 Gemini APP 的 Canvas 功能 【AI 早报 2025-11-14】",
      "publish_date": "2025-11-14",
      "bv_id": "BV1G5CPBrEmd",
      "organize_time": "2025-11-22 08:51:47",
      "news_count": 17,
      "overview": "1. 🚀 Google DeepMind发布SIMA 2智能体\n2. 🚀 Lumine发布3D开放世界通用智能体\n3. 🚀 百度发布文心5.0大模型\n4. 🚀 OpenAI上线GPT-5.1模型API\n5. 🔧 Codex发布0.58.0集成gpt-5.1模型\n6. 🚀 OpenAI发布Apps SDK预览版\n7. 🔧 Gemini 3或已上线Canvas功能\n8. 🔧 Google发布Gemini Live重大更新\n9. 🔧 Google升级Gemini CLI用户体验\n10. 🔧 Google NotebookLM推出Deep Research功能\n11. 🔧 Google更新AI搜索购物体验\n12. 🚀 Anthropic扩展Claude Code网页版\n13. 🔧 VS Code发布1.106集成Agent管理\n14. 🔧 Qwen发布DeepResearch 2511升级\n15. 📈 阿里云百炼调整通义千问3-Max价格\n16. 🚀 H Company发布Holo2模型系列\n17. 🚀 JanHQ发布Jan-v2-VL多模态Agent模型",
      "content": "# Gemini 3 现身 Gemini APP 的 Canvas 功能 【AI 早报 2025-11-14】\n\n**📅 发布日期：** 2025-11-14\n**🎬 BV号：** BV1G5CPBrEmd\n**📝 整理时间：** 2025-11-22 08:51:47\n**📊 资讯数量：** 17 条\n\n---\n\n## 📋 本期概览\n\n1. 🚀 Google DeepMind发布SIMA 2智能体\n2. 🚀 Lumine发布3D开放世界通用智能体\n3. 🚀 百度发布文心5.0大模型\n4. 🚀 OpenAI上线GPT-5.1模型API\n5. 🔧 Codex发布0.58.0集成gpt-5.1模型\n6. 🚀 OpenAI发布Apps SDK预览版\n7. 🔧 Gemini 3或已上线Canvas功能\n8. 🔧 Google发布Gemini Live重大更新\n9. 🔧 Google升级Gemini CLI用户体验\n10. 🔧 Google NotebookLM推出Deep Research功能\n11. 🔧 Google更新AI搜索购物体验\n12. 🚀 Anthropic扩展Claude Code网页版\n13. 🔧 VS Code发布1.106集成Agent管理\n14. 🔧 Qwen发布DeepResearch 2511升级\n15. 📈 阿里云百炼调整通义千问3-Max价格\n16. 🚀 H Company发布Holo2模型系列\n17. 🚀 JanHQ发布Jan-v2-VL多模态Agent模型\n\n---\n\n### 1. 🚀 Google DeepMind发布SIMA 2智能体 {#1-Google-DeepMind发布SIMA-2智能体}\n\n**标签：** `Google DeepMind` `SIMA 2`\n\nGoogle DeepMind于近日发布SIMA 2（Scalable Instructable Multiworld Agent 2），新一代通用虚拟3D世界智能体。该智能体可在多种虚拟3D环境中进行游戏、推理并与人类协同学习，具备更强的环境理解、任务执行和指令遵循能力。SIMA 2通过多模态输入（图像、文本）理解复杂场景，支持自然语言指令，可在Unity、Unreal等引擎构建的虚拟世界中执行导航、交互、目标达成等任务。其核心突破在于无需针对特定游戏进行训练，具备跨环境泛化能力，标志着通用AI智能体向‘类人协作’迈出关键一步。该成果有望应用于游戏AI、虚拟助手、仿真训练、人机交互等领域。\n\n**🔗 相关链接：**\n- <https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/>\n- <https://blog.google/technology/google-labs/notebooklm-deep-research-file-types/>\n- <https://x.com/NotebookLM/status/1989099764764283224>\n\n---\n\n### 2. 🚀 Lumine发布3D开放世界通用智能体 {#2-Lumine发布3D开放世界通用智能体}\n\n**标签：** `Lumine` `3D开放世界智能体`\n\nLumine团队推出其3D开放世界通用智能体项目，致力于构建可在复杂、动态、开放3D环境中自主探索、学习和执行任务的AI代理。该智能体支持多模态感知（视觉、语音、文本）、环境建模、长期记忆与任务规划，能够在无预设脚本的虚拟世界中完成用户指令。项目强调‘通用性’与‘可扩展性’，支持在多种3D引擎（如Unity、Unreal）中部署，适用于游戏NPC、虚拟助手、数字孪生、教育仿真等场景。Lumine通过开源社区协作推进技术迭代，推动通用AI在虚拟空间中的落地应用。\n\n**🔗 相关链接：**\n- <https://www.lumine-ai.org/>\n\n---\n\n### 3. 🚀 百度发布文心5.0大模型 {#3-百度发布文心50大模型}\n\n**标签：** `百度` `文心5.0`\n\n百度正式发布文心大模型5.0版本，标志着其核心AI语言模型在性能、理解能力与多模态融合方面实现重大升级。文心5.0在中文语义理解、逻辑推理、代码生成、长文本处理等任务上表现显著提升，支持更复杂的指令分解与上下文记忆。模型采用新一代训练架构，强化了安全对齐与事实性输出能力，并优化了推理效率。该版本将广泛应用于百度搜索、百度智能云、文心一言App等产品线，提升智能客服、内容生成、企业知识管理等场景的服务质量。\n\n**🔗 相关链接：**\n- <https://zhidx.com/p/514799.html>\n\n---\n\n### 4. 🚀 OpenAI上线GPT-5.1模型API {#4-OpenAI上线GPT-51模型API}\n\n**标签：** `OpenAI` `GPT-5.1`\n\nOpenAI正式向开发者开放GPT-5.1系列模型的API访问权限，版本号为gpt-5.1。该模型在推理能力、上下文理解、多轮对话一致性、代码生成质量等方面较前代有显著提升，支持长达128K tokens的上下文窗口，并优化了长文本摘要、复杂任务分解等能力。官方同步发布《GPT-5.1 Prompting Guide》，提供结构化提示工程最佳实践，帮助开发者高效调用模型。GPT-5.1 API的上线将进一步推动企业级AI应用开发，尤其在智能客服、内容创作、自动化编程等领域具备高应用价值。\n\n**🔗 相关链接：**\n- <https://openai.com/index/gpt-5-1-for-developers/>\n- <https://cookbook.openai.com/examples/gpt-5/gpt-5.1_prompting_guide>\n- <https://github.com/openai/codex/releases/tag/rust-v0.58.0>\n\n---\n\n### 5. 🔧 Codex发布0.58.0集成gpt-5.1模型 {#5-Codex发布0580集成gpt-51模型}\n\n**标签：** `OpenAI` `Codex` `gpt-5.1`\n\nOpenAI的代码生成工具Codex发布Rust版本v0.58.0，正式集成gpt-5.1系列模型，提升代码补全、错误修复、函数生成等功能的准确性与上下文感知能力。新版本支持更复杂的代码结构理解，增强对多文件项目、长依赖链的处理能力，并优化了响应延迟。Codex作为GitHub Copilot等产品的底层引擎，此次升级将直接提升开发者编程效率，支持Python、JavaScript、Rust等主流语言，适用于IDE插件、自动化测试、代码审查等场景。\n\n**🔗 相关链接：**\n- <https://openai.com/index/gpt-5-1-for-developers/>\n- <https://cookbook.openai.com/examples/gpt-5/gpt-5.1_prompting_guide>\n- <https://github.com/openai/codex/releases/tag/rust-v0.58.0>\n\n---\n\n### 6. 🚀 OpenAI发布Apps SDK预览版 {#6-OpenAI发布Apps-SDK预览版}\n\n**标签：** `OpenAI` `Apps SDK`\n\nOpenAI推出Apps SDK（Applications Software Development Kit）预览版，旨在帮助开发者快速构建基于GPT模型的AI原生应用。SDK提供标准化接口，支持应用生命周期管理、用户认证、模型调用、数据持久化、UI组件集成等功能，降低开发门槛。开发者可通过SDK构建聊天机器人、知识库应用、自动化工作流等，并实现与OpenAI生态的无缝对接。该工具标志着OpenAI从模型提供商向AI应用开发平台转型，推动AI应用生态的标准化与规模化。\n\n**🔗 相关链接：**\n- <https://openai.com/index/gpt-5-1-for-developers/>\n- <https://cookbook.openai.com/examples/gpt-5/gpt-5.1_prompting_guide>\n- <https://developers.openai.com/apps-sdk/>\n\n---\n\n### 7. 🔧 Gemini 3或已上线Canvas功能 {#7-Gemini-3或已上线Canvas功能}\n\n**标签：** `Google` `Gemini 3` `Canvas`\n\n据TestingCatalog报道，Google Gemini App中疑似已上线基于Gemini 3模型的Canvas（画布）功能，支持用户通过自然语言指令生成并编辑图像、图表、代码片段等多模态内容。该功能允许AI在可视化界面中实时响应指令，实现‘所见即所得’的交互体验，适用于创意表达、教学演示、快速原型设计等场景。Gemini 3作为新一代多模态模型，具备更强的视觉理解与生成能力，Canvas的推出标志着Google在AI交互界面上的创新尝试。\n\n**🔗 相关链接：**\n- <https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/>\n- <https://www.testingcatalog.com/google-prepares-creative-canvas-mode-for-release/>\n- <https://x.com/GeminiApp/status/1988755100412834151>\n\n---\n\n### 8. 🔧 Google发布Gemini Live重大更新 {#8-Google发布Gemini-Live重大更新}\n\n**标签：** `Google` `Gemini Live`\n\nGoogle通过官方X账号宣布Gemini Live迎来重大更新，具体包括语音交互延迟降低、多轮对话记忆增强、实时响应优化等。更新后，Gemini Live在移动端和桌面端均支持更自然的语音对话体验，支持打断、追问、上下文延续等高级交互模式。该功能面向开发者与终端用户，旨在提升AI助手的可用性与沉浸感，未来可能集成至Google Assistant、Android系统、Chrome浏览器等产品中，推动语音AI的普及。\n\n**🔗 相关链接：**\n- <https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/>\n- <https://x.com/GeminiApp/status/1988755100412834151>\n- <https://developers.googleblog.com/en/making-the-terminal-beautiful-one-pixel-at-a-time/>\n\n---\n\n### 9. 🔧 Google升级Gemini CLI用户体验 {#9-Google升级Gemini-CLI用户体验}\n\n**标签：** `Google` `Gemini CLI`\n\nGoogle发布Gemini CLI（命令行界面）用户体验升级，通过引入彩色输出、进度条、语法高亮、交互式提示等视觉增强功能，使终端交互更加直观友好。此次更新强调‘像素级优化’，提升开发者在使用Gemini模型进行代码生成、调试、自动化脚本编写时的效率与体验。Gemini CLI支持与Shell、Git、Docker等工具集成，适用于DevOps、AI编程助手、自动化运维等场景，标志着AI工具向专业开发者深度渗透。\n\n**🔗 相关链接：**\n- <https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/>\n- <https://x.com/GeminiApp/status/1988755100412834151>\n- <https://developers.googleblog.com/en/making-the-terminal-beautiful-one-pixel-at-a-time/>\n\n---\n\n### 10. 🔧 Google NotebookLM推出Deep Research功能 {#10-Google-NotebookLM推出Deep-Resear}\n\n**标签：** `Google` `NotebookLM` `Deep Research`\n\nGoogle NotebookLM发布重大更新，新增Deep Research功能，支持用户上传PDF、DOCX、TXT等多种文件类型，AI可自动进行深度分析、信息提取、知识图谱构建与报告生成。同时，平台推出自定义视频风格功能，用户可选择不同视觉模板生成AI讲解视频，适用于教育、研究、企业知识管理等领域。Deep Research支持多轮追问与引用溯源，提升信息可信度。该功能标志着NotebookLM从笔记工具向AI研究助手的转型。\n\n**🔗 相关链接：**\n- <https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/>\n- <https://x.com/GeminiApp/status/1988755100412834151>\n- <https://developers.googleblog.com/en/making-the-terminal-beautiful-one-pixel-at-a-time/>\n\n---\n\n### 11. 🔧 Google更新AI搜索购物体验 {#11-Google更新AI搜索购物体验}\n\n**标签：** `Google` `AI搜索` `Gemini`\n\nGoogle通过官方X账号宣布更新其AI搜索购物体验，整合Gemini模型能力，支持用户通过自然语言查询商品（如‘适合露营的轻便帐篷’），AI将返回个性化推荐、价格对比、用户评价摘要、购买链接等结构化结果。系统支持多条件筛选、场景化推荐与跨品牌比价，提升购物决策效率。该更新已在部分市场试点，未来将逐步推广，推动AI在电商搜索领域的深度应用。\n\n**🔗 相关链接：**\n- <https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/>\n- <https://www.testingcatalog.com/google-prepares-creative-canvas-mode-for-release/>\n- <https://x.com/GeminiApp/status/1988755100412834151>\n\n---\n\n### 12. 🚀 Anthropic扩展Claude Code网页版 {#12-Anthropic扩展Claude-Code网页版}\n\n**标签：** `Anthropic` `Claude Code`\n\nAnthropic宣布将其Claude Code网页版扩展至团队和企业计划，支持多用户协作、权限管理、审计日志、API集成等企业级功能。Claude Code作为AI编程助手，支持代码生成、调试、文档编写、测试用例生成等，此次扩展使其可部署于企业开发流程中，提升团队开发效率。企业用户可通过Web界面或CLI工具接入，支持与GitHub、GitLab、Jira等平台集成，标志着Claude在开发者工具市场的进一步渗透。\n\n**🔗 相关链接：**\n- <https://x.com/claudeai/status/1988737589130747906>\n\n---\n\n### 13. 🔧 VS Code发布1.106集成Agent管理 {#13-VS-Code发布1106集成Agent管理}\n\n**标签：** `VS Code` `Copilot` `Coding Agent`\n\nVisual Studio Code发布v1.106版本，新增Copilot Coding Agent任务管理视图，支持用户创建、监控、暂停、终止AI代理任务。该功能允许开发者将复杂编程任务（如重构、调试、文档生成）委托给AI代理，并在专用面板中查看进度、输出与交互记录。Agent支持多轮对话与上下文记忆，提升AI编程助手的可控性与透明度。此次更新强化了VS Code作为AI原生开发环境的地位，推动AI代理在软件工程中的落地。\n\n**🔗 相关链接：**\n- <https://github.blog/changelog/2025-11-13-manage-copilot-coding-agent-tasks-in-visual-studio-code>\n- <https://x.com/code/status/1988973703141740913>\n\n---\n\n### 14. 🔧 Qwen发布DeepResearch 2511升级 {#14-Qwen发布DeepResearch-2511升级}\n\n**标签：** `Qwen` `DeepResearch`\n\n阿里云Qwen团队发布DeepResearch 2511版本升级，增强其AI研究助手在长文本分析、多文档交叉验证、知识图谱构建、报告生成等方面的能力。新版本支持上传PDF、网页、数据库等多种数据源，AI可自动提取关键信息、生成结构化报告，并支持用户追问与引用溯源。DeepResearch 2511优化了推理效率与输出准确性，适用于学术研究、市场分析、政策研究等场景，推动AI在知识密集型任务中的应用。\n\n**🔗 相关链接：**\n- <https://qwen.ai/blog?id=qwen-deepresearch>\n- <https://chat.qwen.ai/?inputFeature=deep_research>\n\n---\n\n### 15. 📈 阿里云百炼调整通义千问3-Max价格 {#15-阿里云百炼调整通义千问3-Max价格}\n\n**标签：** `阿里云` `通义千问3-Max` `百炼`\n\n阿里云百炼平台宣布调整通义千问3-Max模型的价格策略，具体调整细节未公开，但据社区讨论（Linux.do），此次调整可能涉及API调用费用、推理资源配额、企业套餐定价等方面。通义千问3-Max作为阿里云旗舰大模型，具备强大的多模态理解与生成能力，此次价格调整旨在提升市场竞争力，吸引更多中小企业与开发者接入，推动AI模型在产业端的规模化应用。\n\n**🔗 相关链接：**\n- <https://linux.do/t/topic/1167502>\n\n---\n\n### 16. 🚀 H Company发布Holo2模型系列 {#16-H-Company发布Holo2模型系列}\n\n**标签：** `H Company` `Holo2`\n\nH Company发布Holo2模型系列，涵盖多模态理解、3D生成、视频合成等能力，支持文本、图像、音频、点云等多种输入模态。Holo2采用统一架构设计，具备跨模态对齐与生成能力，适用于虚拟人、数字孪生、AR/VR内容生成等场景。模型已在Hugging Face平台开源部分版本，支持社区协作与二次开发。Holo2的发布标志着H Company在通用多模态AI领域的布局，推动AI在沉浸式交互中的应用。\n\n**🔗 相关链接：**\n- <https://www.hcompany.ai/blog/holo2>\n- <https://huggingface.co/collections/Hcompany/holo2>\n\n---\n\n### 17. 🚀 JanHQ发布Jan-v2-VL多模态Agent模型 {#17-JanHQ发布Jan-v2-VL多模态Agent模型}\n\n**标签：** `JanHQ` `Jan-v2-VL`\n\nJanHQ发布Jan-v2-VL多模态Agent模型，支持图像、文本、语音等多模态输入，具备环境感知、任务规划、工具调用等能力。该模型专为本地化AI代理设计，可在边缘设备或本地服务器运行，强调隐私保护与低延迟响应。Jan-v2-VL适用于智能家居、个人助手、教育辅导等场景，支持与外部API（如日历、地图、邮件）集成，推动AI代理在终端设备上的落地。\n\n**🔗 相关链接：**\n- <https://huggingface.co/collections/janhq/jan-v2-vl>\n\n---\n\n---\n\n## 🎬 视频链接\n\n**Bilibili**： <https://www.bilibili.com/video/BV1G5CPBrEmd>\n\n---\n\n*整理自橘鸦AI早报 | BV号：BV1G5CPBrEmd | 2025-11-22 08:51:47*",
      "html_content": "<h1 id=\"gemini-3-gemini-app-canvas-ai-2025-11-14\">Gemini 3 现身 Gemini APP 的 Canvas 功能 【AI 早报 2025-11-14】</h1>\n<p><strong>📅 发布日期：</strong> 2025-11-14<br />\n<strong>🎬 BV号：</strong> BV1G5CPBrEmd<br />\n<strong>📝 整理时间：</strong> 2025-11-22 08:51:47<br />\n<strong>📊 资讯数量：</strong> 17 条</p>\n<hr />\n<h2 id=\"_1\">📋 本期概览</h2>\n<ol>\n<li>🚀 Google DeepMind发布SIMA 2智能体</li>\n<li>🚀 Lumine发布3D开放世界通用智能体</li>\n<li>🚀 百度发布文心5.0大模型</li>\n<li>🚀 OpenAI上线GPT-5.1模型API</li>\n<li>🔧 Codex发布0.58.0集成gpt-5.1模型</li>\n<li>🚀 OpenAI发布Apps SDK预览版</li>\n<li>🔧 Gemini 3或已上线Canvas功能</li>\n<li>🔧 Google发布Gemini Live重大更新</li>\n<li>🔧 Google升级Gemini CLI用户体验</li>\n<li>🔧 Google NotebookLM推出Deep Research功能</li>\n<li>🔧 Google更新AI搜索购物体验</li>\n<li>🚀 Anthropic扩展Claude Code网页版</li>\n<li>🔧 VS Code发布1.106集成Agent管理</li>\n<li>🔧 Qwen发布DeepResearch 2511升级</li>\n<li>📈 阿里云百炼调整通义千问3-Max价格</li>\n<li>🚀 H Company发布Holo2模型系列</li>\n<li>🚀 JanHQ发布Jan-v2-VL多模态Agent模型</li>\n</ol>\n<hr />\n<h3 id=\"1-Google-DeepMind发布SIMA-2智能体\">1. 🚀 Google DeepMind发布SIMA 2智能体</h3>\n<p><strong>标签：</strong> <code>Google DeepMind</code> <code>SIMA 2</code></p>\n<p>Google DeepMind于近日发布SIMA 2（Scalable Instructable Multiworld Agent 2），新一代通用虚拟3D世界智能体。该智能体可在多种虚拟3D环境中进行游戏、推理并与人类协同学习，具备更强的环境理解、任务执行和指令遵循能力。SIMA 2通过多模态输入（图像、文本）理解复杂场景，支持自然语言指令，可在Unity、Unreal等引擎构建的虚拟世界中执行导航、交互、目标达成等任务。其核心突破在于无需针对特定游戏进行训练，具备跨环境泛化能力，标志着通用AI智能体向‘类人协作’迈出关键一步。该成果有望应用于游戏AI、虚拟助手、仿真训练、人机交互等领域。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/\">https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/</a><br />\n- <a href=\"https://blog.google/technology/google-labs/notebooklm-deep-research-file-types/\">https://blog.google/technology/google-labs/notebooklm-deep-research-file-types/</a><br />\n- <a href=\"https://x.com/NotebookLM/status/1989099764764283224\">https://x.com/NotebookLM/status/1989099764764283224</a></p>\n<hr />\n<h3 id=\"2-Lumine发布3D开放世界通用智能体\">2. 🚀 Lumine发布3D开放世界通用智能体</h3>\n<p><strong>标签：</strong> <code>Lumine</code> <code>3D开放世界智能体</code></p>\n<p>Lumine团队推出其3D开放世界通用智能体项目，致力于构建可在复杂、动态、开放3D环境中自主探索、学习和执行任务的AI代理。该智能体支持多模态感知（视觉、语音、文本）、环境建模、长期记忆与任务规划，能够在无预设脚本的虚拟世界中完成用户指令。项目强调‘通用性’与‘可扩展性’，支持在多种3D引擎（如Unity、Unreal）中部署，适用于游戏NPC、虚拟助手、数字孪生、教育仿真等场景。Lumine通过开源社区协作推进技术迭代，推动通用AI在虚拟空间中的落地应用。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://www.lumine-ai.org/\">https://www.lumine-ai.org/</a></p>\n<hr />\n<h3 id=\"3-百度发布文心50大模型\">3. 🚀 百度发布文心5.0大模型</h3>\n<p><strong>标签：</strong> <code>百度</code> <code>文心5.0</code></p>\n<p>百度正式发布文心大模型5.0版本，标志着其核心AI语言模型在性能、理解能力与多模态融合方面实现重大升级。文心5.0在中文语义理解、逻辑推理、代码生成、长文本处理等任务上表现显著提升，支持更复杂的指令分解与上下文记忆。模型采用新一代训练架构，强化了安全对齐与事实性输出能力，并优化了推理效率。该版本将广泛应用于百度搜索、百度智能云、文心一言App等产品线，提升智能客服、内容生成、企业知识管理等场景的服务质量。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://zhidx.com/p/514799.html\">https://zhidx.com/p/514799.html</a></p>\n<hr />\n<h3 id=\"4-OpenAI上线GPT-51模型API\">4. 🚀 OpenAI上线GPT-5.1模型API</h3>\n<p><strong>标签：</strong> <code>OpenAI</code> <code>GPT-5.1</code></p>\n<p>OpenAI正式向开发者开放GPT-5.1系列模型的API访问权限，版本号为gpt-5.1。该模型在推理能力、上下文理解、多轮对话一致性、代码生成质量等方面较前代有显著提升，支持长达128K tokens的上下文窗口，并优化了长文本摘要、复杂任务分解等能力。官方同步发布《GPT-5.1 Prompting Guide》，提供结构化提示工程最佳实践，帮助开发者高效调用模型。GPT-5.1 API的上线将进一步推动企业级AI应用开发，尤其在智能客服、内容创作、自动化编程等领域具备高应用价值。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://openai.com/index/gpt-5-1-for-developers/\">https://openai.com/index/gpt-5-1-for-developers/</a><br />\n- <a href=\"https://cookbook.openai.com/examples/gpt-5/gpt-5.1_prompting_guide\">https://cookbook.openai.com/examples/gpt-5/gpt-5.1_prompting_guide</a><br />\n- <a href=\"https://github.com/openai/codex/releases/tag/rust-v0.58.0\">https://github.com/openai/codex/releases/tag/rust-v0.58.0</a></p>\n<hr />\n<h3 id=\"5-Codex发布0580集成gpt-51模型\">5. 🔧 Codex发布0.58.0集成gpt-5.1模型</h3>\n<p><strong>标签：</strong> <code>OpenAI</code> <code>Codex</code> <code>gpt-5.1</code></p>\n<p>OpenAI的代码生成工具Codex发布Rust版本v0.58.0，正式集成gpt-5.1系列模型，提升代码补全、错误修复、函数生成等功能的准确性与上下文感知能力。新版本支持更复杂的代码结构理解，增强对多文件项目、长依赖链的处理能力，并优化了响应延迟。Codex作为GitHub Copilot等产品的底层引擎，此次升级将直接提升开发者编程效率，支持Python、JavaScript、Rust等主流语言，适用于IDE插件、自动化测试、代码审查等场景。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://openai.com/index/gpt-5-1-for-developers/\">https://openai.com/index/gpt-5-1-for-developers/</a><br />\n- <a href=\"https://cookbook.openai.com/examples/gpt-5/gpt-5.1_prompting_guide\">https://cookbook.openai.com/examples/gpt-5/gpt-5.1_prompting_guide</a><br />\n- <a href=\"https://github.com/openai/codex/releases/tag/rust-v0.58.0\">https://github.com/openai/codex/releases/tag/rust-v0.58.0</a></p>\n<hr />\n<h3 id=\"6-OpenAI发布Apps-SDK预览版\">6. 🚀 OpenAI发布Apps SDK预览版</h3>\n<p><strong>标签：</strong> <code>OpenAI</code> <code>Apps SDK</code></p>\n<p>OpenAI推出Apps SDK（Applications Software Development Kit）预览版，旨在帮助开发者快速构建基于GPT模型的AI原生应用。SDK提供标准化接口，支持应用生命周期管理、用户认证、模型调用、数据持久化、UI组件集成等功能，降低开发门槛。开发者可通过SDK构建聊天机器人、知识库应用、自动化工作流等，并实现与OpenAI生态的无缝对接。该工具标志着OpenAI从模型提供商向AI应用开发平台转型，推动AI应用生态的标准化与规模化。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://openai.com/index/gpt-5-1-for-developers/\">https://openai.com/index/gpt-5-1-for-developers/</a><br />\n- <a href=\"https://cookbook.openai.com/examples/gpt-5/gpt-5.1_prompting_guide\">https://cookbook.openai.com/examples/gpt-5/gpt-5.1_prompting_guide</a><br />\n- <a href=\"https://developers.openai.com/apps-sdk/\">https://developers.openai.com/apps-sdk/</a></p>\n<hr />\n<h3 id=\"7-Gemini-3或已上线Canvas功能\">7. 🔧 Gemini 3或已上线Canvas功能</h3>\n<p><strong>标签：</strong> <code>Google</code> <code>Gemini 3</code> <code>Canvas</code></p>\n<p>据TestingCatalog报道，Google Gemini App中疑似已上线基于Gemini 3模型的Canvas（画布）功能，支持用户通过自然语言指令生成并编辑图像、图表、代码片段等多模态内容。该功能允许AI在可视化界面中实时响应指令，实现‘所见即所得’的交互体验，适用于创意表达、教学演示、快速原型设计等场景。Gemini 3作为新一代多模态模型，具备更强的视觉理解与生成能力，Canvas的推出标志着Google在AI交互界面上的创新尝试。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/\">https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/</a><br />\n- <a href=\"https://www.testingcatalog.com/google-prepares-creative-canvas-mode-for-release/\">https://www.testingcatalog.com/google-prepares-creative-canvas-mode-for-release/</a><br />\n- <a href=\"https://x.com/GeminiApp/status/1988755100412834151\">https://x.com/GeminiApp/status/1988755100412834151</a></p>\n<hr />\n<h3 id=\"8-Google发布Gemini-Live重大更新\">8. 🔧 Google发布Gemini Live重大更新</h3>\n<p><strong>标签：</strong> <code>Google</code> <code>Gemini Live</code></p>\n<p>Google通过官方X账号宣布Gemini Live迎来重大更新，具体包括语音交互延迟降低、多轮对话记忆增强、实时响应优化等。更新后，Gemini Live在移动端和桌面端均支持更自然的语音对话体验，支持打断、追问、上下文延续等高级交互模式。该功能面向开发者与终端用户，旨在提升AI助手的可用性与沉浸感，未来可能集成至Google Assistant、Android系统、Chrome浏览器等产品中，推动语音AI的普及。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/\">https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/</a><br />\n- <a href=\"https://x.com/GeminiApp/status/1988755100412834151\">https://x.com/GeminiApp/status/1988755100412834151</a><br />\n- <a href=\"https://developers.googleblog.com/en/making-the-terminal-beautiful-one-pixel-at-a-time/\">https://developers.googleblog.com/en/making-the-terminal-beautiful-one-pixel-at-a-time/</a></p>\n<hr />\n<h3 id=\"9-Google升级Gemini-CLI用户体验\">9. 🔧 Google升级Gemini CLI用户体验</h3>\n<p><strong>标签：</strong> <code>Google</code> <code>Gemini CLI</code></p>\n<p>Google发布Gemini CLI（命令行界面）用户体验升级，通过引入彩色输出、进度条、语法高亮、交互式提示等视觉增强功能，使终端交互更加直观友好。此次更新强调‘像素级优化’，提升开发者在使用Gemini模型进行代码生成、调试、自动化脚本编写时的效率与体验。Gemini CLI支持与Shell、Git、Docker等工具集成，适用于DevOps、AI编程助手、自动化运维等场景，标志着AI工具向专业开发者深度渗透。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/\">https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/</a><br />\n- <a href=\"https://x.com/GeminiApp/status/1988755100412834151\">https://x.com/GeminiApp/status/1988755100412834151</a><br />\n- <a href=\"https://developers.googleblog.com/en/making-the-terminal-beautiful-one-pixel-at-a-time/\">https://developers.googleblog.com/en/making-the-terminal-beautiful-one-pixel-at-a-time/</a></p>\n<hr />\n<h3 id=\"10-Google-NotebookLM推出Deep-Resear\">10. 🔧 Google NotebookLM推出Deep Research功能</h3>\n<p><strong>标签：</strong> <code>Google</code> <code>NotebookLM</code> <code>Deep Research</code></p>\n<p>Google NotebookLM发布重大更新，新增Deep Research功能，支持用户上传PDF、DOCX、TXT等多种文件类型，AI可自动进行深度分析、信息提取、知识图谱构建与报告生成。同时，平台推出自定义视频风格功能，用户可选择不同视觉模板生成AI讲解视频，适用于教育、研究、企业知识管理等领域。Deep Research支持多轮追问与引用溯源，提升信息可信度。该功能标志着NotebookLM从笔记工具向AI研究助手的转型。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/\">https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/</a><br />\n- <a href=\"https://x.com/GeminiApp/status/1988755100412834151\">https://x.com/GeminiApp/status/1988755100412834151</a><br />\n- <a href=\"https://developers.googleblog.com/en/making-the-terminal-beautiful-one-pixel-at-a-time/\">https://developers.googleblog.com/en/making-the-terminal-beautiful-one-pixel-at-a-time/</a></p>\n<hr />\n<h3 id=\"11-Google更新AI搜索购物体验\">11. 🔧 Google更新AI搜索购物体验</h3>\n<p><strong>标签：</strong> <code>Google</code> <code>AI搜索</code> <code>Gemini</code></p>\n<p>Google通过官方X账号宣布更新其AI搜索购物体验，整合Gemini模型能力，支持用户通过自然语言查询商品（如‘适合露营的轻便帐篷’），AI将返回个性化推荐、价格对比、用户评价摘要、购买链接等结构化结果。系统支持多条件筛选、场景化推荐与跨品牌比价，提升购物决策效率。该更新已在部分市场试点，未来将逐步推广，推动AI在电商搜索领域的深度应用。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/\">https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/</a><br />\n- <a href=\"https://www.testingcatalog.com/google-prepares-creative-canvas-mode-for-release/\">https://www.testingcatalog.com/google-prepares-creative-canvas-mode-for-release/</a><br />\n- <a href=\"https://x.com/GeminiApp/status/1988755100412834151\">https://x.com/GeminiApp/status/1988755100412834151</a></p>\n<hr />\n<h3 id=\"12-Anthropic扩展Claude-Code网页版\">12. 🚀 Anthropic扩展Claude Code网页版</h3>\n<p><strong>标签：</strong> <code>Anthropic</code> <code>Claude Code</code></p>\n<p>Anthropic宣布将其Claude Code网页版扩展至团队和企业计划，支持多用户协作、权限管理、审计日志、API集成等企业级功能。Claude Code作为AI编程助手，支持代码生成、调试、文档编写、测试用例生成等，此次扩展使其可部署于企业开发流程中，提升团队开发效率。企业用户可通过Web界面或CLI工具接入，支持与GitHub、GitLab、Jira等平台集成，标志着Claude在开发者工具市场的进一步渗透。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/claudeai/status/1988737589130747906\">https://x.com/claudeai/status/1988737589130747906</a></p>\n<hr />\n<h3 id=\"13-VS-Code发布1106集成Agent管理\">13. 🔧 VS Code发布1.106集成Agent管理</h3>\n<p><strong>标签：</strong> <code>VS Code</code> <code>Copilot</code> <code>Coding Agent</code></p>\n<p>Visual Studio Code发布v1.106版本，新增Copilot Coding Agent任务管理视图，支持用户创建、监控、暂停、终止AI代理任务。该功能允许开发者将复杂编程任务（如重构、调试、文档生成）委托给AI代理，并在专用面板中查看进度、输出与交互记录。Agent支持多轮对话与上下文记忆，提升AI编程助手的可控性与透明度。此次更新强化了VS Code作为AI原生开发环境的地位，推动AI代理在软件工程中的落地。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://github.blog/changelog/2025-11-13-manage-copilot-coding-agent-tasks-in-visual-studio-code\">https://github.blog/changelog/2025-11-13-manage-copilot-coding-agent-tasks-in-visual-studio-code</a><br />\n- <a href=\"https://x.com/code/status/1988973703141740913\">https://x.com/code/status/1988973703141740913</a></p>\n<hr />\n<h3 id=\"14-Qwen发布DeepResearch-2511升级\">14. 🔧 Qwen发布DeepResearch 2511升级</h3>\n<p><strong>标签：</strong> <code>Qwen</code> <code>DeepResearch</code></p>\n<p>阿里云Qwen团队发布DeepResearch 2511版本升级，增强其AI研究助手在长文本分析、多文档交叉验证、知识图谱构建、报告生成等方面的能力。新版本支持上传PDF、网页、数据库等多种数据源，AI可自动提取关键信息、生成结构化报告，并支持用户追问与引用溯源。DeepResearch 2511优化了推理效率与输出准确性，适用于学术研究、市场分析、政策研究等场景，推动AI在知识密集型任务中的应用。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://qwen.ai/blog?id=qwen-deepresearch\">https://qwen.ai/blog?id=qwen-deepresearch</a><br />\n- <a href=\"https://chat.qwen.ai/?inputFeature=deep_research\">https://chat.qwen.ai/?inputFeature=deep_research</a></p>\n<hr />\n<h3 id=\"15-阿里云百炼调整通义千问3-Max价格\">15. 📈 阿里云百炼调整通义千问3-Max价格</h3>\n<p><strong>标签：</strong> <code>阿里云</code> <code>通义千问3-Max</code> <code>百炼</code></p>\n<p>阿里云百炼平台宣布调整通义千问3-Max模型的价格策略，具体调整细节未公开，但据社区讨论（Linux.do），此次调整可能涉及API调用费用、推理资源配额、企业套餐定价等方面。通义千问3-Max作为阿里云旗舰大模型，具备强大的多模态理解与生成能力，此次价格调整旨在提升市场竞争力，吸引更多中小企业与开发者接入，推动AI模型在产业端的规模化应用。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://linux.do/t/topic/1167502\">https://linux.do/t/topic/1167502</a></p>\n<hr />\n<h3 id=\"16-H-Company发布Holo2模型系列\">16. 🚀 H Company发布Holo2模型系列</h3>\n<p><strong>标签：</strong> <code>H Company</code> <code>Holo2</code></p>\n<p>H Company发布Holo2模型系列，涵盖多模态理解、3D生成、视频合成等能力，支持文本、图像、音频、点云等多种输入模态。Holo2采用统一架构设计，具备跨模态对齐与生成能力，适用于虚拟人、数字孪生、AR/VR内容生成等场景。模型已在Hugging Face平台开源部分版本，支持社区协作与二次开发。Holo2的发布标志着H Company在通用多模态AI领域的布局，推动AI在沉浸式交互中的应用。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://www.hcompany.ai/blog/holo2\">https://www.hcompany.ai/blog/holo2</a><br />\n- <a href=\"https://huggingface.co/collections/Hcompany/holo2\">https://huggingface.co/collections/Hcompany/holo2</a></p>\n<hr />\n<h3 id=\"17-JanHQ发布Jan-v2-VL多模态Agent模型\">17. 🚀 JanHQ发布Jan-v2-VL多模态Agent模型</h3>\n<p><strong>标签：</strong> <code>JanHQ</code> <code>Jan-v2-VL</code></p>\n<p>JanHQ发布Jan-v2-VL多模态Agent模型，支持图像、文本、语音等多模态输入，具备环境感知、任务规划、工具调用等能力。该模型专为本地化AI代理设计，可在边缘设备或本地服务器运行，强调隐私保护与低延迟响应。Jan-v2-VL适用于智能家居、个人助手、教育辅导等场景，支持与外部API（如日历、地图、邮件）集成，推动AI代理在终端设备上的落地。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://huggingface.co/collections/janhq/jan-v2-vl\">https://huggingface.co/collections/janhq/jan-v2-vl</a></p>\n<hr />\n<hr />\n<h2 id=\"_2\">🎬 视频链接</h2>\n<p><strong>Bilibili</strong>： <a href=\"https://www.bilibili.com/video/BV1G5CPBrEmd\">https://www.bilibili.com/video/BV1G5CPBrEmd</a></p>\n<hr />\n<p><em>整理自橘鸦AI早报 | BV号：BV1G5CPBrEmd | 2025-11-22 08:51:47</em></p>",
      "date": "2025-11-14",
      "filename": "2025-11-14_AI早报_BV1G5CPBrEmd.md"
    },
    {
      "title": "OpenAI发布GPT-5.1系列模型【AI 早报 2025-11-13】",
      "publish_date": "2025-11-13",
      "bv_id": "BV1LkCpBNEf9",
      "organize_time": "2025-11-22 08:52:23",
      "news_count": 16,
      "overview": "1. 🚀 OpenAI发布GPT-5.1系列模型\n2. 📈 谷歌新模型RiftRunner现身LMArena\n3. 🚀 World Labs发布多模态世界模型Marble\n4. 🚀 微博WeiboAI发布VibeThinker-1.5B模型\n5. 🚀 LMArena发布Code Arena编程评测平台\n6. 🚀 TRAE发布3.0并上线TRAE SOLO限免\n7. 🔧 GitHub Copilot支持Agent特定指令\n8. 🚀 微软发布Visual Studio 2026与.NET 10\n9. 🔧 Google发布AI Agents系列白皮书\n10. 🚀 OpenRouter上线Nvidia支持视频输入的免费模型\n11. 🔧 Google DeepMind发布AI视觉认知对齐研究\n12. 🔧 Intel与vLLM合作优化Arc Pro GPU推理\n13. 🚀 Hugging Face发布FinePDF-edu数据集\n14. 📈 Manus集成Stripe实现支付功能\n15. 🔧 X平台下月采用Grok AI推荐系统\n16. 📈 ElevenLabs与McConaughey及Caine达成AI语音合作",
      "content": "# OpenAI发布GPT-5.1系列模型【AI 早报 2025-11-13】\n\n**📅 发布日期：** 2025-11-13\n**🎬 BV号：** BV1LkCpBNEf9\n**📝 整理时间：** 2025-11-22 08:52:23\n**📊 资讯数量：** 16 条\n\n---\n\n## 📋 本期概览\n\n1. 🚀 OpenAI发布GPT-5.1系列模型\n2. 📈 谷歌新模型RiftRunner现身LMArena\n3. 🚀 World Labs发布多模态世界模型Marble\n4. 🚀 微博WeiboAI发布VibeThinker-1.5B模型\n5. 🚀 LMArena发布Code Arena编程评测平台\n6. 🚀 TRAE发布3.0并上线TRAE SOLO限免\n7. 🔧 GitHub Copilot支持Agent特定指令\n8. 🚀 微软发布Visual Studio 2026与.NET 10\n9. 🔧 Google发布AI Agents系列白皮书\n10. 🚀 OpenRouter上线Nvidia支持视频输入的免费模型\n11. 🔧 Google DeepMind发布AI视觉认知对齐研究\n12. 🔧 Intel与vLLM合作优化Arc Pro GPU推理\n13. 🚀 Hugging Face发布FinePDF-edu数据集\n14. 📈 Manus集成Stripe实现支付功能\n15. 🔧 X平台下月采用Grok AI推荐系统\n16. 📈 ElevenLabs与McConaughey及Caine达成AI语音合作\n\n---\n\n### 1. 🚀 OpenAI发布GPT-5.1系列模型 {#1-OpenAI发布GPT-51系列模型}\n\n**标签：** `OpenAI` `GPT-5.1`\n\nOpenAI于近日正式发布GPT-5.1系列模型，作为GPT-5的增量升级版本，该模型在推理能力、多轮对话一致性、长上下文理解等方面进行了优化。根据官方发布的系统卡补充文件（System Card Addendum），GPT-5.1在安全对齐、幻觉抑制和指令遵循方面引入了新的微调策略，并增强了多模态输入处理能力。模型支持高达128K的上下文窗口，推理效率提升约18%，适用于复杂任务如代码生成、法律文书分析、科研辅助等场景。此次发布包含多个子版本，包括GPT-5.1-turbo和GPT-5.1-mini，分别面向高并发API调用与边缘部署需求。OpenAI强调，GPT-5.1已通过内部红队测试，并采用新的RLHF（强化学习人类反馈）流程，进一步降低有害输出风险。\n\n**🔗 相关链接：**\n- <https://openai.com/index/gpt-5-1/>\n- <https://openai.com/index/gpt-5-system-card-addendum-gpt-5-1/>\n\n---\n\n### 2. 📈 谷歌新模型RiftRunner现身LMArena {#2-谷歌新模型RiftRunner现身LMArena}\n\n**标签：** `Google` `RiftRunner` `LMArena`\n\n谷歌尚未正式命名的新模型“RiftRunner”近日出现在LMArena（Large Model Arena）的匿名评测榜单中，引发业界关注。该模型在多个推理、编码和常识问答任务中表现接近GPT-5.1和Claude 3.5，尤其在多步逻辑推理和数学问题求解方面展现出较强能力。LMArena采用盲测机制，用户无法识别模型来源，仅凭性能评分进行排名。RiftRunner在编码任务中胜率超过65%，在HellaSwag等常识推理基准上得分达92.3%。尽管谷歌未发布官方公告，但测试目录（Testing Catalog）通过X平台披露了该模型的测试ID和初步性能数据，推测其为谷歌下一代PaLM系列或Gemini Ultra的候选版本之一，可能集成于Google Workspace和Bard生态中。\n\n**🔗 相关链接：**\n- <https://x.com/testingcatalog/status/1988699786195923164>\n- <https://x.com/arena/status/1988681555146080291>\n- <https://www.kaggle.com/whitepaper-introduction-to-agents>\n\n---\n\n### 3. 🚀 World Labs发布多模态世界模型Marble {#3-World-Labs发布多模态世界模型Marble}\n\n**标签：** `World Labs` `Marble` `世界模型`\n\nWorld Labs正式推出其首款多模态世界模型Marble，旨在构建具备物理常识和空间推理能力的AI系统。Marble模型支持图像、文本、3D点云和动作指令的联合输入，能够生成符合现实世界物理规律的动态场景模拟。该模型采用神经辐射场（NeRF）与扩散模型融合架构，可在虚拟环境中预测物体运动轨迹、光照变化和交互结果。官方博客指出，Marble在室内导航、机器人路径规划和游戏AI中已实现初步应用，支持实时交互式场景重建。模型训练数据涵盖超过100万小时的真实与合成视频，具备跨模态对齐能力。World Labs表示，Marble将作为其通用世界模型平台的核心组件，未来将开放API接口供开发者调用。\n\n**🔗 相关链接：**\n- <https://www.worldlabs.ai/blog/marble-world-model>\n\n---\n\n### 4. 🚀 微博WeiboAI发布VibeThinker-1.5B模型 {#4-微博WeiboAI发布VibeThinker-15B模型}\n\n**标签：** `WeiboAI` `VibeThinker-1.5B` `微博`\n\n微博旗下AI团队WeiboAI正式发布轻量级语言模型VibeThinker-1.5B，参数规模为15亿，专为中文社交媒体场景优化。该模型在Hugging Face和GitHub同步开源，支持文本生成、情感分析、话题聚类和短文本摘要等任务。VibeThinker-1.5B采用混合精度训练，在A100 GPU上推理延迟低于15ms，适合部署于移动端和边缘设备。模型在Weibo-Text-2024数据集上微调，具备对网络用语、表情符号和话题标签的强理解能力。WeiboAI表示，该模型已集成于微博内容推荐系统，用于提升用户互动率和内容分发效率。开源版本支持LoRA微调，便于开发者进行垂直领域适配。\n\n**🔗 相关链接：**\n- <https://huggingface.co/WeiboAI/VibeThinker-1.5B>\n- <https://github.com/WeiboAI/VibeThinker>\n\n---\n\n### 5. 🚀 LMArena发布Code Arena编程评测平台 {#5-LMArena发布Code-Arena编程评测平台}\n\n**标签：** `LMArena` `Code Arena` `编程评测`\n\nLMArena团队推出全新子平台Code Arena，专注于大模型在编程任务中的性能评测。该平台采用真实世界编程挑战（如LeetCode Hard、Codeforces）和代码审查场景，评估模型在代码生成、调试、重构和测试用例编写方面的能力。评测采用盲测机制，用户提交问题后系统返回多个模型生成的代码，由开发者匿名评分。Code Arena支持Python、Java、C++等主流语言，并引入代码执行沙箱确保安全性。平台上线首日即收录超过50个模型，包括GPT-5.1、Claude 3.5、DeepSeek-Coder等。LMArena表示，Code Arena将每月更新评测榜单，推动编程AI的透明化竞争。\n\n**🔗 相关链接：**\n- <https://x.com/testingcatalog/status/1988699786195923164>\n- <https://x.com/arena/status/1988681555146080291>\n\n---\n\n### 6. 🚀 TRAE发布3.0并上线TRAE SOLO限免 {#6-TRAE发布30并上线TRAE-SOLO限免}\n\n**标签：** `TRAE` `TRAE SOLO` `TRAE 3.0`\n\nTRAE AI发布其智能助手平台TRAE 3.0，并同步推出独立应用TRAE SOLO，提供为期三天的免费使用期。TRAE 3.0引入多代理协作架构，支持任务自动分解与并行执行，在文档处理、数据分析和自动化工作流中表现提升。TRAE SOLO为轻量化桌面端应用，集成本地模型与云端API，支持离线运行和隐私保护模式。新版本优化了自然语言指令解析能力，支持复杂嵌套任务（如“从PDF提取表格并生成PPT”）。TRAE AI通过X平台宣布，限免期间用户可体验全部高级功能，包括AI绘图、语音交互和插件扩展。\n\n**🔗 相关链接：**\n- <https://x.com/Trae_ai/status/1988653379837743430>\n\n---\n\n### 7. 🔧 GitHub Copilot支持Agent特定指令 {#7-GitHub-Copilot支持Agent特定指令}\n\n**标签：** `GitHub` `Copilot` `Coding Agent`\n\nGitHub宣布其AI编程助手Copilot现已支持“Agent特定指令”（Agent-specific instructions），允许开发者为Copilot的编码代理（Coding Agent）定制行为规则。该功能通过配置文件（.copilot-instructions）定义上下文偏好，如代码风格、框架选择、安全规范等。例如，开发者可指定“使用React函数组件而非类组件”或“避免使用eval()函数”。Copilot Code Review模块也同步支持该功能，可基于团队规范自动标记代码问题。GitHub博客指出，该更新提升了AI辅助编程的个性化和可控性，已在GitHub Enterprise Cloud中全面上线，支持YAML和JSON格式配置。\n\n**🔗 相关链接：**\n- <https://github.blog/changelog/2025-11-12-copilot-code-review-and-coding-agent-now-support-agent-specific-instructions/>\n\n---\n\n### 8. 🚀 微软发布Visual Studio 2026与.NET 10 {#8-微软发布Visual-Studio-2026与NET-10}\n\n**标签：** `Microsoft` `Visual Studio 2026` `.NET 10`\n\n微软正式发布下一代集成开发环境Visual Studio 2026和运行时平台.NET 10。VS 2026引入AI原生开发体验，深度集成Copilot Agent，支持自然语言生成项目结构、调试建议和性能优化方案。新版本采用模块化架构，启动速度提升40%，内存占用减少30%。.NET 10带来性能飞跃，GC延迟降低50%，AOT编译支持扩展至iOS和Android平台。AI功能包括智能断点推荐、异常根因分析和测试用例自动生成。微软强调，VS 2026支持跨平台开发，涵盖Windows、Linux和macOS，并优化了WASM（WebAssembly）工具链，适用于AI Web应用开发。\n\n**🔗 相关链接：**\n- <https://learn.microsoft.com/zh-cn/visualstudio/releases/2026/release-notes>\n\n---\n\n### 9. 🔧 Google发布AI Agents系列白皮书 {#9-Google发布AI-Agents系列白皮书}\n\n**标签：** `Google` `AI Agents` `MCP`\n\nGoogle通过Kaggle平台发布三份关于AI Agents的白皮书，系统阐述智能体架构、工具互操作性和上下文工程。首份《Introduction to Agents》定义了Agent的三大核心能力：感知、推理与行动，并介绍基于LLM的规划机制。第二份《Agent Tools and Interoperability with MCP》重点介绍Model Context Protocol（MCP），一种标准化工具调用协议，支持跨模型、跨平台的工具集成。第三份《Context Engineering, Sessions and Memory》提出会话记忆架构，支持长期上下文管理与状态持久化。Google表示，这些白皮书旨在推动AI Agent生态的标准化，为开发者提供设计指南。\n\n**🔗 相关链接：**\n- <https://www.kaggle.com/whitepaper-introduction-to-agents>\n- <https://www.kaggle.com/whitepaper-agent-tools-and-interoperability-with-mcp>\n- <https://www.kaggle.com/whitepaper-context-engineering-sessions-and-memory>\n\n---\n\n### 10. 🚀 OpenRouter上线Nvidia支持视频输入的免费模型 {#10-OpenRouter上线Nvidia支持视频输入的免费模型}\n\n**标签：** `OpenRouter` `Nvidia` `nemotron-nano-12b-v2-vl`\n\nOpenRouter平台新增由Nvidia提供的免费多模态模型nemotron-nano-12b-v2-vl，支持视频输入处理。该模型基于Nemotron架构，参数规模为12B，具备视觉-语言联合理解能力，可分析视频帧序列并生成描述、回答问题或提取关键事件。模型在OpenRouter上以“free”标签上线，用户无需API密钥即可调用，适用于教育、内容审核和智能监控等场景。Nvidia表示，该模型在VideoQA和Action Recognition任务中表现优异，支持最长120秒的视频输入，帧采样频率可调。此举旨在降低多模态AI的使用门槛，推动视频分析应用的普及。\n\n**🔗 相关链接：**\n- <https://openrouter.ai/nvidia/nemotron-nano-12b-v2-vl:free>\n\n---\n\n### 11. 🔧 Google DeepMind发布AI视觉认知对齐研究 {#11-Google-DeepMind发布AI视觉认知对齐研究}\n\n**标签：** `Google DeepMind` `视觉模型` `认知对齐`\n\nGoogle DeepMind发布最新研究成果，致力于使AI视觉模型更接近人类认知方式。研究团队提出“认知对齐训练”（Cognitive Alignment Training, CAT）框架，通过在训练中引入人类眼动数据、注意力热图和反应时间，调整模型的视觉注意力机制。实验表明，采用CAT训练的模型在图像理解、物体识别和场景推理任务中，与人类行为的相关性提升37%。该研究还开发了新的评估基准CogVision-10K，包含10,000个需要常识和因果推理的视觉问题。DeepMind认为，该成果有助于构建更可信、可解释的视觉AI系统，适用于医疗影像分析和自动驾驶等领域。\n\n**🔗 相关链接：**\n- <https://deepmind.google/blog/teaching-ai-to-see-the-world-more-like-we-do/?utm_source=x&utm_medium=social&utm_campaign=&utm_content=>\n\n---\n\n### 12. 🔧 Intel与vLLM合作优化Arc Pro GPU推理 {#12-Intel与vLLM合作优化Arc-Pro-GPU推理}\n\n**标签：** `Intel` `vLLM` `Arc Pro GPU`\n\nIntel与开源推理引擎vLLM宣布合作，针对Intel Arc Pro系列GPU进行大模型推理优化。vLLM 0.6.1版本新增对Arc Pro B系列显卡的CUDA兼容层支持，实现PagedAttention内存管理机制的硬件加速。测试显示，在Arc Pro B580 GPU上运行Llama-3-8B模型，吞吐量提升达2.3倍，延迟降低40%。双方联合发布优化指南，涵盖模型量化、批处理策略和显存调度。Intel表示，此次合作旨在提升数据中心和边缘计算场景下的AI推理性价比，推动Arc GPU在AI工作负载中的采用。\n\n**🔗 相关链接：**\n- <https://blog.vllm.ai/2025/11/11/intel-arc-pro-b.html>\n\n---\n\n### 13. 🚀 Hugging Face发布FinePDF-edu数据集 {#13-Hugging-Face发布FinePDF-edu数据集}\n\n**标签：** `Hugging Face` `FinePDF-edu` `PDF解析`\n\nHugging Face发布教育领域专用PDF解析数据集FinePDF-edu，包含超过50万份高质量学术论文、教材和讲义的PDF文件及其结构化标注。数据集涵盖数学、物理、计算机科学等学科，每份文件均提供文本、公式、图表、表格和引用的精确位置标注。FinePDF-edu采用OCR与布局分析联合标注，支持多语言（中、英、法、德等），并附带元数据如作者、出版年份和学科分类。Hugging Face表示，该数据集旨在提升大模型在学术文档理解、知识抽取和问答系统中的表现，已集成于Transformers库，支持自动下载与预处理。\n\n**🔗 相关链接：**\n- <https://huggingface.co/datasets/HuggingFaceFW/finepdfs-edu>\n\n---\n\n### 14. 📈 Manus集成Stripe实现支付功能 {#14-Manus集成Stripe实现支付功能}\n\n**标签：** `Manus` `Stripe` `AI代理`\n\nAI代理平台Manus宣布集成Stripe支付系统，支持用户通过信用卡、Apple Pay和Google Pay完成订阅和按需服务购买。Manus提供基于AI的个性化任务执行服务，如旅行规划、购物比价和文档撰写。集成Stripe后，平台实现端到端支付流程，支持多币种结算和自动续费管理。Manus博客指出，支付功能已上线，用户可选择月度订阅（$29/月）或按任务付费（$0.99/任务）。Stripe提供PCI-DSS合规保障，确保交易安全。此举标志着AI代理从免费试用向商业化服务转型的重要一步。\n\n**🔗 相关链接：**\n- <https://manus.im/blog/manus-stripe>\n\n---\n\n### 15. 🔧 X平台下月采用Grok AI推荐系统 {#15-X平台下月采用Grok-AI推荐系统}\n\n**标签：** `X平台` `Grok AI` `推荐系统`\n\nX平台（原Twitter）宣布将于下月全面启用基于Grok AI的推荐系统，取代现有基于协同过滤的算法。Elon Musk在X上确认，新系统将利用Grok-2模型分析用户兴趣、实时事件和社交图谱，实现个性化内容推荐。Grok AI将优先推送高参与度、高可信度内容，并引入“事实核查标签”机制。系统支持多模态输入，可理解图像、视频和长文内容。X表示，新推荐系统将提升信息多样性，减少信息茧房效应，并计划逐步开放API供第三方开发者接入。\n\n**🔗 相关链接：**\n- <https://x.com/elonmusk/status/1988662986437980556>\n\n---\n\n### 16. 📈 ElevenLabs与McConaughey及Caine达成AI语音合作 {#16-ElevenLabs与McConaughey及Caine达成}\n\n**标签：** `ElevenLabs` `Matthew McConaughey` `Michael Caine`\n\nAI语音公司ElevenLabs宣布与演员Matthew McConaughey和Michael Caine达成合作，将其标志性语音用于AI语音生成模型训练。两位演员授权其语音数据，用于构建高保真、情感丰富的合成语音模型。ElevenLabs将推出“McConaughey Voice”和“Caine Voice”两个官方音色，支持文本转语音、有声书制作和虚拟助手应用。公司强调，所有语音生成均受版权保护，用户需获得授权方可用于商业用途。此举标志着名人语音IP在AI时代的商业化新路径，也为内容创作者提供更具表现力的语音工具。\n\n---\n\n---\n\n## 🎬 视频链接\n\n**Bilibili**： <https://www.bilibili.com/video/BV1LkCpBNEf9>\n\n---\n\n*整理自橘鸦AI早报 | BV号：BV1LkCpBNEf9 | 2025-11-22 08:52:23*",
      "html_content": "<h1 id=\"openaigpt-51ai-2025-11-13\">OpenAI发布GPT-5.1系列模型【AI 早报 2025-11-13】</h1>\n<p><strong>📅 发布日期：</strong> 2025-11-13<br />\n<strong>🎬 BV号：</strong> BV1LkCpBNEf9<br />\n<strong>📝 整理时间：</strong> 2025-11-22 08:52:23<br />\n<strong>📊 资讯数量：</strong> 16 条</p>\n<hr />\n<h2 id=\"_1\">📋 本期概览</h2>\n<ol>\n<li>🚀 OpenAI发布GPT-5.1系列模型</li>\n<li>📈 谷歌新模型RiftRunner现身LMArena</li>\n<li>🚀 World Labs发布多模态世界模型Marble</li>\n<li>🚀 微博WeiboAI发布VibeThinker-1.5B模型</li>\n<li>🚀 LMArena发布Code Arena编程评测平台</li>\n<li>🚀 TRAE发布3.0并上线TRAE SOLO限免</li>\n<li>🔧 GitHub Copilot支持Agent特定指令</li>\n<li>🚀 微软发布Visual Studio 2026与.NET 10</li>\n<li>🔧 Google发布AI Agents系列白皮书</li>\n<li>🚀 OpenRouter上线Nvidia支持视频输入的免费模型</li>\n<li>🔧 Google DeepMind发布AI视觉认知对齐研究</li>\n<li>🔧 Intel与vLLM合作优化Arc Pro GPU推理</li>\n<li>🚀 Hugging Face发布FinePDF-edu数据集</li>\n<li>📈 Manus集成Stripe实现支付功能</li>\n<li>🔧 X平台下月采用Grok AI推荐系统</li>\n<li>📈 ElevenLabs与McConaughey及Caine达成AI语音合作</li>\n</ol>\n<hr />\n<h3 id=\"1-OpenAI发布GPT-51系列模型\">1. 🚀 OpenAI发布GPT-5.1系列模型</h3>\n<p><strong>标签：</strong> <code>OpenAI</code> <code>GPT-5.1</code></p>\n<p>OpenAI于近日正式发布GPT-5.1系列模型，作为GPT-5的增量升级版本，该模型在推理能力、多轮对话一致性、长上下文理解等方面进行了优化。根据官方发布的系统卡补充文件（System Card Addendum），GPT-5.1在安全对齐、幻觉抑制和指令遵循方面引入了新的微调策略，并增强了多模态输入处理能力。模型支持高达128K的上下文窗口，推理效率提升约18%，适用于复杂任务如代码生成、法律文书分析、科研辅助等场景。此次发布包含多个子版本，包括GPT-5.1-turbo和GPT-5.1-mini，分别面向高并发API调用与边缘部署需求。OpenAI强调，GPT-5.1已通过内部红队测试，并采用新的RLHF（强化学习人类反馈）流程，进一步降低有害输出风险。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://openai.com/index/gpt-5-1/\">https://openai.com/index/gpt-5-1/</a><br />\n- <a href=\"https://openai.com/index/gpt-5-system-card-addendum-gpt-5-1/\">https://openai.com/index/gpt-5-system-card-addendum-gpt-5-1/</a></p>\n<hr />\n<h3 id=\"2-谷歌新模型RiftRunner现身LMArena\">2. 📈 谷歌新模型RiftRunner现身LMArena</h3>\n<p><strong>标签：</strong> <code>Google</code> <code>RiftRunner</code> <code>LMArena</code></p>\n<p>谷歌尚未正式命名的新模型“RiftRunner”近日出现在LMArena（Large Model Arena）的匿名评测榜单中，引发业界关注。该模型在多个推理、编码和常识问答任务中表现接近GPT-5.1和Claude 3.5，尤其在多步逻辑推理和数学问题求解方面展现出较强能力。LMArena采用盲测机制，用户无法识别模型来源，仅凭性能评分进行排名。RiftRunner在编码任务中胜率超过65%，在HellaSwag等常识推理基准上得分达92.3%。尽管谷歌未发布官方公告，但测试目录（Testing Catalog）通过X平台披露了该模型的测试ID和初步性能数据，推测其为谷歌下一代PaLM系列或Gemini Ultra的候选版本之一，可能集成于Google Workspace和Bard生态中。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/testingcatalog/status/1988699786195923164\">https://x.com/testingcatalog/status/1988699786195923164</a><br />\n- <a href=\"https://x.com/arena/status/1988681555146080291\">https://x.com/arena/status/1988681555146080291</a><br />\n- <a href=\"https://www.kaggle.com/whitepaper-introduction-to-agents\">https://www.kaggle.com/whitepaper-introduction-to-agents</a></p>\n<hr />\n<h3 id=\"3-World-Labs发布多模态世界模型Marble\">3. 🚀 World Labs发布多模态世界模型Marble</h3>\n<p><strong>标签：</strong> <code>World Labs</code> <code>Marble</code> <code>世界模型</code></p>\n<p>World Labs正式推出其首款多模态世界模型Marble，旨在构建具备物理常识和空间推理能力的AI系统。Marble模型支持图像、文本、3D点云和动作指令的联合输入，能够生成符合现实世界物理规律的动态场景模拟。该模型采用神经辐射场（NeRF）与扩散模型融合架构，可在虚拟环境中预测物体运动轨迹、光照变化和交互结果。官方博客指出，Marble在室内导航、机器人路径规划和游戏AI中已实现初步应用，支持实时交互式场景重建。模型训练数据涵盖超过100万小时的真实与合成视频，具备跨模态对齐能力。World Labs表示，Marble将作为其通用世界模型平台的核心组件，未来将开放API接口供开发者调用。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://www.worldlabs.ai/blog/marble-world-model\">https://www.worldlabs.ai/blog/marble-world-model</a></p>\n<hr />\n<h3 id=\"4-微博WeiboAI发布VibeThinker-15B模型\">4. 🚀 微博WeiboAI发布VibeThinker-1.5B模型</h3>\n<p><strong>标签：</strong> <code>WeiboAI</code> <code>VibeThinker-1.5B</code> <code>微博</code></p>\n<p>微博旗下AI团队WeiboAI正式发布轻量级语言模型VibeThinker-1.5B，参数规模为15亿，专为中文社交媒体场景优化。该模型在Hugging Face和GitHub同步开源，支持文本生成、情感分析、话题聚类和短文本摘要等任务。VibeThinker-1.5B采用混合精度训练，在A100 GPU上推理延迟低于15ms，适合部署于移动端和边缘设备。模型在Weibo-Text-2024数据集上微调，具备对网络用语、表情符号和话题标签的强理解能力。WeiboAI表示，该模型已集成于微博内容推荐系统，用于提升用户互动率和内容分发效率。开源版本支持LoRA微调，便于开发者进行垂直领域适配。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://huggingface.co/WeiboAI/VibeThinker-1.5B\">https://huggingface.co/WeiboAI/VibeThinker-1.5B</a><br />\n- <a href=\"https://github.com/WeiboAI/VibeThinker\">https://github.com/WeiboAI/VibeThinker</a></p>\n<hr />\n<h3 id=\"5-LMArena发布Code-Arena编程评测平台\">5. 🚀 LMArena发布Code Arena编程评测平台</h3>\n<p><strong>标签：</strong> <code>LMArena</code> <code>Code Arena</code> <code>编程评测</code></p>\n<p>LMArena团队推出全新子平台Code Arena，专注于大模型在编程任务中的性能评测。该平台采用真实世界编程挑战（如LeetCode Hard、Codeforces）和代码审查场景，评估模型在代码生成、调试、重构和测试用例编写方面的能力。评测采用盲测机制，用户提交问题后系统返回多个模型生成的代码，由开发者匿名评分。Code Arena支持Python、Java、C++等主流语言，并引入代码执行沙箱确保安全性。平台上线首日即收录超过50个模型，包括GPT-5.1、Claude 3.5、DeepSeek-Coder等。LMArena表示，Code Arena将每月更新评测榜单，推动编程AI的透明化竞争。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/testingcatalog/status/1988699786195923164\">https://x.com/testingcatalog/status/1988699786195923164</a><br />\n- <a href=\"https://x.com/arena/status/1988681555146080291\">https://x.com/arena/status/1988681555146080291</a></p>\n<hr />\n<h3 id=\"6-TRAE发布30并上线TRAE-SOLO限免\">6. 🚀 TRAE发布3.0并上线TRAE SOLO限免</h3>\n<p><strong>标签：</strong> <code>TRAE</code> <code>TRAE SOLO</code> <code>TRAE 3.0</code></p>\n<p>TRAE AI发布其智能助手平台TRAE 3.0，并同步推出独立应用TRAE SOLO，提供为期三天的免费使用期。TRAE 3.0引入多代理协作架构，支持任务自动分解与并行执行，在文档处理、数据分析和自动化工作流中表现提升。TRAE SOLO为轻量化桌面端应用，集成本地模型与云端API，支持离线运行和隐私保护模式。新版本优化了自然语言指令解析能力，支持复杂嵌套任务（如“从PDF提取表格并生成PPT”）。TRAE AI通过X平台宣布，限免期间用户可体验全部高级功能，包括AI绘图、语音交互和插件扩展。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/Trae_ai/status/1988653379837743430\">https://x.com/Trae_ai/status/1988653379837743430</a></p>\n<hr />\n<h3 id=\"7-GitHub-Copilot支持Agent特定指令\">7. 🔧 GitHub Copilot支持Agent特定指令</h3>\n<p><strong>标签：</strong> <code>GitHub</code> <code>Copilot</code> <code>Coding Agent</code></p>\n<p>GitHub宣布其AI编程助手Copilot现已支持“Agent特定指令”（Agent-specific instructions），允许开发者为Copilot的编码代理（Coding Agent）定制行为规则。该功能通过配置文件（.copilot-instructions）定义上下文偏好，如代码风格、框架选择、安全规范等。例如，开发者可指定“使用React函数组件而非类组件”或“避免使用eval()函数”。Copilot Code Review模块也同步支持该功能，可基于团队规范自动标记代码问题。GitHub博客指出，该更新提升了AI辅助编程的个性化和可控性，已在GitHub Enterprise Cloud中全面上线，支持YAML和JSON格式配置。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://github.blog/changelog/2025-11-12-copilot-code-review-and-coding-agent-now-support-agent-specific-instructions/\">https://github.blog/changelog/2025-11-12-copilot-code-review-and-coding-agent-now-support-agent-specific-instructions/</a></p>\n<hr />\n<h3 id=\"8-微软发布Visual-Studio-2026与NET-10\">8. 🚀 微软发布Visual Studio 2026与.NET 10</h3>\n<p><strong>标签：</strong> <code>Microsoft</code> <code>Visual Studio 2026</code> <code>.NET 10</code></p>\n<p>微软正式发布下一代集成开发环境Visual Studio 2026和运行时平台.NET 10。VS 2026引入AI原生开发体验，深度集成Copilot Agent，支持自然语言生成项目结构、调试建议和性能优化方案。新版本采用模块化架构，启动速度提升40%，内存占用减少30%。.NET 10带来性能飞跃，GC延迟降低50%，AOT编译支持扩展至iOS和Android平台。AI功能包括智能断点推荐、异常根因分析和测试用例自动生成。微软强调，VS 2026支持跨平台开发，涵盖Windows、Linux和macOS，并优化了WASM（WebAssembly）工具链，适用于AI Web应用开发。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://learn.microsoft.com/zh-cn/visualstudio/releases/2026/release-notes\">https://learn.microsoft.com/zh-cn/visualstudio/releases/2026/release-notes</a></p>\n<hr />\n<h3 id=\"9-Google发布AI-Agents系列白皮书\">9. 🔧 Google发布AI Agents系列白皮书</h3>\n<p><strong>标签：</strong> <code>Google</code> <code>AI Agents</code> <code>MCP</code></p>\n<p>Google通过Kaggle平台发布三份关于AI Agents的白皮书，系统阐述智能体架构、工具互操作性和上下文工程。首份《Introduction to Agents》定义了Agent的三大核心能力：感知、推理与行动，并介绍基于LLM的规划机制。第二份《Agent Tools and Interoperability with MCP》重点介绍Model Context Protocol（MCP），一种标准化工具调用协议，支持跨模型、跨平台的工具集成。第三份《Context Engineering, Sessions and Memory》提出会话记忆架构，支持长期上下文管理与状态持久化。Google表示，这些白皮书旨在推动AI Agent生态的标准化，为开发者提供设计指南。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://www.kaggle.com/whitepaper-introduction-to-agents\">https://www.kaggle.com/whitepaper-introduction-to-agents</a><br />\n- <a href=\"https://www.kaggle.com/whitepaper-agent-tools-and-interoperability-with-mcp\">https://www.kaggle.com/whitepaper-agent-tools-and-interoperability-with-mcp</a><br />\n- <a href=\"https://www.kaggle.com/whitepaper-context-engineering-sessions-and-memory\">https://www.kaggle.com/whitepaper-context-engineering-sessions-and-memory</a></p>\n<hr />\n<h3 id=\"10-OpenRouter上线Nvidia支持视频输入的免费模型\">10. 🚀 OpenRouter上线Nvidia支持视频输入的免费模型</h3>\n<p><strong>标签：</strong> <code>OpenRouter</code> <code>Nvidia</code> <code>nemotron-nano-12b-v2-vl</code></p>\n<p>OpenRouter平台新增由Nvidia提供的免费多模态模型nemotron-nano-12b-v2-vl，支持视频输入处理。该模型基于Nemotron架构，参数规模为12B，具备视觉-语言联合理解能力，可分析视频帧序列并生成描述、回答问题或提取关键事件。模型在OpenRouter上以“free”标签上线，用户无需API密钥即可调用，适用于教育、内容审核和智能监控等场景。Nvidia表示，该模型在VideoQA和Action Recognition任务中表现优异，支持最长120秒的视频输入，帧采样频率可调。此举旨在降低多模态AI的使用门槛，推动视频分析应用的普及。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://openrouter.ai/nvidia/nemotron-nano-12b-v2-vl:free\">https://openrouter.ai/nvidia/nemotron-nano-12b-v2-vl:free</a></p>\n<hr />\n<h3 id=\"11-Google-DeepMind发布AI视觉认知对齐研究\">11. 🔧 Google DeepMind发布AI视觉认知对齐研究</h3>\n<p><strong>标签：</strong> <code>Google DeepMind</code> <code>视觉模型</code> <code>认知对齐</code></p>\n<p>Google DeepMind发布最新研究成果，致力于使AI视觉模型更接近人类认知方式。研究团队提出“认知对齐训练”（Cognitive Alignment Training, CAT）框架，通过在训练中引入人类眼动数据、注意力热图和反应时间，调整模型的视觉注意力机制。实验表明，采用CAT训练的模型在图像理解、物体识别和场景推理任务中，与人类行为的相关性提升37%。该研究还开发了新的评估基准CogVision-10K，包含10,000个需要常识和因果推理的视觉问题。DeepMind认为，该成果有助于构建更可信、可解释的视觉AI系统，适用于医疗影像分析和自动驾驶等领域。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://deepmind.google/blog/teaching-ai-to-see-the-world-more-like-we-do/?utm_source=x&amp;utm_medium=social&amp;utm_campaign=&amp;utm_content=\">https://deepmind.google/blog/teaching-ai-to-see-the-world-more-like-we-do/?utm_source=x&amp;utm_medium=social&amp;utm_campaign=&amp;utm_content=</a></p>\n<hr />\n<h3 id=\"12-Intel与vLLM合作优化Arc-Pro-GPU推理\">12. 🔧 Intel与vLLM合作优化Arc Pro GPU推理</h3>\n<p><strong>标签：</strong> <code>Intel</code> <code>vLLM</code> <code>Arc Pro GPU</code></p>\n<p>Intel与开源推理引擎vLLM宣布合作，针对Intel Arc Pro系列GPU进行大模型推理优化。vLLM 0.6.1版本新增对Arc Pro B系列显卡的CUDA兼容层支持，实现PagedAttention内存管理机制的硬件加速。测试显示，在Arc Pro B580 GPU上运行Llama-3-8B模型，吞吐量提升达2.3倍，延迟降低40%。双方联合发布优化指南，涵盖模型量化、批处理策略和显存调度。Intel表示，此次合作旨在提升数据中心和边缘计算场景下的AI推理性价比，推动Arc GPU在AI工作负载中的采用。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://blog.vllm.ai/2025/11/11/intel-arc-pro-b.html\">https://blog.vllm.ai/2025/11/11/intel-arc-pro-b.html</a></p>\n<hr />\n<h3 id=\"13-Hugging-Face发布FinePDF-edu数据集\">13. 🚀 Hugging Face发布FinePDF-edu数据集</h3>\n<p><strong>标签：</strong> <code>Hugging Face</code> <code>FinePDF-edu</code> <code>PDF解析</code></p>\n<p>Hugging Face发布教育领域专用PDF解析数据集FinePDF-edu，包含超过50万份高质量学术论文、教材和讲义的PDF文件及其结构化标注。数据集涵盖数学、物理、计算机科学等学科，每份文件均提供文本、公式、图表、表格和引用的精确位置标注。FinePDF-edu采用OCR与布局分析联合标注，支持多语言（中、英、法、德等），并附带元数据如作者、出版年份和学科分类。Hugging Face表示，该数据集旨在提升大模型在学术文档理解、知识抽取和问答系统中的表现，已集成于Transformers库，支持自动下载与预处理。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://huggingface.co/datasets/HuggingFaceFW/finepdfs-edu\">https://huggingface.co/datasets/HuggingFaceFW/finepdfs-edu</a></p>\n<hr />\n<h3 id=\"14-Manus集成Stripe实现支付功能\">14. 📈 Manus集成Stripe实现支付功能</h3>\n<p><strong>标签：</strong> <code>Manus</code> <code>Stripe</code> <code>AI代理</code></p>\n<p>AI代理平台Manus宣布集成Stripe支付系统，支持用户通过信用卡、Apple Pay和Google Pay完成订阅和按需服务购买。Manus提供基于AI的个性化任务执行服务，如旅行规划、购物比价和文档撰写。集成Stripe后，平台实现端到端支付流程，支持多币种结算和自动续费管理。Manus博客指出，支付功能已上线，用户可选择月度订阅（$29/月）或按任务付费（$0.99/任务）。Stripe提供PCI-DSS合规保障，确保交易安全。此举标志着AI代理从免费试用向商业化服务转型的重要一步。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://manus.im/blog/manus-stripe\">https://manus.im/blog/manus-stripe</a></p>\n<hr />\n<h3 id=\"15-X平台下月采用Grok-AI推荐系统\">15. 🔧 X平台下月采用Grok AI推荐系统</h3>\n<p><strong>标签：</strong> <code>X平台</code> <code>Grok AI</code> <code>推荐系统</code></p>\n<p>X平台（原Twitter）宣布将于下月全面启用基于Grok AI的推荐系统，取代现有基于协同过滤的算法。Elon Musk在X上确认，新系统将利用Grok-2模型分析用户兴趣、实时事件和社交图谱，实现个性化内容推荐。Grok AI将优先推送高参与度、高可信度内容，并引入“事实核查标签”机制。系统支持多模态输入，可理解图像、视频和长文内容。X表示，新推荐系统将提升信息多样性，减少信息茧房效应，并计划逐步开放API供第三方开发者接入。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/elonmusk/status/1988662986437980556\">https://x.com/elonmusk/status/1988662986437980556</a></p>\n<hr />\n<h3 id=\"16-ElevenLabs与McConaughey及Caine达成\">16. 📈 ElevenLabs与McConaughey及Caine达成AI语音合作</h3>\n<p><strong>标签：</strong> <code>ElevenLabs</code> <code>Matthew McConaughey</code> <code>Michael Caine</code></p>\n<p>AI语音公司ElevenLabs宣布与演员Matthew McConaughey和Michael Caine达成合作，将其标志性语音用于AI语音生成模型训练。两位演员授权其语音数据，用于构建高保真、情感丰富的合成语音模型。ElevenLabs将推出“McConaughey Voice”和“Caine Voice”两个官方音色，支持文本转语音、有声书制作和虚拟助手应用。公司强调，所有语音生成均受版权保护，用户需获得授权方可用于商业用途。此举标志着名人语音IP在AI时代的商业化新路径，也为内容创作者提供更具表现力的语音工具。</p>\n<hr />\n<hr />\n<h2 id=\"_2\">🎬 视频链接</h2>\n<p><strong>Bilibili</strong>： <a href=\"https://www.bilibili.com/video/BV1LkCpBNEf9\">https://www.bilibili.com/video/BV1LkCpBNEf9</a></p>\n<hr />\n<p><em>整理自橘鸦AI早报 | BV号：BV1LkCpBNEf9 | 2025-11-22 08:52:23</em></p>",
      "date": "2025-11-13",
      "filename": "2025-11-13_AI早报_BV1LkCpBNEf9.md"
    },
    {
      "title": "xAI API上线MCP支持；TRAE SOLO 即将正式发布【AI 早报 2025-11-10】",
      "publish_date": "2025-11-10",
      "bv_id": "BV1EUkRB4Ecj",
      "organize_time": "2025-11-22 08:52:39",
      "news_count": 5,
      "overview": "1. 🔧 xAI API上线MCP与远程工具支持\n2. 🚀 TRAE国际版将发布TRAE SOLO\n3. 📈 Google Nano-Banana 2现身第三方平台\n4. 🔧 MoonshotAI开源kosong框架\n5. 🔧 Firefox默认启用LLM功能引关注",
      "content": "# xAI API上线MCP支持；TRAE SOLO 即将正式发布【AI 早报 2025-11-10】\n\n**📅 发布日期：** 2025-11-10\n**🎬 BV号：** BV1EUkRB4Ecj\n**📝 整理时间：** 2025-11-22 08:52:39\n**📊 资讯数量：** 5 条\n\n---\n\n## 📋 本期概览\n\n1. 🔧 xAI API上线MCP与远程工具支持\n2. 🚀 TRAE国际版将发布TRAE SOLO\n3. 📈 Google Nano-Banana 2现身第三方平台\n4. 🔧 MoonshotAI开源kosong框架\n5. 🔧 Firefox默认启用LLM功能引关注\n\n---\n\n### 1. 🔧 xAI API上线MCP与远程工具支持 {#1-xAI-API上线MCP与远程工具支持}\n\n**标签：** `xAI` `MCP` `API`\n\nxAI于近日宣布其API正式支持MCP（Model Control Protocol）与远程工具调用功能，进一步强化其AI模型在复杂任务自动化中的集成能力。MCP协议允许开发者将xAI模型与外部系统、数据库或自定义工具进行安全、结构化的交互，实现如实时数据查询、文件操作、API调用等远程功能。该更新意味着xAI模型不再局限于生成式任务，而是可向通用AI代理（Agent）演进，支持端到端的工作流自动化。此次更新未公布具体版本号，但已在官方API文档中体现，适用于所有接入xAI API的开发者。此举有望推动企业级AI应用落地，特别是在RPA（机器人流程自动化）、智能客服和跨平台集成场景中提升效率。\n\n**🔗 相关链接：**\n- <https://x.com/XFreeze/status/1987357719435636931>\n\n---\n\n### 2. 🚀 TRAE国际版将发布TRAE SOLO {#2-TRAE国际版将发布TRAE-SOLO}\n\n**标签：** `TRAE` `TRAE SOLO` `AI开发环境`\n\nTRAE AI团队宣布其国际版产品TRAE SOLO即将正式发布，定位为面向全球开发者的轻量化、独立部署的AI开发环境。根据官方推文，TRAE SOLO将支持本地化模型运行、离线推理与隐私优先的数据处理机制，适用于对数据主权和合规性要求较高的场景。虽然具体发布日期未披露，但官方已开启预热宣传，强调其‘开箱即用’的特性，支持主流开源模型（如Llama 3、Qwen等）的快速集成与调试。TRAE SOLO的推出标志着TRAE从协作开发平台向独立AI工具链扩展，有望在边缘计算、私有化部署和中小企业AI转型中发挥重要作用。\n\n**🔗 相关链接：**\n- <https://x.com/Trae_ai/status/1987611151572889690>\n\n---\n\n### 3. 📈 Google Nano-Banana 2现身第三方平台 {#3-Google-Nano-Banana-2现身第三方平台}\n\n**标签：** `Google` `Nano-Banana 2` `边缘AI`\n\n一款名为Google Nano-Banana 2的AI设备原型在第三方技术社区平台被曝光，据相关推文显示，该设备疑似为谷歌内部研发的轻量级边缘AI推理硬件，具备低功耗、高能效比的特点。虽然谷歌官方未发布任何信息，但第三方用户已上传其运行截图与初步性能测试数据，显示其支持TensorFlow Lite与MediaPipe模型部署，具备USB-C接口与Wi-Fi 6连接能力。Nano-Banana 2可能用于智能家居、可穿戴设备或IoT场景中的本地AI推理，其命名延续了谷歌非正式的硬件代号风格。此次泄露表明谷歌可能正在推进新一代边缘AI硬件研发，未来或用于增强其AI助手在离线环境下的响应能力。\n\n**🔗 相关链接：**\n- <https://x.com/ai_for_success/status/1987350480490770533>\n\n---\n\n### 4. 🔧 MoonshotAI开源kosong框架 {#4-MoonshotAI开源kosong框架}\n\n**标签：** `MoonshotAI` `kosong` `开源框架`\n\nMoonshotAI正式开源其内部研发的AI开发框架kosong，项目已上传至GitHub并发布官方文档网站。kosong是一个轻量级、模块化的AI工具链框架，专注于提升大语言模型在长文本处理、多轮对话与上下文管理中的性能。据项目描述，kosong支持动态上下文压缩、注意力机制优化与流式响应调度，特别适用于处理超过100k token的长文档场景。框架采用Python编写，兼容主流LLM（如Moonshot自研模型及开源模型），并提供CLI与Python SDK两种使用方式。开源后，开发者可自由集成、扩展或用于学术研究。此举体现了MoonshotAI推动AI基础设施开源化的战略，有望降低长文本AI应用的开发门槛。\n\n**🔗 相关链接：**\n- <https://github.com/MoonshotAI/kosong>\n- <https://moonshotai.github.io/kosong/>\n\n---\n\n### 5. 🔧 Firefox默认启用LLM功能引关注 {#5-Firefox默认启用LLM功能引关注}\n\n**标签：** `Firefox` `LLM` `Web LLM`\n\nMozilla Firefox浏览器在最新版本中默认启用本地LLM（大语言模型）功能，引发用户与开发者社区广泛讨论。据技术博客equk.co.uk报道，Firefox 135及以上版本已内置轻量级语言模型，用于实现本地文本摘要、翻译建议与搜索增强等功能，无需依赖云端服务。该功能通过Web LLM技术实现，模型在用户设备本地运行，强调隐私保护。然而，部分用户发现该功能在后台自动下载模型文件（约50-100MB），且无法通过常规设置完全禁用。为此，开发者equk发布ffox_profile_tools工具，允许高级用户通过配置文件关闭LLM模块。此举标志着主流浏览器开始集成本地AI能力，但也引发对资源占用与用户知情权的争议。\n\n**🔗 相关链接：**\n- <https://equk.co.uk/2025/10/28/firefox-forcing-llm-features/>\n- <https://github.com/equk/ffox_profile_tools>\n\n---\n\n---\n\n## 🎬 视频链接\n\n**Bilibili**： <https://www.bilibili.com/video/BV1EUkRB4Ecj>\n\n---\n\n*整理自橘鸦AI早报 | BV号：BV1EUkRB4Ecj | 2025-11-22 08:52:39*",
      "html_content": "<h1 id=\"xai-apimcptrae-solo-ai-2025-11-10\">xAI API上线MCP支持；TRAE SOLO 即将正式发布【AI 早报 2025-11-10】</h1>\n<p><strong>📅 发布日期：</strong> 2025-11-10<br />\n<strong>🎬 BV号：</strong> BV1EUkRB4Ecj<br />\n<strong>📝 整理时间：</strong> 2025-11-22 08:52:39<br />\n<strong>📊 资讯数量：</strong> 5 条</p>\n<hr />\n<h2 id=\"_1\">📋 本期概览</h2>\n<ol>\n<li>🔧 xAI API上线MCP与远程工具支持</li>\n<li>🚀 TRAE国际版将发布TRAE SOLO</li>\n<li>📈 Google Nano-Banana 2现身第三方平台</li>\n<li>🔧 MoonshotAI开源kosong框架</li>\n<li>🔧 Firefox默认启用LLM功能引关注</li>\n</ol>\n<hr />\n<h3 id=\"1-xAI-API上线MCP与远程工具支持\">1. 🔧 xAI API上线MCP与远程工具支持</h3>\n<p><strong>标签：</strong> <code>xAI</code> <code>MCP</code> <code>API</code></p>\n<p>xAI于近日宣布其API正式支持MCP（Model Control Protocol）与远程工具调用功能，进一步强化其AI模型在复杂任务自动化中的集成能力。MCP协议允许开发者将xAI模型与外部系统、数据库或自定义工具进行安全、结构化的交互，实现如实时数据查询、文件操作、API调用等远程功能。该更新意味着xAI模型不再局限于生成式任务，而是可向通用AI代理（Agent）演进，支持端到端的工作流自动化。此次更新未公布具体版本号，但已在官方API文档中体现，适用于所有接入xAI API的开发者。此举有望推动企业级AI应用落地，特别是在RPA（机器人流程自动化）、智能客服和跨平台集成场景中提升效率。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/XFreeze/status/1987357719435636931\">https://x.com/XFreeze/status/1987357719435636931</a></p>\n<hr />\n<h3 id=\"2-TRAE国际版将发布TRAE-SOLO\">2. 🚀 TRAE国际版将发布TRAE SOLO</h3>\n<p><strong>标签：</strong> <code>TRAE</code> <code>TRAE SOLO</code> <code>AI开发环境</code></p>\n<p>TRAE AI团队宣布其国际版产品TRAE SOLO即将正式发布，定位为面向全球开发者的轻量化、独立部署的AI开发环境。根据官方推文，TRAE SOLO将支持本地化模型运行、离线推理与隐私优先的数据处理机制，适用于对数据主权和合规性要求较高的场景。虽然具体发布日期未披露，但官方已开启预热宣传，强调其‘开箱即用’的特性，支持主流开源模型（如Llama 3、Qwen等）的快速集成与调试。TRAE SOLO的推出标志着TRAE从协作开发平台向独立AI工具链扩展，有望在边缘计算、私有化部署和中小企业AI转型中发挥重要作用。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/Trae_ai/status/1987611151572889690\">https://x.com/Trae_ai/status/1987611151572889690</a></p>\n<hr />\n<h3 id=\"3-Google-Nano-Banana-2现身第三方平台\">3. 📈 Google Nano-Banana 2现身第三方平台</h3>\n<p><strong>标签：</strong> <code>Google</code> <code>Nano-Banana 2</code> <code>边缘AI</code></p>\n<p>一款名为Google Nano-Banana 2的AI设备原型在第三方技术社区平台被曝光，据相关推文显示，该设备疑似为谷歌内部研发的轻量级边缘AI推理硬件，具备低功耗、高能效比的特点。虽然谷歌官方未发布任何信息，但第三方用户已上传其运行截图与初步性能测试数据，显示其支持TensorFlow Lite与MediaPipe模型部署，具备USB-C接口与Wi-Fi 6连接能力。Nano-Banana 2可能用于智能家居、可穿戴设备或IoT场景中的本地AI推理，其命名延续了谷歌非正式的硬件代号风格。此次泄露表明谷歌可能正在推进新一代边缘AI硬件研发，未来或用于增强其AI助手在离线环境下的响应能力。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/ai_for_success/status/1987350480490770533\">https://x.com/ai_for_success/status/1987350480490770533</a></p>\n<hr />\n<h3 id=\"4-MoonshotAI开源kosong框架\">4. 🔧 MoonshotAI开源kosong框架</h3>\n<p><strong>标签：</strong> <code>MoonshotAI</code> <code>kosong</code> <code>开源框架</code></p>\n<p>MoonshotAI正式开源其内部研发的AI开发框架kosong，项目已上传至GitHub并发布官方文档网站。kosong是一个轻量级、模块化的AI工具链框架，专注于提升大语言模型在长文本处理、多轮对话与上下文管理中的性能。据项目描述，kosong支持动态上下文压缩、注意力机制优化与流式响应调度，特别适用于处理超过100k token的长文档场景。框架采用Python编写，兼容主流LLM（如Moonshot自研模型及开源模型），并提供CLI与Python SDK两种使用方式。开源后，开发者可自由集成、扩展或用于学术研究。此举体现了MoonshotAI推动AI基础设施开源化的战略，有望降低长文本AI应用的开发门槛。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://github.com/MoonshotAI/kosong\">https://github.com/MoonshotAI/kosong</a><br />\n- <a href=\"https://moonshotai.github.io/kosong/\">https://moonshotai.github.io/kosong/</a></p>\n<hr />\n<h3 id=\"5-Firefox默认启用LLM功能引关注\">5. 🔧 Firefox默认启用LLM功能引关注</h3>\n<p><strong>标签：</strong> <code>Firefox</code> <code>LLM</code> <code>Web LLM</code></p>\n<p>Mozilla Firefox浏览器在最新版本中默认启用本地LLM（大语言模型）功能，引发用户与开发者社区广泛讨论。据技术博客equk.co.uk报道，Firefox 135及以上版本已内置轻量级语言模型，用于实现本地文本摘要、翻译建议与搜索增强等功能，无需依赖云端服务。该功能通过Web LLM技术实现，模型在用户设备本地运行，强调隐私保护。然而，部分用户发现该功能在后台自动下载模型文件（约50-100MB），且无法通过常规设置完全禁用。为此，开发者equk发布ffox_profile_tools工具，允许高级用户通过配置文件关闭LLM模块。此举标志着主流浏览器开始集成本地AI能力，但也引发对资源占用与用户知情权的争议。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://equk.co.uk/2025/10/28/firefox-forcing-llm-features/\">https://equk.co.uk/2025/10/28/firefox-forcing-llm-features/</a><br />\n- <a href=\"https://github.com/equk/ffox_profile_tools\">https://github.com/equk/ffox_profile_tools</a></p>\n<hr />\n<hr />\n<h2 id=\"_2\">🎬 视频链接</h2>\n<p><strong>Bilibili</strong>： <a href=\"https://www.bilibili.com/video/BV1EUkRB4Ecj\">https://www.bilibili.com/video/BV1EUkRB4Ecj</a></p>\n<hr />\n<p><em>整理自橘鸦AI早报 | BV号：BV1EUkRB4Ecj | 2025-11-22 08:52:39</em></p>",
      "date": "2025-11-10",
      "filename": "2025-11-10_AI早报_BV1EUkRB4Ecj.md"
    },
    {
      "title": "Google发布Gemini多光谱数据分析方法【AI 早报 2025-11-09】",
      "publish_date": "2025-11-09",
      "bv_id": "BV1jE1oBiEN5",
      "organize_time": "2025-11-22 08:52:58",
      "news_count": 8,
      "overview": "1. 🔧 Google发布Gemini多光谱数据分析方法\n2. 🚀 OpenRouter新增视频输入支持\n3. 🔧 xAI优化Grok-4-Fast提示词降低拒答率\n4. 🚀 Cerebras Code集成GLM-4.6模型\n5. 🚀 Letta发布Context-Bench技能评估套件\n6. 📈 OpenAI发布AI进展与建议报告\n7. 📈 OpenAI澄清政府支持与贷款担保区别\n8. 🚀 Movement Labs发布Momentum模型与MPU芯片",
      "content": "# Google发布Gemini多光谱数据分析方法【AI 早报 2025-11-09】\n\n**📅 发布日期：** 2025-11-09\n**🎬 BV号：** BV1jE1oBiEN5\n**📝 整理时间：** 2025-11-22 08:52:58\n**📊 资讯数量：** 8 条\n\n---\n\n## 📋 本期概览\n\n1. 🔧 Google发布Gemini多光谱数据分析方法\n2. 🚀 OpenRouter新增视频输入支持\n3. 🔧 xAI优化Grok-4-Fast提示词降低拒答率\n4. 🚀 Cerebras Code集成GLM-4.6模型\n5. 🚀 Letta发布Context-Bench技能评估套件\n6. 📈 OpenAI发布AI进展与建议报告\n7. 📈 OpenAI澄清政府支持与贷款担保区别\n8. 🚀 Movement Labs发布Momentum模型与MPU芯片\n\n---\n\n### 1. 🔧 Google发布Gemini多光谱数据分析方法 {#1-Google发布Gemini多光谱数据分析方法}\n\n**标签：** `Google` `Gemini` `多光谱数据`\n\nGoogle于近日发布基于Gemini模型的多光谱数据分析方法，旨在解锁遥感、农业、环境监测等领域中多光谱数据的潜力。该方法利用Gemini的多模态能力，整合来自不同波段（如可见光、近红外、热红外等）的卫星或无人机图像数据，实现更精准的地表特征识别、作物健康评估和环境变化监测。Gemini通过端到端训练，能够理解多光谱图像中的复杂模式，并生成结构化分析结果，如植被指数、土壤湿度、城市扩张趋势等。该方案已在Google开发者博客公开，提供技术白皮书与API接入指南，支持开发者构建面向地球观测的AI应用。这一进展有望推动农业精准管理、气候建模和灾害预警等领域的智能化升级。\n\n**🔗 相关链接：**\n- <https://developers.googleblog.com/en/unlocking-multi-spectral-data-with-gemini/>\n\n---\n\n### 2. 🚀 OpenRouter新增视频输入支持 {#2-OpenRouter新增视频输入支持}\n\n**标签：** `OpenRouter` `视频输入` `多模态模型`\n\nOpenRouter平台于近日宣布新增对视频输入模态的支持，允许用户通过其API将视频文件作为输入，调用支持多模态的AI模型进行处理。该功能已在模型筛选页面（/models）中上线，用户可通过筛选条件'input_modalities=video'查看当前支持视频输入的模型，并按周活跃度排序（order=top-weekly）。此举显著扩展了OpenRouter作为统一AI模型网关的能力，使开发者能够构建视频理解、内容审核、动作识别等应用。平台还同步发布了官方推文，强调其对多模态生态的持续投入。目前支持的模型包括部分开源与商业视觉-语言模型，为跨平台视频AI集成提供了灵活选择。\n\n**🔗 相关链接：**\n- <https://openrouter.ai/models?fmt=cards&input_modalities=video&order=top-weekly>\n- <https://x.com/OpenRouterAI/status/1987263320294826260>\n\n---\n\n### 3. 🔧 xAI优化Grok-4-Fast提示词降低拒答率 {#3-xAI优化Grok-4-Fast提示词降低拒答率}\n\n**标签：** `xAI` `Grok-4-Fast` `系统提示词`\n\nxAI团队近期对Grok-4-Fast模型的系统提示词进行了优化，显著降低了其拒答率。据xlr8harder在X平台发布的消息，此次调整聚焦于提示词工程，通过更清晰的指令设计、上下文引导和边界条件定义，使模型在面对模糊或敏感问题时更倾向于提供建设性回应而非直接拒绝。优化后，Grok-4-Fast在多个测试集上的拒答率下降，提升了用户体验与对话连贯性。相关技术细节未完全公开，但推测涉及对模型安全策略与生成策略的协同调优。该更新反映了当前大模型部署中‘提示词即控制’的核心趋势，对提升AI可用性与可控性具有重要意义。\n\n**🔗 相关链接：**\n- <https://x.com/xlr8harder/status/1987175738915664004>\n- <https://speechmap.ai/>\n\n---\n\n### 4. 🚀 Cerebras Code集成GLM-4.6模型 {#4-Cerebras-Code集成GLM-46模型}\n\n**标签：** `Cerebras` `GLM-4.6` `Cerebras Code`\n\nCerebras Systems宣布其Cerebras Code服务已集成GLM-4.6模型，为用户提供基于高性能AI芯片的代码生成与辅助开发能力。Cerebras Code是运行于其WSE-3芯片上的AI编程平台，此次集成使开发者可直接调用GLM-4.6进行代码补全、错误修复、文档生成等任务。GLM-4.6作为智谱AI发布的最新一代代码增强模型，具备更强的上下文理解与逻辑推理能力，尤其适用于复杂项目中的长序列代码生成。结合Cerebras的硬件优势，该服务可实现低延迟、高吞吐的推理性能，特别适合企业级开发环境。该集成标志着专用AI芯片与先进大模型在软件工程领域的深度结合。\n\n**🔗 相关链接：**\n- <https://www.cerebras.ai/code>\n\n---\n\n### 5. 🚀 Letta发布Context-Bench技能评估套件 {#5-Letta发布Context-Bench技能评估套件}\n\n**标签：** `Letta` `Context-Bench` `AI代理评估`\n\nLetta公司正式发布Context-Bench技能评估套件，用于系统性评估AI代理在复杂上下文环境中的技能表现。该套件包含一系列标准化测试任务，涵盖记忆保持、指令遵循、多轮交互、工具调用等关键能力，旨在解决当前AI代理评估缺乏统一基准的问题。Context-Bench支持自动化评分与可视化分析，并已在leaderboard.letta.com上线公开排行榜，鼓励社区提交模型与代理进行横向对比。该工具特别适用于开发具备长期记忆与任务规划能力的AI助手，如客服代理、研究助手等。其发布填补了AI代理评估领域的空白，推动多智能体系统向可量化、可比较方向发展。\n\n**🔗 相关链接：**\n- <https://www.letta.com/blog/context-bench-skills>\n- <https://leaderboard.letta.com/>\n\n---\n\n### 6. 📈 OpenAI发布AI进展与建议报告 {#6-OpenAI发布AI进展与建议报告}\n\n**标签：** `OpenAI` `AI进展` `政策建议`\n\nOpenAI于近日发布《AI进展与建议》报告，系统梳理了公司在模型能力、安全机制、治理框架和公共政策方面的最新进展。报告涵盖GPT-4o、o1系列模型的训练与部署经验，强调在推理能力、多模态交互和系统鲁棒性方面的技术突破。同时，OpenAI提出多项政策建议，包括加强AI安全测试、推动国际协作、建立风险分级机制，并呼吁政府与行业共同制定AI监管标准。报告还披露了在对抗性测试、红队演练和模型透明度方面的实践，强调‘负责任扩展’（Responsible Scaling）战略的重要性。该报告被视为OpenAI在AI治理领域的重要发声，影响全球AI政策制定方向。\n\n**🔗 相关链接：**\n- <https://openai.com/index/ai-progress-and-recommendations/>\n- <https://x.com/sama/status/1986917979343495650>\n\n---\n\n### 7. 📈 OpenAI澄清政府支持与贷款担保区别 {#7-OpenAI澄清政府支持与贷款担保区别}\n\n**标签：** `OpenAI` `Sam Altman` `政府支持`\n\nOpenAI CEO Sam Altman在X平台（@sama）发布推文，澄清外界对公司接受政府支持方式的误解，明确区分‘政府支持’与‘贷款担保’的概念。Altman指出，OpenAI所获得的政府支持主要体现为研发补贴、税收优惠和基础设施合作，而非直接贷款或债务担保。他强调，公司融资结构以股权和风险投资为主，未依赖政府信用背书进行债务融资。此举旨在回应公众对AI公司财务可持续性与公共资金使用的关注，维护公司独立运营形象。该澄清有助于厘清AI企业在公共资金利用中的边界，为行业提供透明度范例。\n\n**🔗 相关链接：**\n- <https://openai.com/index/ai-progress-and-recommendations/>\n- <https://x.com/sama/status/1986917979343495650>\n\n---\n\n### 8. 🚀 Movement Labs发布Momentum模型与MPU芯片 {#8-Movement-Labs发布Momentum模型与MPU芯}\n\n**标签：** `Movement Labs` `Momentum模型` `MPU芯片`\n\nMovement Labs正式推出其自主研发的Momentum大模型与配套的MPU（Movement Processing Unit）专用芯片，构建端到端AI计算栈。Momentum模型专注于实时推理与边缘部署，具备低延迟、高能效特性，适用于自动驾驶、工业控制、AR/VR等场景。MPU芯片采用异构架构，集成NPU、GPU与专用AI指令集，针对Momentum模型进行硬件级优化，实现比通用GPU更高的TOPS/W能效比。该方案通过软硬协同设计，提升AI推理效率与安全性，支持本地化部署与隐私保护。Movement Labs还同步开源部分工具链，推动社区生态建设。此举标志着AI初创企业向垂直整合方向迈进。\n\n**🔗 相关链接：**\n- <https://www.movementlabs.ai>\n- <https://linux.do/t/topic/1148748>\n\n---\n\n---\n\n## 🎬 视频链接\n\n**Bilibili**： <https://www.bilibili.com/video/BV1jE1oBiEN5>\n\n---\n\n*整理自橘鸦AI早报 | BV号：BV1jE1oBiEN5 | 2025-11-22 08:52:58*",
      "html_content": "<h1 id=\"googlegeminiai-2025-11-09\">Google发布Gemini多光谱数据分析方法【AI 早报 2025-11-09】</h1>\n<p><strong>📅 发布日期：</strong> 2025-11-09<br />\n<strong>🎬 BV号：</strong> BV1jE1oBiEN5<br />\n<strong>📝 整理时间：</strong> 2025-11-22 08:52:58<br />\n<strong>📊 资讯数量：</strong> 8 条</p>\n<hr />\n<h2 id=\"_1\">📋 本期概览</h2>\n<ol>\n<li>🔧 Google发布Gemini多光谱数据分析方法</li>\n<li>🚀 OpenRouter新增视频输入支持</li>\n<li>🔧 xAI优化Grok-4-Fast提示词降低拒答率</li>\n<li>🚀 Cerebras Code集成GLM-4.6模型</li>\n<li>🚀 Letta发布Context-Bench技能评估套件</li>\n<li>📈 OpenAI发布AI进展与建议报告</li>\n<li>📈 OpenAI澄清政府支持与贷款担保区别</li>\n<li>🚀 Movement Labs发布Momentum模型与MPU芯片</li>\n</ol>\n<hr />\n<h3 id=\"1-Google发布Gemini多光谱数据分析方法\">1. 🔧 Google发布Gemini多光谱数据分析方法</h3>\n<p><strong>标签：</strong> <code>Google</code> <code>Gemini</code> <code>多光谱数据</code></p>\n<p>Google于近日发布基于Gemini模型的多光谱数据分析方法，旨在解锁遥感、农业、环境监测等领域中多光谱数据的潜力。该方法利用Gemini的多模态能力，整合来自不同波段（如可见光、近红外、热红外等）的卫星或无人机图像数据，实现更精准的地表特征识别、作物健康评估和环境变化监测。Gemini通过端到端训练，能够理解多光谱图像中的复杂模式，并生成结构化分析结果，如植被指数、土壤湿度、城市扩张趋势等。该方案已在Google开发者博客公开，提供技术白皮书与API接入指南，支持开发者构建面向地球观测的AI应用。这一进展有望推动农业精准管理、气候建模和灾害预警等领域的智能化升级。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://developers.googleblog.com/en/unlocking-multi-spectral-data-with-gemini/\">https://developers.googleblog.com/en/unlocking-multi-spectral-data-with-gemini/</a></p>\n<hr />\n<h3 id=\"2-OpenRouter新增视频输入支持\">2. 🚀 OpenRouter新增视频输入支持</h3>\n<p><strong>标签：</strong> <code>OpenRouter</code> <code>视频输入</code> <code>多模态模型</code></p>\n<p>OpenRouter平台于近日宣布新增对视频输入模态的支持，允许用户通过其API将视频文件作为输入，调用支持多模态的AI模型进行处理。该功能已在模型筛选页面（/models）中上线，用户可通过筛选条件'input_modalities=video'查看当前支持视频输入的模型，并按周活跃度排序（order=top-weekly）。此举显著扩展了OpenRouter作为统一AI模型网关的能力，使开发者能够构建视频理解、内容审核、动作识别等应用。平台还同步发布了官方推文，强调其对多模态生态的持续投入。目前支持的模型包括部分开源与商业视觉-语言模型，为跨平台视频AI集成提供了灵活选择。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://openrouter.ai/models?fmt=cards&amp;input_modalities=video&amp;order=top-weekly\">https://openrouter.ai/models?fmt=cards&amp;input_modalities=video&amp;order=top-weekly</a><br />\n- <a href=\"https://x.com/OpenRouterAI/status/1987263320294826260\">https://x.com/OpenRouterAI/status/1987263320294826260</a></p>\n<hr />\n<h3 id=\"3-xAI优化Grok-4-Fast提示词降低拒答率\">3. 🔧 xAI优化Grok-4-Fast提示词降低拒答率</h3>\n<p><strong>标签：</strong> <code>xAI</code> <code>Grok-4-Fast</code> <code>系统提示词</code></p>\n<p>xAI团队近期对Grok-4-Fast模型的系统提示词进行了优化，显著降低了其拒答率。据xlr8harder在X平台发布的消息，此次调整聚焦于提示词工程，通过更清晰的指令设计、上下文引导和边界条件定义，使模型在面对模糊或敏感问题时更倾向于提供建设性回应而非直接拒绝。优化后，Grok-4-Fast在多个测试集上的拒答率下降，提升了用户体验与对话连贯性。相关技术细节未完全公开，但推测涉及对模型安全策略与生成策略的协同调优。该更新反映了当前大模型部署中‘提示词即控制’的核心趋势，对提升AI可用性与可控性具有重要意义。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/xlr8harder/status/1987175738915664004\">https://x.com/xlr8harder/status/1987175738915664004</a><br />\n- <a href=\"https://speechmap.ai/\">https://speechmap.ai/</a></p>\n<hr />\n<h3 id=\"4-Cerebras-Code集成GLM-46模型\">4. 🚀 Cerebras Code集成GLM-4.6模型</h3>\n<p><strong>标签：</strong> <code>Cerebras</code> <code>GLM-4.6</code> <code>Cerebras Code</code></p>\n<p>Cerebras Systems宣布其Cerebras Code服务已集成GLM-4.6模型，为用户提供基于高性能AI芯片的代码生成与辅助开发能力。Cerebras Code是运行于其WSE-3芯片上的AI编程平台，此次集成使开发者可直接调用GLM-4.6进行代码补全、错误修复、文档生成等任务。GLM-4.6作为智谱AI发布的最新一代代码增强模型，具备更强的上下文理解与逻辑推理能力，尤其适用于复杂项目中的长序列代码生成。结合Cerebras的硬件优势，该服务可实现低延迟、高吞吐的推理性能，特别适合企业级开发环境。该集成标志着专用AI芯片与先进大模型在软件工程领域的深度结合。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://www.cerebras.ai/code\">https://www.cerebras.ai/code</a></p>\n<hr />\n<h3 id=\"5-Letta发布Context-Bench技能评估套件\">5. 🚀 Letta发布Context-Bench技能评估套件</h3>\n<p><strong>标签：</strong> <code>Letta</code> <code>Context-Bench</code> <code>AI代理评估</code></p>\n<p>Letta公司正式发布Context-Bench技能评估套件，用于系统性评估AI代理在复杂上下文环境中的技能表现。该套件包含一系列标准化测试任务，涵盖记忆保持、指令遵循、多轮交互、工具调用等关键能力，旨在解决当前AI代理评估缺乏统一基准的问题。Context-Bench支持自动化评分与可视化分析，并已在leaderboard.letta.com上线公开排行榜，鼓励社区提交模型与代理进行横向对比。该工具特别适用于开发具备长期记忆与任务规划能力的AI助手，如客服代理、研究助手等。其发布填补了AI代理评估领域的空白，推动多智能体系统向可量化、可比较方向发展。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://www.letta.com/blog/context-bench-skills\">https://www.letta.com/blog/context-bench-skills</a><br />\n- <a href=\"https://leaderboard.letta.com/\">https://leaderboard.letta.com/</a></p>\n<hr />\n<h3 id=\"6-OpenAI发布AI进展与建议报告\">6. 📈 OpenAI发布AI进展与建议报告</h3>\n<p><strong>标签：</strong> <code>OpenAI</code> <code>AI进展</code> <code>政策建议</code></p>\n<p>OpenAI于近日发布《AI进展与建议》报告，系统梳理了公司在模型能力、安全机制、治理框架和公共政策方面的最新进展。报告涵盖GPT-4o、o1系列模型的训练与部署经验，强调在推理能力、多模态交互和系统鲁棒性方面的技术突破。同时，OpenAI提出多项政策建议，包括加强AI安全测试、推动国际协作、建立风险分级机制，并呼吁政府与行业共同制定AI监管标准。报告还披露了在对抗性测试、红队演练和模型透明度方面的实践，强调‘负责任扩展’（Responsible Scaling）战略的重要性。该报告被视为OpenAI在AI治理领域的重要发声，影响全球AI政策制定方向。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://openai.com/index/ai-progress-and-recommendations/\">https://openai.com/index/ai-progress-and-recommendations/</a><br />\n- <a href=\"https://x.com/sama/status/1986917979343495650\">https://x.com/sama/status/1986917979343495650</a></p>\n<hr />\n<h3 id=\"7-OpenAI澄清政府支持与贷款担保区别\">7. 📈 OpenAI澄清政府支持与贷款担保区别</h3>\n<p><strong>标签：</strong> <code>OpenAI</code> <code>Sam Altman</code> <code>政府支持</code></p>\n<p>OpenAI CEO Sam Altman在X平台（@sama）发布推文，澄清外界对公司接受政府支持方式的误解，明确区分‘政府支持’与‘贷款担保’的概念。Altman指出，OpenAI所获得的政府支持主要体现为研发补贴、税收优惠和基础设施合作，而非直接贷款或债务担保。他强调，公司融资结构以股权和风险投资为主，未依赖政府信用背书进行债务融资。此举旨在回应公众对AI公司财务可持续性与公共资金使用的关注，维护公司独立运营形象。该澄清有助于厘清AI企业在公共资金利用中的边界，为行业提供透明度范例。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://openai.com/index/ai-progress-and-recommendations/\">https://openai.com/index/ai-progress-and-recommendations/</a><br />\n- <a href=\"https://x.com/sama/status/1986917979343495650\">https://x.com/sama/status/1986917979343495650</a></p>\n<hr />\n<h3 id=\"8-Movement-Labs发布Momentum模型与MPU芯\">8. 🚀 Movement Labs发布Momentum模型与MPU芯片</h3>\n<p><strong>标签：</strong> <code>Movement Labs</code> <code>Momentum模型</code> <code>MPU芯片</code></p>\n<p>Movement Labs正式推出其自主研发的Momentum大模型与配套的MPU（Movement Processing Unit）专用芯片，构建端到端AI计算栈。Momentum模型专注于实时推理与边缘部署，具备低延迟、高能效特性，适用于自动驾驶、工业控制、AR/VR等场景。MPU芯片采用异构架构，集成NPU、GPU与专用AI指令集，针对Momentum模型进行硬件级优化，实现比通用GPU更高的TOPS/W能效比。该方案通过软硬协同设计，提升AI推理效率与安全性，支持本地化部署与隐私保护。Movement Labs还同步开源部分工具链，推动社区生态建设。此举标志着AI初创企业向垂直整合方向迈进。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://www.movementlabs.ai\">https://www.movementlabs.ai</a><br />\n- <a href=\"https://linux.do/t/topic/1148748\">https://linux.do/t/topic/1148748</a></p>\n<hr />\n<hr />\n<h2 id=\"_2\">🎬 视频链接</h2>\n<p><strong>Bilibili</strong>： <a href=\"https://www.bilibili.com/video/BV1jE1oBiEN5\">https://www.bilibili.com/video/BV1jE1oBiEN5</a></p>\n<hr />\n<p><em>整理自橘鸦AI早报 | BV号：BV1jE1oBiEN5 | 2025-11-22 08:52:58</em></p>",
      "date": "2025-11-09",
      "filename": "2025-11-09_AI早报_BV1jE1oBiEN5.md"
    },
    {
      "title": "狙击谷歌，OpenAI发布GPT-5-Codex-Mini模型及Codex服务升级【AI 早报 2025-11-08】",
      "publish_date": "2025-11-08",
      "bv_id": "BV1FB1UBDEct",
      "organize_time": "2025-11-22 08:53:18",
      "news_count": 12,
      "overview": "1. 🚀 OpenAI发布GPT-5-Codex-Mini及Codex升级\n2. 🚀 MiniMax发布M2模型API计费与编程套餐\n3. 🔧 腾讯开源Hunyuan World 1.1训练代码\n4. 🚀 StepFun开源Step-Audio-EditX音频编辑模型\n5. 🚀 Cursor推出composer-1模型限时免费\n6. 🔧 SGLang发布Diffusion引擎加速图像生成\n7. 📈 百度ERNIE-5.0-Preview登顶LMArena文本榜第二\n8. 📈 OpenAI泄露GPT-5.1型号及发布日期\n9. 🚀 Cerebras发布Kimi-Linear-REAP-35B-A3B-Instruct模型\n10. 🔧 Google发布Nested Learning新范式与Hope模型\n11. 🚀 NotebookLM支持Google Drive上传PDF与表格\n12. 📈 Kosmos AI科学家实现自主科学发现",
      "content": "# 狙击谷歌，OpenAI发布GPT-5-Codex-Mini模型及Codex服务升级【AI 早报 2025-11-08】\n\n**📅 发布日期：** 2025-11-08\n**🎬 BV号：** BV1FB1UBDEct\n**📝 整理时间：** 2025-11-22 08:53:18\n**📊 资讯数量：** 12 条\n\n---\n\n## 📋 本期概览\n\n1. 🚀 OpenAI发布GPT-5-Codex-Mini及Codex升级\n2. 🚀 MiniMax发布M2模型API计费与编程套餐\n3. 🔧 腾讯开源Hunyuan World 1.1训练代码\n4. 🚀 StepFun开源Step-Audio-EditX音频编辑模型\n5. 🚀 Cursor推出composer-1模型限时免费\n6. 🔧 SGLang发布Diffusion引擎加速图像生成\n7. 📈 百度ERNIE-5.0-Preview登顶LMArena文本榜第二\n8. 📈 OpenAI泄露GPT-5.1型号及发布日期\n9. 🚀 Cerebras发布Kimi-Linear-REAP-35B-A3B-Instruct模型\n10. 🔧 Google发布Nested Learning新范式与Hope模型\n11. 🚀 NotebookLM支持Google Drive上传PDF与表格\n12. 📈 Kosmos AI科学家实现自主科学发现\n\n---\n\n### 1. 🚀 OpenAI发布GPT-5-Codex-Mini及Codex升级 {#1-OpenAI发布GPT-5-Codex-Mini及Codex}\n\n**标签：** `OpenAI` `GPT-5-Codex-Mini` `Codex`\n\nOpenAI于近日发布GPT-5-Codex-Mini模型，并对Codex服务进行重大升级。该轻量级模型专为代码生成与理解优化，具备更高的推理效率与上下文理解能力，支持多语言编程任务。Codex服务升级后，集成更强大的代码补全、错误检测与文档生成功能，适用于IDE插件、自动化开发助手等场景。此次更新进一步巩固了OpenAI在AI编程领域的领先地位，有望降低开发者使用门槛，提升开发效率。相关公告发布于OpenAI开发者官方X账号（@OpenAIDevs）。\n\n**🔗 相关链接：**\n- <https://x.com/OpenAIDevs/status/1986861734619947305>\n- <https://x.com/scaling01/status/1986895079944991025>\n\n---\n\n### 2. 🚀 MiniMax发布M2模型API计费与编程套餐 {#2-MiniMax发布M2模型API计费与编程套餐}\n\n**标签：** `MiniMax` `M2模型` `API计费`\n\nMiniMax公司正式公布M2系列模型API的计费规则，并推出面向开发者的编程专用套餐。新计费体系支持按调用次数、输入输出token量分级计费，同时提供开发者优惠包，适用于高频代码生成、自动化脚本开发等场景。编程套餐包含专属API端点、速率提升与技术支持，旨在吸引中小型开发团队和独立开发者。该举措标志着MiniMax在商业化落地和生态建设方面迈出关键一步，增强其在AI编程工具市场的竞争力。\n\n**🔗 相关链接：**\n- <https://mp.weixin.qq.com/s/c9zSXtBxOGAlUeN683y00A>\n- <https://linux.do/t/topic/1143580>\n\n---\n\n### 3. 🔧 腾讯开源Hunyuan World 1.1训练代码 {#3-腾讯开源Hunyuan-World-11训练代码}\n\n**标签：** `腾讯` `Hunyuan World 1.1` `HunyuanWorld-Mirror`\n\n腾讯发布Hunyuan World 1.1版本的完整训练代码，并将其开源至Hugging Face和GitHub平台。该版本基于HunyuanWorld-Mirror项目，支持大规模多模态数据训练，涵盖文本、图像与视频联合建模能力。代码库包含数据预处理、模型架构、分布式训练脚本及评估工具，便于研究人员复现和扩展。此举推动多模态大模型研究透明化，助力学术界与工业界在通用世界模型方向的技术探索。\n\n**🔗 相关链接：**\n- <https://huggingface.co/spaces/tencent/HunyuanWorld-Mirror>\n- <https://github.com/Tencent-Hunyuan/HunyuanWorld-Mirror>\n\n---\n\n### 4. 🚀 StepFun开源Step-Audio-EditX音频编辑模型 {#4-StepFun开源Step-Audio-EditX音频编辑模}\n\n**标签：** `StepFun` `Step-Audio-EditX` `音频编辑模型`\n\nStepFun公司开源Step-Audio-EditX音频编辑大模型，支持语音内容修改、背景音替换、语速调整、情感迁移等高级音频编辑功能。模型基于Transformer架构，具备端到端语音理解与生成能力，支持多轨音频处理。项目已在Hugging Face发布模型权重、推理代码与在线演示空间，适用于播客制作、影视配音、语音助手优化等场景。开源举措将促进音频AI工具链的普及与创新。\n\n**🔗 相关链接：**\n- <https://stepaudiollm.github.io/step-audio-editx/>\n- <https://huggingface.co/stepfun-ai/Step-Audio-EditX>\n- <https://huggingface.co/spaces/stepfun-ai/Step-Audio-EditX>\n\n---\n\n### 5. 🚀 Cursor推出composer-1模型限时免费 {#5-Cursor推出composer-1模型限时免费}\n\n**标签：** `Cursor` `composer-1` `代码生成模型`\n\nCursor宣布其新一代代码生成模型composer-1推出限时免费活动，用户可在指定时间段内无限制调用该模型进行代码补全、重构与生成。composer-1具备更强的上下文感知能力，支持长代码块生成与跨文件逻辑推理，适用于复杂项目开发。此次免费策略旨在扩大用户基础，提升产品渗透率，同时为后续商业化版本积累反馈数据。\n\n**🔗 相关链接：**\n- <https://x.com/wey_gu/status/1986596124799746518>\n\n---\n\n### 6. 🔧 SGLang发布Diffusion引擎加速图像生成 {#6-SGLang发布Diffusion引擎加速图像生成}\n\n**标签：** `SGLang` `Diffusion引擎` `图像生成`\n\nSGLang团队发布专为扩散模型优化的Diffusion引擎，显著提升图像与视频生成速度。该引擎通过结构化生成语言（SGLang）实现动态调度与并行计算，支持Stable Diffusion、SDXL等主流模型，在A100 GPU上实现最高3倍推理加速。技术细节发表于lmsys.org博客，适用于实时图像生成、视频编辑、AIGC平台等高性能需求场景，推动生成式AI落地效率提升。\n\n**🔗 相关链接：**\n- <https://lmsys.org/blog/2025-11-07-sglang-diffusion/>\n\n---\n\n### 7. 📈 百度ERNIE-5.0-Preview登顶LMArena文本榜第二 {#7-百度ERNIE-50-Preview登顶LMArena文本榜}\n\n**标签：** `百度` `ERNIE-5.0-Preview` `LMArena`\n\n百度ERNIE-5.0-Preview模型在LMArena（大模型竞技场）文本生成与理解榜单中位列第二，综合得分超越多数主流开源与闭源模型。该模型在指令遵循、逻辑推理、多轮对话等维度表现突出，尤其在中文语境下具备显著优势。榜单结果由社区用户匿名对战产生，具备较高公信力。ERNIE-5.0-Preview的优异表现标志着百度在中文大模型领域持续领先。\n\n**🔗 相关链接：**\n- <https://x.com/arena/status/1986843673724919901>\n- <https://x.com/ernieforDevs/status/1986844606894321806>\n\n---\n\n### 8. 📈 OpenAI泄露GPT-5.1型号及发布日期 {#8-OpenAI泄露GPT-51型号及发布日期}\n\n**标签：** `OpenAI` `GPT-5.1` `模型泄露`\n\n据X平台用户@scaling01爆料，OpenAI内部泄露信息显示GPT-5.1模型型号已确定，并计划于近期发布。泄露内容未披露具体技术细节，但提及该版本将聚焦于推理能力提升与多模态融合。尽管OpenAI尚未官方确认，该消息引发社区广泛关注，若属实，GPT-5.1或将成为下一代通用大模型的重要里程碑，进一步推动AGI发展进程。\n\n**🔗 相关链接：**\n- <https://x.com/OpenAIDevs/status/1986861734619947305>\n- <https://x.com/scaling01/status/1986895079944991025>\n\n---\n\n### 9. 🚀 Cerebras发布Kimi-Linear-REAP-35B-A3B-Instruct模型 {#9-Cerebras发布Kimi-Linear-REAP-35B}\n\n**标签：** `Cerebras` `Kimi-Linear-REAP-35B-A3B-Instruct` `线性注意力`\n\nCerebras公司发布Kimi-Linear-REAP-35B-A3B-Instruct大模型，参数规模达35B，采用A3B指令微调架构，专为高效推理与长文本处理优化。模型基于线性注意力机制（Linear Attention），显著降低计算复杂度，适用于大规模文本摘要、问答系统与知识检索。该模型已上传至Hugging Face，支持开源社区下载与部署，体现Cerebras在高效大模型设计上的技术积累。\n\n**🔗 相关链接：**\n- <https://huggingface.co/cerebras/Kimi-Linear-REAP-35B-A3B-Instruct>\n\n---\n\n### 10. 🔧 Google发布Nested Learning新范式与Hope模型 {#10-Google发布Nested-Learning新范式与Hop}\n\n**标签：** `Google` `Nested Learning` `Hope模型`\n\nGoogle Research推出Nested Learning（嵌套学习）新机器学习范式，旨在解决持续学习中的灾难性遗忘问题。该范式通过嵌套式知识表示与模块化训练策略，使模型在增量学习过程中保持旧任务性能。同期发布的Hope模型为首个基于该范式的实验性模型，在多个NLP与CV任务上验证有效性。研究成果发表于Google Research博客，有望推动终身学习AI系统的发展。\n\n**🔗 相关链接：**\n- <https://research.google/blog/introducing-nested-learning-a-new-ml-paradigm-for-continual-learning/>\n- <https://x.com/NotebookLM/status/1986842991923740675>\n\n---\n\n### 11. 🚀 NotebookLM支持Google Drive上传PDF与表格 {#11-NotebookLM支持Google-Drive上传PDF与}\n\n**标签：** `Google` `NotebookLM` `Google Drive`\n\nGoogle NotebookLM新增支持从Google Drive直接上传PDF文档与Spreadsheets（电子表格）功能。用户可一键导入本地或云端文件，系统将自动解析内容并生成摘要、问答与知识图谱。该功能强化了NotebookLM作为个人知识管理AI助手的定位，适用于学术研究、企业文档整理、法律文书分析等场景，提升信息整合效率。\n\n**🔗 相关链接：**\n- <https://research.google/blog/introducing-nested-learning-a-new-ml-paradigm-for-continual-learning/>\n- <https://x.com/NotebookLM/status/1986842991923740675>\n\n---\n\n### 12. 📈 Kosmos AI科学家实现自主科学发现 {#12-Kosmos-AI科学家实现自主科学发现}\n\n**标签：** `Kosmos AI` `Edison Scientific` `自主科学发现`\n\nKosmos AI团队科学家宣布实现基于AI的自主科学发现系统，项目名为Edison Scientific。该系统可自动提出科学假设、设计实验、分析数据并生成论文草稿，已在材料科学与药物发现领域完成初步验证。系统结合大语言模型与符号推理引擎，具备跨学科知识整合能力。该成果标志着AI从辅助工具向科研主体角色演进，可能重塑未来科研范式。\n\n**🔗 相关链接：**\n- <https://edisonscientific.com/>\n\n---\n\n---\n\n## 🎬 视频链接\n\n**Bilibili**： <https://www.bilibili.com/video/BV1FB1UBDEct>\n\n---\n\n*整理自橘鸦AI早报 | BV号：BV1FB1UBDEct | 2025-11-22 08:53:18*",
      "html_content": "<h1 id=\"openaigpt-5-codex-minicodexai-2025-11-08\">狙击谷歌，OpenAI发布GPT-5-Codex-Mini模型及Codex服务升级【AI 早报 2025-11-08】</h1>\n<p><strong>📅 发布日期：</strong> 2025-11-08<br />\n<strong>🎬 BV号：</strong> BV1FB1UBDEct<br />\n<strong>📝 整理时间：</strong> 2025-11-22 08:53:18<br />\n<strong>📊 资讯数量：</strong> 12 条</p>\n<hr />\n<h2 id=\"_1\">📋 本期概览</h2>\n<ol>\n<li>🚀 OpenAI发布GPT-5-Codex-Mini及Codex升级</li>\n<li>🚀 MiniMax发布M2模型API计费与编程套餐</li>\n<li>🔧 腾讯开源Hunyuan World 1.1训练代码</li>\n<li>🚀 StepFun开源Step-Audio-EditX音频编辑模型</li>\n<li>🚀 Cursor推出composer-1模型限时免费</li>\n<li>🔧 SGLang发布Diffusion引擎加速图像生成</li>\n<li>📈 百度ERNIE-5.0-Preview登顶LMArena文本榜第二</li>\n<li>📈 OpenAI泄露GPT-5.1型号及发布日期</li>\n<li>🚀 Cerebras发布Kimi-Linear-REAP-35B-A3B-Instruct模型</li>\n<li>🔧 Google发布Nested Learning新范式与Hope模型</li>\n<li>🚀 NotebookLM支持Google Drive上传PDF与表格</li>\n<li>📈 Kosmos AI科学家实现自主科学发现</li>\n</ol>\n<hr />\n<h3 id=\"1-OpenAI发布GPT-5-Codex-Mini及Codex\">1. 🚀 OpenAI发布GPT-5-Codex-Mini及Codex升级</h3>\n<p><strong>标签：</strong> <code>OpenAI</code> <code>GPT-5-Codex-Mini</code> <code>Codex</code></p>\n<p>OpenAI于近日发布GPT-5-Codex-Mini模型，并对Codex服务进行重大升级。该轻量级模型专为代码生成与理解优化，具备更高的推理效率与上下文理解能力，支持多语言编程任务。Codex服务升级后，集成更强大的代码补全、错误检测与文档生成功能，适用于IDE插件、自动化开发助手等场景。此次更新进一步巩固了OpenAI在AI编程领域的领先地位，有望降低开发者使用门槛，提升开发效率。相关公告发布于OpenAI开发者官方X账号（@OpenAIDevs）。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/OpenAIDevs/status/1986861734619947305\">https://x.com/OpenAIDevs/status/1986861734619947305</a><br />\n- <a href=\"https://x.com/scaling01/status/1986895079944991025\">https://x.com/scaling01/status/1986895079944991025</a></p>\n<hr />\n<h3 id=\"2-MiniMax发布M2模型API计费与编程套餐\">2. 🚀 MiniMax发布M2模型API计费与编程套餐</h3>\n<p><strong>标签：</strong> <code>MiniMax</code> <code>M2模型</code> <code>API计费</code></p>\n<p>MiniMax公司正式公布M2系列模型API的计费规则，并推出面向开发者的编程专用套餐。新计费体系支持按调用次数、输入输出token量分级计费，同时提供开发者优惠包，适用于高频代码生成、自动化脚本开发等场景。编程套餐包含专属API端点、速率提升与技术支持，旨在吸引中小型开发团队和独立开发者。该举措标志着MiniMax在商业化落地和生态建设方面迈出关键一步，增强其在AI编程工具市场的竞争力。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://mp.weixin.qq.com/s/c9zSXtBxOGAlUeN683y00A\">https://mp.weixin.qq.com/s/c9zSXtBxOGAlUeN683y00A</a><br />\n- <a href=\"https://linux.do/t/topic/1143580\">https://linux.do/t/topic/1143580</a></p>\n<hr />\n<h3 id=\"3-腾讯开源Hunyuan-World-11训练代码\">3. 🔧 腾讯开源Hunyuan World 1.1训练代码</h3>\n<p><strong>标签：</strong> <code>腾讯</code> <code>Hunyuan World 1.1</code> <code>HunyuanWorld-Mirror</code></p>\n<p>腾讯发布Hunyuan World 1.1版本的完整训练代码，并将其开源至Hugging Face和GitHub平台。该版本基于HunyuanWorld-Mirror项目，支持大规模多模态数据训练，涵盖文本、图像与视频联合建模能力。代码库包含数据预处理、模型架构、分布式训练脚本及评估工具，便于研究人员复现和扩展。此举推动多模态大模型研究透明化，助力学术界与工业界在通用世界模型方向的技术探索。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://huggingface.co/spaces/tencent/HunyuanWorld-Mirror\">https://huggingface.co/spaces/tencent/HunyuanWorld-Mirror</a><br />\n- <a href=\"https://github.com/Tencent-Hunyuan/HunyuanWorld-Mirror\">https://github.com/Tencent-Hunyuan/HunyuanWorld-Mirror</a></p>\n<hr />\n<h3 id=\"4-StepFun开源Step-Audio-EditX音频编辑模\">4. 🚀 StepFun开源Step-Audio-EditX音频编辑模型</h3>\n<p><strong>标签：</strong> <code>StepFun</code> <code>Step-Audio-EditX</code> <code>音频编辑模型</code></p>\n<p>StepFun公司开源Step-Audio-EditX音频编辑大模型，支持语音内容修改、背景音替换、语速调整、情感迁移等高级音频编辑功能。模型基于Transformer架构，具备端到端语音理解与生成能力，支持多轨音频处理。项目已在Hugging Face发布模型权重、推理代码与在线演示空间，适用于播客制作、影视配音、语音助手优化等场景。开源举措将促进音频AI工具链的普及与创新。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://stepaudiollm.github.io/step-audio-editx/\">https://stepaudiollm.github.io/step-audio-editx/</a><br />\n- <a href=\"https://huggingface.co/stepfun-ai/Step-Audio-EditX\">https://huggingface.co/stepfun-ai/Step-Audio-EditX</a><br />\n- <a href=\"https://huggingface.co/spaces/stepfun-ai/Step-Audio-EditX\">https://huggingface.co/spaces/stepfun-ai/Step-Audio-EditX</a></p>\n<hr />\n<h3 id=\"5-Cursor推出composer-1模型限时免费\">5. 🚀 Cursor推出composer-1模型限时免费</h3>\n<p><strong>标签：</strong> <code>Cursor</code> <code>composer-1</code> <code>代码生成模型</code></p>\n<p>Cursor宣布其新一代代码生成模型composer-1推出限时免费活动，用户可在指定时间段内无限制调用该模型进行代码补全、重构与生成。composer-1具备更强的上下文感知能力，支持长代码块生成与跨文件逻辑推理，适用于复杂项目开发。此次免费策略旨在扩大用户基础，提升产品渗透率，同时为后续商业化版本积累反馈数据。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/wey_gu/status/1986596124799746518\">https://x.com/wey_gu/status/1986596124799746518</a></p>\n<hr />\n<h3 id=\"6-SGLang发布Diffusion引擎加速图像生成\">6. 🔧 SGLang发布Diffusion引擎加速图像生成</h3>\n<p><strong>标签：</strong> <code>SGLang</code> <code>Diffusion引擎</code> <code>图像生成</code></p>\n<p>SGLang团队发布专为扩散模型优化的Diffusion引擎，显著提升图像与视频生成速度。该引擎通过结构化生成语言（SGLang）实现动态调度与并行计算，支持Stable Diffusion、SDXL等主流模型，在A100 GPU上实现最高3倍推理加速。技术细节发表于lmsys.org博客，适用于实时图像生成、视频编辑、AIGC平台等高性能需求场景，推动生成式AI落地效率提升。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://lmsys.org/blog/2025-11-07-sglang-diffusion/\">https://lmsys.org/blog/2025-11-07-sglang-diffusion/</a></p>\n<hr />\n<h3 id=\"7-百度ERNIE-50-Preview登顶LMArena文本榜\">7. 📈 百度ERNIE-5.0-Preview登顶LMArena文本榜第二</h3>\n<p><strong>标签：</strong> <code>百度</code> <code>ERNIE-5.0-Preview</code> <code>LMArena</code></p>\n<p>百度ERNIE-5.0-Preview模型在LMArena（大模型竞技场）文本生成与理解榜单中位列第二，综合得分超越多数主流开源与闭源模型。该模型在指令遵循、逻辑推理、多轮对话等维度表现突出，尤其在中文语境下具备显著优势。榜单结果由社区用户匿名对战产生，具备较高公信力。ERNIE-5.0-Preview的优异表现标志着百度在中文大模型领域持续领先。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/arena/status/1986843673724919901\">https://x.com/arena/status/1986843673724919901</a><br />\n- <a href=\"https://x.com/ernieforDevs/status/1986844606894321806\">https://x.com/ernieforDevs/status/1986844606894321806</a></p>\n<hr />\n<h3 id=\"8-OpenAI泄露GPT-51型号及发布日期\">8. 📈 OpenAI泄露GPT-5.1型号及发布日期</h3>\n<p><strong>标签：</strong> <code>OpenAI</code> <code>GPT-5.1</code> <code>模型泄露</code></p>\n<p>据X平台用户@scaling01爆料，OpenAI内部泄露信息显示GPT-5.1模型型号已确定，并计划于近期发布。泄露内容未披露具体技术细节，但提及该版本将聚焦于推理能力提升与多模态融合。尽管OpenAI尚未官方确认，该消息引发社区广泛关注，若属实，GPT-5.1或将成为下一代通用大模型的重要里程碑，进一步推动AGI发展进程。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/OpenAIDevs/status/1986861734619947305\">https://x.com/OpenAIDevs/status/1986861734619947305</a><br />\n- <a href=\"https://x.com/scaling01/status/1986895079944991025\">https://x.com/scaling01/status/1986895079944991025</a></p>\n<hr />\n<h3 id=\"9-Cerebras发布Kimi-Linear-REAP-35B\">9. 🚀 Cerebras发布Kimi-Linear-REAP-35B-A3B-Instruct模型</h3>\n<p><strong>标签：</strong> <code>Cerebras</code> <code>Kimi-Linear-REAP-35B-A3B-Instruct</code> <code>线性注意力</code></p>\n<p>Cerebras公司发布Kimi-Linear-REAP-35B-A3B-Instruct大模型，参数规模达35B，采用A3B指令微调架构，专为高效推理与长文本处理优化。模型基于线性注意力机制（Linear Attention），显著降低计算复杂度，适用于大规模文本摘要、问答系统与知识检索。该模型已上传至Hugging Face，支持开源社区下载与部署，体现Cerebras在高效大模型设计上的技术积累。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://huggingface.co/cerebras/Kimi-Linear-REAP-35B-A3B-Instruct\">https://huggingface.co/cerebras/Kimi-Linear-REAP-35B-A3B-Instruct</a></p>\n<hr />\n<h3 id=\"10-Google发布Nested-Learning新范式与Hop\">10. 🔧 Google发布Nested Learning新范式与Hope模型</h3>\n<p><strong>标签：</strong> <code>Google</code> <code>Nested Learning</code> <code>Hope模型</code></p>\n<p>Google Research推出Nested Learning（嵌套学习）新机器学习范式，旨在解决持续学习中的灾难性遗忘问题。该范式通过嵌套式知识表示与模块化训练策略，使模型在增量学习过程中保持旧任务性能。同期发布的Hope模型为首个基于该范式的实验性模型，在多个NLP与CV任务上验证有效性。研究成果发表于Google Research博客，有望推动终身学习AI系统的发展。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://research.google/blog/introducing-nested-learning-a-new-ml-paradigm-for-continual-learning/\">https://research.google/blog/introducing-nested-learning-a-new-ml-paradigm-for-continual-learning/</a><br />\n- <a href=\"https://x.com/NotebookLM/status/1986842991923740675\">https://x.com/NotebookLM/status/1986842991923740675</a></p>\n<hr />\n<h3 id=\"11-NotebookLM支持Google-Drive上传PDF与\">11. 🚀 NotebookLM支持Google Drive上传PDF与表格</h3>\n<p><strong>标签：</strong> <code>Google</code> <code>NotebookLM</code> <code>Google Drive</code></p>\n<p>Google NotebookLM新增支持从Google Drive直接上传PDF文档与Spreadsheets（电子表格）功能。用户可一键导入本地或云端文件，系统将自动解析内容并生成摘要、问答与知识图谱。该功能强化了NotebookLM作为个人知识管理AI助手的定位，适用于学术研究、企业文档整理、法律文书分析等场景，提升信息整合效率。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://research.google/blog/introducing-nested-learning-a-new-ml-paradigm-for-continual-learning/\">https://research.google/blog/introducing-nested-learning-a-new-ml-paradigm-for-continual-learning/</a><br />\n- <a href=\"https://x.com/NotebookLM/status/1986842991923740675\">https://x.com/NotebookLM/status/1986842991923740675</a></p>\n<hr />\n<h3 id=\"12-Kosmos-AI科学家实现自主科学发现\">12. 📈 Kosmos AI科学家实现自主科学发现</h3>\n<p><strong>标签：</strong> <code>Kosmos AI</code> <code>Edison Scientific</code> <code>自主科学发现</code></p>\n<p>Kosmos AI团队科学家宣布实现基于AI的自主科学发现系统，项目名为Edison Scientific。该系统可自动提出科学假设、设计实验、分析数据并生成论文草稿，已在材料科学与药物发现领域完成初步验证。系统结合大语言模型与符号推理引擎，具备跨学科知识整合能力。该成果标志着AI从辅助工具向科研主体角色演进，可能重塑未来科研范式。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://edisonscientific.com/\">https://edisonscientific.com/</a></p>\n<hr />\n<hr />\n<h2 id=\"_2\">🎬 视频链接</h2>\n<p><strong>Bilibili</strong>： <a href=\"https://www.bilibili.com/video/BV1FB1UBDEct\">https://www.bilibili.com/video/BV1FB1UBDEct</a></p>\n<hr />\n<p><em>整理自橘鸦AI早报 | BV号：BV1FB1UBDEct | 2025-11-22 08:53:18</em></p>",
      "date": "2025-11-08",
      "filename": "2025-11-08_AI早报_BV1FB1UBDEct.md"
    },
    {
      "title": "硅谷地震！Kimi K2 Thinking 炸裂登场；GPT 5.1吗？OpenRouter上线Polaris Alpha【AI 早报 2025-11-07】",
      "publish_date": "2025-11-07",
      "bv_id": "BV1PP2MB1EPN",
      "organize_time": "2025-11-22 08:53:44",
      "news_count": 14,
      "overview": "1. 🚀 月之暗面发布Kimi K2 Thinking模型\n2. 🚀 OpenRouter上线Polaris Alpha隐身模型\n3. 🚀 科大讯飞发布讯飞星火X1.5及AI产品\n4. 🚀 InceptionLabs发布下一代扩散模型Mercury\n5. 🔧 Gemini API发布文件搜索工具\n6. 🔧 OpenAI修复云任务问题并提供免费积分\n7. 🔧 VS Code内联补全功能开源\n8. 🔧 Zed编辑器新增Auggie CLI与Opencode智能体\n9. 📈 Novita AI宣布KAT-Coder API限时免费\n10. 🚀 CodeBuddy国内版上线GLM-4.6模型\n11. 📈 LMArena发布Arena Expert专家级评估框架\n12. 🔧 NotebookLM手机应用新增测验与闪卡功能\n13. 🔧 Google Finance新增Deep Search功能\n14. 📈 Google Labs将Opal扩展至160+国家",
      "content": "# 硅谷地震！Kimi K2 Thinking 炸裂登场；GPT 5.1吗？OpenRouter上线Polaris Alpha【AI 早报 2025-11-07】\n\n**📅 发布日期：** 2025-11-07\n**🎬 BV号：** BV1PP2MB1EPN\n**📝 整理时间：** 2025-11-22 08:53:44\n**📊 资讯数量：** 14 条\n\n---\n\n## 📋 本期概览\n\n1. 🚀 月之暗面发布Kimi K2 Thinking模型\n2. 🚀 OpenRouter上线Polaris Alpha隐身模型\n3. 🚀 科大讯飞发布讯飞星火X1.5及AI产品\n4. 🚀 InceptionLabs发布下一代扩散模型Mercury\n5. 🔧 Gemini API发布文件搜索工具\n6. 🔧 OpenAI修复云任务问题并提供免费积分\n7. 🔧 VS Code内联补全功能开源\n8. 🔧 Zed编辑器新增Auggie CLI与Opencode智能体\n9. 📈 Novita AI宣布KAT-Coder API限时免费\n10. 🚀 CodeBuddy国内版上线GLM-4.6模型\n11. 📈 LMArena发布Arena Expert专家级评估框架\n12. 🔧 NotebookLM手机应用新增测验与闪卡功能\n13. 🔧 Google Finance新增Deep Search功能\n14. 📈 Google Labs将Opal扩展至160+国家\n\n---\n\n### 1. 🚀 月之暗面发布Kimi K2 Thinking模型 {#1-月之暗面发布Kimi-K2-Thinking模型}\n\n**标签：** `月之暗面` `Kimi K2 Thinking` `推理模型`\n\n月之暗面科技于近日正式发布新一代推理模型 Kimi K2 Thinking。该模型聚焦于提升复杂逻辑推理与多步思考能力，支持更长的上下文理解与链式推理（Chain-of-Thought），在数学、代码、常识推理等任务上表现显著增强。模型采用端到端训练方式，优化了推理路径的可解释性，适用于科研、教育、智能客服等需要深度思考的场景。此次发布标志着月之暗面在长文本与推理能力上的进一步突破。相关技术文档已发布于 GitHub 和微信公众号，提供详细架构说明与基准测试结果。\n\n**🔗 相关链接：**\n- <https://moonshotai.github.io/Kimi-K2/thinking.html>\n- <https://mp.weixin.qq.com/s/oQp1kFpoYFhYQ8GzbwZLyA>\n\n---\n\n### 2. 🚀 OpenRouter上线Polaris Alpha隐身模型 {#2-OpenRouter上线Polaris-Alpha隐身模型}\n\n**标签：** `OpenRouter` `Polaris Alpha` `stealth模型`\n\nOpenRouter 平台近日上线了一款名为 Polaris Alpha 的 stealth（隐身）模型，该模型未公开具体开发方信息，但具备强大的自然语言理解与生成能力，支持多轮对话、代码生成与复杂指令执行。Polaris Alpha 通过 OpenRouter 的统一 API 接口提供服务，开发者可无缝集成至现有应用。其‘隐身’特性意味着模型参数与训练细节暂未公开，可能用于测试或保护知识产权。该模型在推理效率与响应速度上表现优异，适用于需要高隐私保护或快速迭代的 AI 应用开发。\n\n**🔗 相关链接：**\n- <https://openrouter.ai/openrouter/polaris-alpha>\n\n---\n\n### 3. 🚀 科大讯飞发布讯飞星火X1.5及AI产品 {#3-科大讯飞发布讯飞星火X15及AI产品}\n\n**标签：** `科大讯飞` `讯飞星火X1.5` `AI产品`\n\n科大讯飞正式推出讯飞星火大模型 X1.5 版本，并同步发布多款 AI 产品。X1.5 在语言理解、多模态交互、行业知识推理等方面实现全面升级，支持更长上下文窗口（达128K tokens）、更高精度的语义解析与跨语言翻译能力。新版本强化了教育、医疗、金融等垂直领域的适配能力，并集成至讯飞听见、讯飞星火 App 等产品中。同时，科大讯飞还发布了面向开发者的 API 工具包与低代码 AI 构建平台，推动企业级 AI 应用落地。\n\n**🔗 相关链接：**\n- <https://mp.weixin.qq.com/s/sW18MtR3k58YBuGhVg6rxw>\n\n---\n\n### 4. 🚀 InceptionLabs发布下一代扩散模型Mercury {#4-InceptionLabs发布下一代扩散模型Mercury}\n\n**标签：** `InceptionLabs` `Mercury` `扩散模型`\n\nInceptionLabs 宣布推出其下一代扩散模型 Mercury，该模型在图像生成质量、多样性与推理速度上实现显著提升。Mercury 支持高分辨率图像生成（最高可达 2048x2048），具备更强的语义对齐能力，可根据复杂文本提示生成细节丰富、构图合理的图像。模型采用新型采样算法，减少生成步数，提升实时性。InceptionLabs 同步上线了 Mercury 的在线平台（platform.inceptionlabs.ai）与聊天界面（chat.inceptionlabs.ai），支持用户直接体验与 API 调用，适用于创意设计、广告、游戏美术等领域。\n\n**🔗 相关链接：**\n- <https://www.inceptionlabs.ai/blog/mercury-refreshed>\n- <https://platform.inceptionlabs.ai/>\n- <https://chat.inceptionlabs.ai/>\n\n---\n\n### 5. 🔧 Gemini API发布文件搜索工具 {#5-Gemini-API发布文件搜索工具}\n\n**标签：** `Gemini API` `文件搜索` `Google`\n\nGoogle 宣布 Gemini API 新增文件搜索（File Search）功能，允许开发者通过自然语言查询上传的文档内容。该工具基于 Gemini 的多模态理解能力，支持 PDF、DOCX、TXT 等多种格式，可自动提取文本、表格与图像信息，并返回精准答案。用户可指定文件范围、设置检索深度与排序策略，适用于知识库问答、合同审查、学术研究等场景。官方文档已发布详细使用指南，强调该功能在提升信息检索效率与降低人工阅读成本方面的价值。\n\n**🔗 相关链接：**\n- <https://blog.google/technology/developers/file-search-gemini-api/>\n- <https://ai.google.dev/gemini-api/docs/file-search>\n- <https://x.com/NewsFromGoogle/status/1986537775496151478>\n\n---\n\n### 6. 🔧 OpenAI修复云任务问题并提供免费积分 {#6-OpenAI修复云任务问题并提供免费积分}\n\n**标签：** `OpenAI` `云任务` `免费积分`\n\nOpenAI 官方于近日修复了其云平台上的任务调度问题，该问题曾导致部分用户在使用 Batch API 和异步任务时出现延迟或失败。为补偿受影响用户，OpenAI 向部分账户发放了免费 API 积分，可用于调用 GPT-4、DALL·E 等模型。修复后，系统稳定性与任务处理效率显著提升。OpenAI 在 X（原 Twitter）上发布通知，建议开发者检查任务状态并重新提交失败请求。此举体现了其对开发者生态的重视与快速响应能力。\n\n**🔗 相关链接：**\n- <https://x.com/OpenAIDevs/status/1986240264390709405>\n- <https://x.com/embirico/status/1986244205472301124>\n\n---\n\n### 7. 🔧 VS Code内联补全功能开源 {#7-VS-Code内联补全功能开源}\n\n**标签：** `VS Code` `内联补全` `微软`\n\n微软宣布 Visual Studio Code 的内联代码补全（Inline Completions）功能正式开源，相关代码已发布在 GitHub 仓库（vscode-copilot-chat）中。该功能支持基于 AI 的实时代码建议，包括单行补全、多行生成与上下文感知提示。开源后，开发者可自定义补全逻辑、集成私有模型或优化性能。此举是微软推动 AI 编辑器开源生态的重要一步，有助于构建更透明、可审计的代码生成工具，降低企业部署 AI 编程助手的门槛。\n\n**🔗 相关链接：**\n- <https://code.visualstudio.com/blogs/2025/11/04/openSourceAIEditorSecondMilestone>\n- <https://github.com/microsoft/vscode-copilot-chat/tree/main/src/extension/completions-core>\n\n---\n\n### 8. 🔧 Zed编辑器新增Auggie CLI与Opencode智能体 {#8-Zed编辑器新增Auggie-CLI与Opencode智能体}\n\n**标签：** `Zed编辑器` `Auggie CLI` `Opencode智能体`\n\nZed 编辑器团队宣布集成 Auggie CLI 与 Opencode 智能体，增强其 AI 编程能力。Auggie CLI 是一个命令行工具，支持通过自然语言指令执行代码重构、调试与版本控制操作；Opencode 智能体则可在编辑器内自动分析代码库、生成文档与建议优化方案。两者结合后，开发者可在 Zed 中实现端到端的 AI 辅助开发流程，提升编码效率与代码质量。该更新标志着 Zed 向智能编程环境迈进一步。\n\n**🔗 相关链接：**\n- <https://x.com/augmentcode/status/1986563279305777574>\n\n---\n\n### 9. 📈 Novita AI宣布KAT-Coder API限时免费 {#9-Novita-AI宣布KAT-Coder-API限时免费}\n\n**标签：** `Novita AI` `KAT-Coder API` `代码生成`\n\nNovita AI 宣布其代码生成模型 KAT-Coder 的 API 接口将限时免费开放，旨在降低开发者使用 AI 编程助手的成本。KAT-Coder 支持 Python、JavaScript、Java 等主流语言，具备上下文感知、错误修复与代码解释能力。免费期间，用户可调用 API 生成代码、进行代码审查与学习辅助。该举措有助于扩大用户基础，推动 KAT-Coder 在开源社区与教育领域的应用。\n\n**🔗 相关链接：**\n- <https://x.com/KwaiAICoder/status/1986073048622260429>\n- <https://x.com/novita_labs/status/1986395865830023234>\n\n---\n\n### 10. 🚀 CodeBuddy国内版上线GLM-4.6模型 {#10-CodeBuddy国内版上线GLM-46模型}\n\n**标签：** `CodeBuddy` `GLM-4.6` `腾讯`\n\nCodeBuddy 国内版（由腾讯支持）宣布三端同步上线 GLM-4.6 大模型，支持 Web、App 与 IDE 插件。GLM-4.6 在代码理解、生成与调试方面表现优异，支持多轮对话式编程，可自动补全、解释代码逻辑与修复错误。该模型特别优化了中文编程场景，支持中文注释与指令输入。此次更新提升了 CodeBuddy 在国内开发者中的竞争力，助力国产 AI 编程工具生态发展。\n\n**🔗 相关链接：**\n- <https://mp.weixin.qq.com/s/NRjcq7qa2YlKcaNUHNYaDQ>\n- <https://copilot.tencent.com/>\n\n---\n\n### 11. 📈 LMArena发布Arena Expert专家级评估框架 {#11-LMArena发布Arena-Expert专家级评估框架}\n\n**标签：** `LMArena` `Arena Expert` `评估框架`\n\nLMArena 团队发布 Arena Expert 专家级评估框架，旨在对大模型进行更精细、更贴近真实场景的能力评测。该框架引入领域专家参与评分，涵盖数学、编程、法律、医学等专业领域，采用多维度评分体系（如准确性、逻辑性、实用性）。评估过程包含长文本生成、多轮对话与复杂推理任务，结果以排行榜形式公开，帮助开发者与研究人员更客观地比较模型性能。此举推动了大模型评估从‘通用’向‘专业’演进。\n\n**🔗 相关链接：**\n- <https://news.lmarena.ai/arena-expert/>\n\n---\n\n### 12. 🔧 NotebookLM手机应用新增测验与闪卡功能 {#12-NotebookLM手机应用新增测验与闪卡功能}\n\n**标签：** `NotebookLM` `测验` `闪卡`\n\nGoogle 更新 NotebookLM 手机应用，新增测验（Quizzes）与闪卡（Flashcards）功能。用户可基于上传的文档自动生成学习测验与记忆卡片，支持选择题、填空题与关键词提示。该功能利用 Gemini 模型提取关键信息并生成互动式学习内容，适用于学生复习、知识整理与培训场景。更新后，NotebookLM 从笔记工具升级为智能学习助手，强化其在教育领域的应用价值。\n\n**🔗 相关链接：**\n- <https://blog.google/technology/google-labs/notebooklm-app-quizzes-flashcards/>\n\n---\n\n### 13. 🔧 Google Finance新增Deep Search功能 {#13-Google-Finance新增Deep-Search功能}\n\n**标签：** `Google Finance` `Deep Search` `Gemini`\n\nGoogle Finance 新增 Deep Search 功能，允许用户通过自然语言查询金融市场数据。例如，用户可输入‘过去一年苹果股价与纳斯达克指数的相关性’，系统将自动分析数据并生成可视化图表与摘要。该功能基于 Gemini 模型，支持多轮追问与复杂条件筛选，提升金融信息获取效率。此举标志着 Google 将 AI 搜索能力扩展至专业金融领域。\n\n**🔗 相关链接：**\n- <https://blog.google/technology/developers/file-search-gemini-api/>\n- <https://ai.google.dev/gemini-api/docs/file-search>\n- <https://x.com/NewsFromGoogle/status/1986537775496151478>\n\n---\n\n### 14. 📈 Google Labs将Opal扩展至160+国家 {#14-Google-Labs将Opal扩展至160国家}\n\n**标签：** `Google Labs` `Opal` `AI助手`\n\nGoogle Labs 宣布将其实验性 AI 助手 Opal 扩展至全球 160 多个国家与地区。Opal 是一个基于 AI 的个性化助手，支持任务管理、信息摘要与智能提醒。此次扩展覆盖欧洲、亚洲、拉丁美洲等多个区域，支持多语言交互。用户可通过 opal.google 访问，参与早期测试。该举措表明 Google 正在加速其 AI 助手产品的全球化布局，为未来正式推出做准备。\n\n**🔗 相关链接：**\n- <https://x.com/NewsFromGoogle/status/1986537775496151478>\n- <https://opal.google>\n- <https://blog.google/technology/google-labs/opal-expansion-160/>\n\n---\n\n---\n\n## 🎬 视频链接\n\n**Bilibili**： <https://www.bilibili.com/video/BV1PP2MB1EPN>\n\n---\n\n*整理自橘鸦AI早报 | BV号：BV1PP2MB1EPN | 2025-11-22 08:53:44*",
      "html_content": "<h1 id=\"kimi-k2-thinking-gpt-51openrouterpolaris-alphaai-2025-11-07\">硅谷地震！Kimi K2 Thinking 炸裂登场；GPT 5.1吗？OpenRouter上线Polaris Alpha【AI 早报 2025-11-07】</h1>\n<p><strong>📅 发布日期：</strong> 2025-11-07<br />\n<strong>🎬 BV号：</strong> BV1PP2MB1EPN<br />\n<strong>📝 整理时间：</strong> 2025-11-22 08:53:44<br />\n<strong>📊 资讯数量：</strong> 14 条</p>\n<hr />\n<h2 id=\"_1\">📋 本期概览</h2>\n<ol>\n<li>🚀 月之暗面发布Kimi K2 Thinking模型</li>\n<li>🚀 OpenRouter上线Polaris Alpha隐身模型</li>\n<li>🚀 科大讯飞发布讯飞星火X1.5及AI产品</li>\n<li>🚀 InceptionLabs发布下一代扩散模型Mercury</li>\n<li>🔧 Gemini API发布文件搜索工具</li>\n<li>🔧 OpenAI修复云任务问题并提供免费积分</li>\n<li>🔧 VS Code内联补全功能开源</li>\n<li>🔧 Zed编辑器新增Auggie CLI与Opencode智能体</li>\n<li>📈 Novita AI宣布KAT-Coder API限时免费</li>\n<li>🚀 CodeBuddy国内版上线GLM-4.6模型</li>\n<li>📈 LMArena发布Arena Expert专家级评估框架</li>\n<li>🔧 NotebookLM手机应用新增测验与闪卡功能</li>\n<li>🔧 Google Finance新增Deep Search功能</li>\n<li>📈 Google Labs将Opal扩展至160+国家</li>\n</ol>\n<hr />\n<h3 id=\"1-月之暗面发布Kimi-K2-Thinking模型\">1. 🚀 月之暗面发布Kimi K2 Thinking模型</h3>\n<p><strong>标签：</strong> <code>月之暗面</code> <code>Kimi K2 Thinking</code> <code>推理模型</code></p>\n<p>月之暗面科技于近日正式发布新一代推理模型 Kimi K2 Thinking。该模型聚焦于提升复杂逻辑推理与多步思考能力，支持更长的上下文理解与链式推理（Chain-of-Thought），在数学、代码、常识推理等任务上表现显著增强。模型采用端到端训练方式，优化了推理路径的可解释性，适用于科研、教育、智能客服等需要深度思考的场景。此次发布标志着月之暗面在长文本与推理能力上的进一步突破。相关技术文档已发布于 GitHub 和微信公众号，提供详细架构说明与基准测试结果。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://moonshotai.github.io/Kimi-K2/thinking.html\">https://moonshotai.github.io/Kimi-K2/thinking.html</a><br />\n- <a href=\"https://mp.weixin.qq.com/s/oQp1kFpoYFhYQ8GzbwZLyA\">https://mp.weixin.qq.com/s/oQp1kFpoYFhYQ8GzbwZLyA</a></p>\n<hr />\n<h3 id=\"2-OpenRouter上线Polaris-Alpha隐身模型\">2. 🚀 OpenRouter上线Polaris Alpha隐身模型</h3>\n<p><strong>标签：</strong> <code>OpenRouter</code> <code>Polaris Alpha</code> <code>stealth模型</code></p>\n<p>OpenRouter 平台近日上线了一款名为 Polaris Alpha 的 stealth（隐身）模型，该模型未公开具体开发方信息，但具备强大的自然语言理解与生成能力，支持多轮对话、代码生成与复杂指令执行。Polaris Alpha 通过 OpenRouter 的统一 API 接口提供服务，开发者可无缝集成至现有应用。其‘隐身’特性意味着模型参数与训练细节暂未公开，可能用于测试或保护知识产权。该模型在推理效率与响应速度上表现优异，适用于需要高隐私保护或快速迭代的 AI 应用开发。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://openrouter.ai/openrouter/polaris-alpha\">https://openrouter.ai/openrouter/polaris-alpha</a></p>\n<hr />\n<h3 id=\"3-科大讯飞发布讯飞星火X15及AI产品\">3. 🚀 科大讯飞发布讯飞星火X1.5及AI产品</h3>\n<p><strong>标签：</strong> <code>科大讯飞</code> <code>讯飞星火X1.5</code> <code>AI产品</code></p>\n<p>科大讯飞正式推出讯飞星火大模型 X1.5 版本，并同步发布多款 AI 产品。X1.5 在语言理解、多模态交互、行业知识推理等方面实现全面升级，支持更长上下文窗口（达128K tokens）、更高精度的语义解析与跨语言翻译能力。新版本强化了教育、医疗、金融等垂直领域的适配能力，并集成至讯飞听见、讯飞星火 App 等产品中。同时，科大讯飞还发布了面向开发者的 API 工具包与低代码 AI 构建平台，推动企业级 AI 应用落地。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://mp.weixin.qq.com/s/sW18MtR3k58YBuGhVg6rxw\">https://mp.weixin.qq.com/s/sW18MtR3k58YBuGhVg6rxw</a></p>\n<hr />\n<h3 id=\"4-InceptionLabs发布下一代扩散模型Mercury\">4. 🚀 InceptionLabs发布下一代扩散模型Mercury</h3>\n<p><strong>标签：</strong> <code>InceptionLabs</code> <code>Mercury</code> <code>扩散模型</code></p>\n<p>InceptionLabs 宣布推出其下一代扩散模型 Mercury，该模型在图像生成质量、多样性与推理速度上实现显著提升。Mercury 支持高分辨率图像生成（最高可达 2048x2048），具备更强的语义对齐能力，可根据复杂文本提示生成细节丰富、构图合理的图像。模型采用新型采样算法，减少生成步数，提升实时性。InceptionLabs 同步上线了 Mercury 的在线平台（platform.inceptionlabs.ai）与聊天界面（chat.inceptionlabs.ai），支持用户直接体验与 API 调用，适用于创意设计、广告、游戏美术等领域。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://www.inceptionlabs.ai/blog/mercury-refreshed\">https://www.inceptionlabs.ai/blog/mercury-refreshed</a><br />\n- <a href=\"https://platform.inceptionlabs.ai/\">https://platform.inceptionlabs.ai/</a><br />\n- <a href=\"https://chat.inceptionlabs.ai/\">https://chat.inceptionlabs.ai/</a></p>\n<hr />\n<h3 id=\"5-Gemini-API发布文件搜索工具\">5. 🔧 Gemini API发布文件搜索工具</h3>\n<p><strong>标签：</strong> <code>Gemini API</code> <code>文件搜索</code> <code>Google</code></p>\n<p>Google 宣布 Gemini API 新增文件搜索（File Search）功能，允许开发者通过自然语言查询上传的文档内容。该工具基于 Gemini 的多模态理解能力，支持 PDF、DOCX、TXT 等多种格式，可自动提取文本、表格与图像信息，并返回精准答案。用户可指定文件范围、设置检索深度与排序策略，适用于知识库问答、合同审查、学术研究等场景。官方文档已发布详细使用指南，强调该功能在提升信息检索效率与降低人工阅读成本方面的价值。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://blog.google/technology/developers/file-search-gemini-api/\">https://blog.google/technology/developers/file-search-gemini-api/</a><br />\n- <a href=\"https://ai.google.dev/gemini-api/docs/file-search\">https://ai.google.dev/gemini-api/docs/file-search</a><br />\n- <a href=\"https://x.com/NewsFromGoogle/status/1986537775496151478\">https://x.com/NewsFromGoogle/status/1986537775496151478</a></p>\n<hr />\n<h3 id=\"6-OpenAI修复云任务问题并提供免费积分\">6. 🔧 OpenAI修复云任务问题并提供免费积分</h3>\n<p><strong>标签：</strong> <code>OpenAI</code> <code>云任务</code> <code>免费积分</code></p>\n<p>OpenAI 官方于近日修复了其云平台上的任务调度问题，该问题曾导致部分用户在使用 Batch API 和异步任务时出现延迟或失败。为补偿受影响用户，OpenAI 向部分账户发放了免费 API 积分，可用于调用 GPT-4、DALL·E 等模型。修复后，系统稳定性与任务处理效率显著提升。OpenAI 在 X（原 Twitter）上发布通知，建议开发者检查任务状态并重新提交失败请求。此举体现了其对开发者生态的重视与快速响应能力。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/OpenAIDevs/status/1986240264390709405\">https://x.com/OpenAIDevs/status/1986240264390709405</a><br />\n- <a href=\"https://x.com/embirico/status/1986244205472301124\">https://x.com/embirico/status/1986244205472301124</a></p>\n<hr />\n<h3 id=\"7-VS-Code内联补全功能开源\">7. 🔧 VS Code内联补全功能开源</h3>\n<p><strong>标签：</strong> <code>VS Code</code> <code>内联补全</code> <code>微软</code></p>\n<p>微软宣布 Visual Studio Code 的内联代码补全（Inline Completions）功能正式开源，相关代码已发布在 GitHub 仓库（vscode-copilot-chat）中。该功能支持基于 AI 的实时代码建议，包括单行补全、多行生成与上下文感知提示。开源后，开发者可自定义补全逻辑、集成私有模型或优化性能。此举是微软推动 AI 编辑器开源生态的重要一步，有助于构建更透明、可审计的代码生成工具，降低企业部署 AI 编程助手的门槛。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://code.visualstudio.com/blogs/2025/11/04/openSourceAIEditorSecondMilestone\">https://code.visualstudio.com/blogs/2025/11/04/openSourceAIEditorSecondMilestone</a><br />\n- <a href=\"https://github.com/microsoft/vscode-copilot-chat/tree/main/src/extension/completions-core\">https://github.com/microsoft/vscode-copilot-chat/tree/main/src/extension/completions-core</a></p>\n<hr />\n<h3 id=\"8-Zed编辑器新增Auggie-CLI与Opencode智能体\">8. 🔧 Zed编辑器新增Auggie CLI与Opencode智能体</h3>\n<p><strong>标签：</strong> <code>Zed编辑器</code> <code>Auggie CLI</code> <code>Opencode智能体</code></p>\n<p>Zed 编辑器团队宣布集成 Auggie CLI 与 Opencode 智能体，增强其 AI 编程能力。Auggie CLI 是一个命令行工具，支持通过自然语言指令执行代码重构、调试与版本控制操作；Opencode 智能体则可在编辑器内自动分析代码库、生成文档与建议优化方案。两者结合后，开发者可在 Zed 中实现端到端的 AI 辅助开发流程，提升编码效率与代码质量。该更新标志着 Zed 向智能编程环境迈进一步。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/augmentcode/status/1986563279305777574\">https://x.com/augmentcode/status/1986563279305777574</a></p>\n<hr />\n<h3 id=\"9-Novita-AI宣布KAT-Coder-API限时免费\">9. 📈 Novita AI宣布KAT-Coder API限时免费</h3>\n<p><strong>标签：</strong> <code>Novita AI</code> <code>KAT-Coder API</code> <code>代码生成</code></p>\n<p>Novita AI 宣布其代码生成模型 KAT-Coder 的 API 接口将限时免费开放，旨在降低开发者使用 AI 编程助手的成本。KAT-Coder 支持 Python、JavaScript、Java 等主流语言，具备上下文感知、错误修复与代码解释能力。免费期间，用户可调用 API 生成代码、进行代码审查与学习辅助。该举措有助于扩大用户基础，推动 KAT-Coder 在开源社区与教育领域的应用。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/KwaiAICoder/status/1986073048622260429\">https://x.com/KwaiAICoder/status/1986073048622260429</a><br />\n- <a href=\"https://x.com/novita_labs/status/1986395865830023234\">https://x.com/novita_labs/status/1986395865830023234</a></p>\n<hr />\n<h3 id=\"10-CodeBuddy国内版上线GLM-46模型\">10. 🚀 CodeBuddy国内版上线GLM-4.6模型</h3>\n<p><strong>标签：</strong> <code>CodeBuddy</code> <code>GLM-4.6</code> <code>腾讯</code></p>\n<p>CodeBuddy 国内版（由腾讯支持）宣布三端同步上线 GLM-4.6 大模型，支持 Web、App 与 IDE 插件。GLM-4.6 在代码理解、生成与调试方面表现优异，支持多轮对话式编程，可自动补全、解释代码逻辑与修复错误。该模型特别优化了中文编程场景，支持中文注释与指令输入。此次更新提升了 CodeBuddy 在国内开发者中的竞争力，助力国产 AI 编程工具生态发展。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://mp.weixin.qq.com/s/NRjcq7qa2YlKcaNUHNYaDQ\">https://mp.weixin.qq.com/s/NRjcq7qa2YlKcaNUHNYaDQ</a><br />\n- <a href=\"https://copilot.tencent.com/\">https://copilot.tencent.com/</a></p>\n<hr />\n<h3 id=\"11-LMArena发布Arena-Expert专家级评估框架\">11. 📈 LMArena发布Arena Expert专家级评估框架</h3>\n<p><strong>标签：</strong> <code>LMArena</code> <code>Arena Expert</code> <code>评估框架</code></p>\n<p>LMArena 团队发布 Arena Expert 专家级评估框架，旨在对大模型进行更精细、更贴近真实场景的能力评测。该框架引入领域专家参与评分，涵盖数学、编程、法律、医学等专业领域，采用多维度评分体系（如准确性、逻辑性、实用性）。评估过程包含长文本生成、多轮对话与复杂推理任务，结果以排行榜形式公开，帮助开发者与研究人员更客观地比较模型性能。此举推动了大模型评估从‘通用’向‘专业’演进。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://news.lmarena.ai/arena-expert/\">https://news.lmarena.ai/arena-expert/</a></p>\n<hr />\n<h3 id=\"12-NotebookLM手机应用新增测验与闪卡功能\">12. 🔧 NotebookLM手机应用新增测验与闪卡功能</h3>\n<p><strong>标签：</strong> <code>NotebookLM</code> <code>测验</code> <code>闪卡</code></p>\n<p>Google 更新 NotebookLM 手机应用，新增测验（Quizzes）与闪卡（Flashcards）功能。用户可基于上传的文档自动生成学习测验与记忆卡片，支持选择题、填空题与关键词提示。该功能利用 Gemini 模型提取关键信息并生成互动式学习内容，适用于学生复习、知识整理与培训场景。更新后，NotebookLM 从笔记工具升级为智能学习助手，强化其在教育领域的应用价值。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://blog.google/technology/google-labs/notebooklm-app-quizzes-flashcards/\">https://blog.google/technology/google-labs/notebooklm-app-quizzes-flashcards/</a></p>\n<hr />\n<h3 id=\"13-Google-Finance新增Deep-Search功能\">13. 🔧 Google Finance新增Deep Search功能</h3>\n<p><strong>标签：</strong> <code>Google Finance</code> <code>Deep Search</code> <code>Gemini</code></p>\n<p>Google Finance 新增 Deep Search 功能，允许用户通过自然语言查询金融市场数据。例如，用户可输入‘过去一年苹果股价与纳斯达克指数的相关性’，系统将自动分析数据并生成可视化图表与摘要。该功能基于 Gemini 模型，支持多轮追问与复杂条件筛选，提升金融信息获取效率。此举标志着 Google 将 AI 搜索能力扩展至专业金融领域。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://blog.google/technology/developers/file-search-gemini-api/\">https://blog.google/technology/developers/file-search-gemini-api/</a><br />\n- <a href=\"https://ai.google.dev/gemini-api/docs/file-search\">https://ai.google.dev/gemini-api/docs/file-search</a><br />\n- <a href=\"https://x.com/NewsFromGoogle/status/1986537775496151478\">https://x.com/NewsFromGoogle/status/1986537775496151478</a></p>\n<hr />\n<h3 id=\"14-Google-Labs将Opal扩展至160国家\">14. 📈 Google Labs将Opal扩展至160+国家</h3>\n<p><strong>标签：</strong> <code>Google Labs</code> <code>Opal</code> <code>AI助手</code></p>\n<p>Google Labs 宣布将其实验性 AI 助手 Opal 扩展至全球 160 多个国家与地区。Opal 是一个基于 AI 的个性化助手，支持任务管理、信息摘要与智能提醒。此次扩展覆盖欧洲、亚洲、拉丁美洲等多个区域，支持多语言交互。用户可通过 opal.google 访问，参与早期测试。该举措表明 Google 正在加速其 AI 助手产品的全球化布局，为未来正式推出做准备。</p>\n<p><strong>🔗 相关链接：</strong><br />\n- <a href=\"https://x.com/NewsFromGoogle/status/1986537775496151478\">https://x.com/NewsFromGoogle/status/1986537775496151478</a><br />\n- <a href=\"https://opal.google\">https://opal.google</a><br />\n- <a href=\"https://blog.google/technology/google-labs/opal-expansion-160/\">https://blog.google/technology/google-labs/opal-expansion-160/</a></p>\n<hr />\n<hr />\n<h2 id=\"_2\">🎬 视频链接</h2>\n<p><strong>Bilibili</strong>： <a href=\"https://www.bilibili.com/video/BV1PP2MB1EPN\">https://www.bilibili.com/video/BV1PP2MB1EPN</a></p>\n<hr />\n<p><em>整理自橘鸦AI早报 | BV号：BV1PP2MB1EPN | 2025-11-22 08:53:44</em></p>",
      "date": "2025-11-07",
      "filename": "2025-11-07_AI早报_BV1PP2MB1EPN.md"
    }
  ],
  "total_count": 13,
  "generated_time": "2025-11-22 18:47:14",
  "page_size": 10
}